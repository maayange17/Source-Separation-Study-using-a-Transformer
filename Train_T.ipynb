{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d02455",
   "metadata": {},
   "outputs": [],
   "source": [
    "Main_path = '~/Source_Sep_Rea/Facebook_Transformers/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cff42712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\n",
      "To initialize your shell, run\n",
      "\n",
      "    $ conda init <SHELL_NAME>\n",
      "\n",
      "Currently supported shells are:\n",
      "  - bash\n",
      "  - fish\n",
      "  - tcsh\n",
      "  - xonsh\n",
      "  - zsh\n",
      "  - powershell\n",
      "\n",
      "See 'conda init --help' for more information and options.\n",
      "\n",
      "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\n",
      "\n",
      "\n",
      "CODE_OF_CONDUCT.md  environment-cpu.yml   mypy.ini\t\t    setup.cfg\n",
      "conf\t\t    environment-cuda.yml  nohup.out\t\t    setup.py\n",
      "CONTRIBUTING.md     hubconf.py\t\t  outputs\t\t    test.mp3\n",
      "demucs\t\t    LICENSE\t\t  outputs.tar.gz\t    tools\n",
      "Demucs.ipynb\t    Makefile\t\t  README.md\n",
      "demucs.png\t    MANIFEST.in\t\t  requirements_minimal.txt\n",
      "docs\t\t    metadata\t\t  requirements.txt\n",
      "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "path_of_code = Main_path + 'demucs-main/demucs-main'\n",
    "\n",
    "!conda activate base\n",
    "\n",
    "!ls $path_of_code\n",
    "%cd $path_of_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c578f9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs/\n",
      "outputs/xps/\n",
      "outputs/xps/e444734f/\n",
      "outputs/xps/cfa93e08/\n",
      "outputs/xps/e51eebcc/\n",
      "outputs/xps/e312f349/\n",
      "outputs/xps/b141dad5/\n",
      "outputs/xps/f435b96e/\n",
      "outputs/xps/80a68df8/\n",
      "outputs/xps/87a4323f/\n",
      "outputs/xps/5d2d6c55/\n",
      "outputs/xps/7ecf8ec1/\n",
      "outputs/xps/7d865c68/\n",
      "outputs/xps/c511e2ab/\n",
      "outputs/xps/c24d4b58/\n",
      "outputs/xps/2cfe4564/\n",
      "outputs/xps/81de367c/\n",
      "outputs/xps/9357e12e/\n",
      "outputs/xps/76a5c33b/\n",
      "outputs/xps/8e19e553/\n",
      "outputs/xps/269b2268/\n",
      "outputs/xps/1b7b2b14/\n",
      "outputs/xps/a1d90b5c/\n",
      "outputs/xps/0d19c1c6/\n",
      "outputs/xps/3d21764b/\n",
      "outputs/xps/3d21764b/.argv.json\n",
      "outputs/xps/0d19c1c6/.argv.json\n",
      "outputs/xps/a1d90b5c/.argv.json\n",
      "outputs/xps/1b7b2b14/.argv.json\n",
      "outputs/xps/269b2268/.argv.json\n",
      "outputs/xps/8e19e553/.argv.json\n",
      "outputs/xps/76a5c33b/.argv.json\n",
      "outputs/xps/9357e12e/.argv.json\n",
      "outputs/xps/81de367c/.argv.json\n",
      "outputs/xps/2cfe4564/.argv.json\n",
      "outputs/xps/c24d4b58/.argv.json\n",
      "outputs/xps/c511e2ab/.argv.json\n",
      "outputs/xps/7d865c68/.argv.json\n",
      "outputs/xps/7ecf8ec1/.argv.json\n",
      "outputs/xps/5d2d6c55/.argv.json\n",
      "outputs/xps/87a4323f/.argv.json\n",
      "outputs/xps/80a68df8/.argv.json\n",
      "outputs/xps/f435b96e/.argv.json\n",
      "outputs/xps/b141dad5/.argv.json\n",
      "outputs/xps/e312f349/.argv.json\n",
      "outputs/xps/e51eebcc/.argv.json\n",
      "outputs/xps/cfa93e08/.argv.json\n",
      "outputs/xps/e444734f/.argv.json\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "\u001b[1mParser\u001b[0m Injecting argv ['hdemucs.norm_starts=999', 'hdemucs.cac=False', 'test.split=True', 'valid_apply=True', 'model=hdemucs', 'hdemucs.dconv_lstm=4', 'ema.epoch=[0.9, 0.95]', 'ema.batch=[0.9995, 0.9999]', 'seed=42', 'hdemucs.hybrid_old=True', 'svd=base', 'svd.penalty=1e-05', 'svd.dim=100', 'svd.convtr=True', 'optim.lr=0.0005'] from sig 81de367c\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "\u001b[1mExecutor:\u001b[0m Starting 1 worker processes for DDP.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:228: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  return hydra.main(\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[\u001b[36m08-17 20:25:17\u001b[0m][\u001b[34mdemucs.train\u001b[0m][\u001b[32mINFO\u001b[0m] - For logs, checkpoints and samples check /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/22d99e8f\u001b[0m\n",
      "[\u001b[36m08-17 20:25:17\u001b[0m][\u001b[34mdora.distrib\u001b[0m][\u001b[32mINFO\u001b[0m] - world_size is 1, skipping init.\u001b[0m\n",
      "GlobalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "GlobalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "LocalSelfAttn: None\n",
      "LocalCrossAttn: None\n",
      "Using Embedding: temporal\n",
      "Time Emb Dim: 6\n",
      "Space Embedding: True\n",
      "Time Embedding: True\n",
      "Val Embedding: True\n",
      "Given Embedding: True\n",
      "Null Value: None\n",
      "Pad Value: None\n",
      "Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0\n",
      "D_Model = 50\n",
      "GlobalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "GlobalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "LocalSelfAttn: None\n",
      "LocalCrossAttn: None\n",
      "Using Embedding: temporal\n",
      "Time Emb Dim: 6\n",
      "Space Embedding: True\n",
      "Time Embedding: True\n",
      "Val Embedding: True\n",
      "Given Embedding: True\n",
      "Null Value: None\n",
      "Pad Value: None\n",
      "Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0\n",
      "D_Model = 50\n",
      "GlobalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "GlobalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "LocalSelfAttn: None\n",
      "LocalCrossAttn: None\n",
      "Using Embedding: temporal\n",
      "Time Emb Dim: 6\n",
      "Space Embedding: True\n",
      "Time Embedding: True\n",
      "Val Embedding: True\n",
      "Given Embedding: True\n",
      "Null Value: None\n",
      "Pad Value: None\n",
      "Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0\n",
      "D_Model = 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GlobalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "GlobalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "LocalSelfAttn: None\n",
      "LocalCrossAttn: None\n",
      "Using Embedding: temporal\n",
      "Time Emb Dim: 6\n",
      "Space Embedding: True\n",
      "Time Embedding: True\n",
      "Val Embedding: True\n",
      "Given Embedding: True\n",
      "Null Value: None\n",
      "Pad Value: None\n",
      "Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0\n",
      "D_Model = 50\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/musdb/configs/mus.yaml\n",
      "[\u001b[36m08-17 20:25:23\u001b[0m][\u001b[34mdemucs.train\u001b[0m][\u001b[32mINFO\u001b[0m] - train/valid set size: 18626 14\u001b[0m\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "[\u001b[36m08-17 20:25:23\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading checkpoint model: /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/22d99e8f/checkpoint.th\u001b[0m\n",
      "[\u001b[36m08-17 20:25:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Replaying metrics from previous run\u001b[0m\n",
      "[\u001b[36m08-17 20:25:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 1 | Loss=0.1819 | Reco=0.1807 | Grad=0.1087 | Penalty=118.3743\u001b[0m\n",
      "[\u001b[36m08-17 20:25:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 1 | Loss=0.2308 | Reco=0.2308 | Nsdr=3.189 | Best=0.2308 | Bname=ema_epoch_1 | Penalty=137.7797\u001b[0m\n",
      "[\u001b[36m08-17 20:25:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 2 | Loss=0.1498 | Reco=0.1484 | Grad=0.1234 | Penalty=142.0411\u001b[0m\n",
      "[\u001b[36m08-17 20:25:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 2 | Loss=0.2094 | Reco=0.2094 | Nsdr=3.943 | Best=0.2094 | Bname=main | Penalty=147.8255\u001b[0m\n",
      "[\u001b[36m08-17 20:25:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 3 | Loss=0.1365 | Reco=0.1350 | Grad=0.1171 | Penalty=145.3890\u001b[0m\n",
      "[\u001b[36m08-17 20:25:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 3 | Loss=0.1958 | Reco=0.1958 | Nsdr=4.480 | Best=0.1958 | Bname=ema_batch_0 | Penalty=150.2971\u001b[0m\n",
      "[\u001b[36m08-17 20:25:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 4 | Loss=0.1303 | Reco=0.1287 | Grad=0.1115 | Penalty=154.7542\u001b[0m\n",
      "[\u001b[36m08-17 20:25:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 4 | Loss=0.1895 | Reco=0.1895 | Nsdr=4.743 | Best=0.1895 | Bname=ema_batch_0 | Penalty=155.6288\u001b[0m\n",
      "[\u001b[36m08-17 20:25:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 5 | Loss=0.1259 | Reco=0.1243 | Grad=0.1100 | Penalty=156.7056\u001b[0m\n",
      "[\u001b[36m08-17 20:25:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 5 | Loss=0.1846 | Reco=0.1846 | Nsdr=4.953 | Best=0.1846 | Bname=ema_batch_0 | Penalty=169.3036\u001b[0m\n",
      "[\u001b[36m08-17 20:25:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 6 | Loss=0.1227 | Reco=0.1210 | Grad=0.1098 | Penalty=164.9727\u001b[0m\n",
      "[\u001b[36m08-17 20:25:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 6 | Loss=0.1813 | Reco=0.1813 | Nsdr=5.101 | Best=0.1813 | Bname=ema_batch_0 | Penalty=173.2328\u001b[0m\n",
      "[\u001b[36m08-17 20:25:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 7 | Loss=0.1206 | Reco=0.1189 | Grad=0.1092 | Penalty=175.9711\u001b[0m\n",
      "[\u001b[36m08-17 20:25:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 7 | Loss=0.1791 | Reco=0.1791 | Nsdr=5.209 | Best=0.1791 | Bname=ema_batch_0 | Penalty=177.0426\u001b[0m\n",
      "[\u001b[36m08-17 20:25:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 8 | Loss=0.1179 | Reco=0.1161 | Grad=0.1072 | Penalty=178.1459\u001b[0m\n",
      "[\u001b[36m08-17 20:25:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 8 | Loss=0.1773 | Reco=0.1773 | Nsdr=5.294 | Best=0.1773 | Bname=ema_batch_0 | Penalty=178.6649\u001b[0m\n",
      "[\u001b[36m08-17 20:25:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 9 | Loss=0.1160 | Reco=0.1142 | Grad=0.1064 | Penalty=179.4066\u001b[0m\n",
      "[\u001b[36m08-17 20:25:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 9 | Loss=0.1758 | Reco=0.1758 | Nsdr=5.356 | Best=0.1758 | Bname=ema_batch_0 | Penalty=182.7116\u001b[0m\n",
      "[\u001b[36m08-17 20:25:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 10 | Loss=0.1146 | Reco=0.1127 | Grad=0.1052 | Penalty=189.3448\u001b[0m\n",
      "[\u001b[36m08-17 20:25:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 10 | Loss=0.1756 | Reco=0.1756 | Nsdr=5.383 | Best=0.1756 | Bname=ema_batch_0 | Penalty=188.8717\u001b[0m\n",
      "[\u001b[36m08-17 20:25:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - ----------------------------------------------------------------------\u001b[0m\n",
      "[\u001b[36m08-17 20:25:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Training...\u001b[0m\n",
      "^C\n",
      "\u001b[1mExecutor:\u001b[0m Received keyboard interrupt, trying to kill all workers.\n"
     ]
    }
   ],
   "source": [
    "#setup d_model = 100\n",
    "!tar xvf outputs.tar.gz\n",
    "\n",
    "!dora run -d -f 81de367c batch_size=4 dset.segment=8 hdemucs.channels=24 test.workers= epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28e5a315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs/\n",
      "outputs/xps/\n",
      "outputs/xps/e444734f/\n",
      "outputs/xps/cfa93e08/\n",
      "outputs/xps/e51eebcc/\n",
      "outputs/xps/e312f349/\n",
      "outputs/xps/b141dad5/\n",
      "outputs/xps/f435b96e/\n",
      "outputs/xps/80a68df8/\n",
      "outputs/xps/87a4323f/\n",
      "outputs/xps/5d2d6c55/\n",
      "outputs/xps/7ecf8ec1/\n",
      "outputs/xps/7d865c68/\n",
      "outputs/xps/c511e2ab/\n",
      "outputs/xps/c24d4b58/\n",
      "outputs/xps/2cfe4564/\n",
      "outputs/xps/81de367c/\n",
      "outputs/xps/9357e12e/\n",
      "outputs/xps/76a5c33b/\n",
      "outputs/xps/8e19e553/\n",
      "outputs/xps/269b2268/\n",
      "outputs/xps/1b7b2b14/\n",
      "outputs/xps/a1d90b5c/\n",
      "outputs/xps/0d19c1c6/\n",
      "outputs/xps/3d21764b/\n",
      "outputs/xps/3d21764b/.argv.json\n",
      "outputs/xps/0d19c1c6/.argv.json\n",
      "outputs/xps/a1d90b5c/.argv.json\n",
      "outputs/xps/1b7b2b14/.argv.json\n",
      "outputs/xps/269b2268/.argv.json\n",
      "outputs/xps/8e19e553/.argv.json\n",
      "outputs/xps/76a5c33b/.argv.json\n",
      "outputs/xps/9357e12e/.argv.json\n",
      "outputs/xps/81de367c/.argv.json\n",
      "outputs/xps/2cfe4564/.argv.json\n",
      "outputs/xps/c24d4b58/.argv.json\n",
      "outputs/xps/c511e2ab/.argv.json\n",
      "outputs/xps/7d865c68/.argv.json\n",
      "outputs/xps/7ecf8ec1/.argv.json\n",
      "outputs/xps/5d2d6c55/.argv.json\n",
      "outputs/xps/87a4323f/.argv.json\n",
      "outputs/xps/80a68df8/.argv.json\n",
      "outputs/xps/f435b96e/.argv.json\n",
      "outputs/xps/b141dad5/.argv.json\n",
      "outputs/xps/e312f349/.argv.json\n",
      "outputs/xps/e51eebcc/.argv.json\n",
      "outputs/xps/cfa93e08/.argv.json\n",
      "outputs/xps/e444734f/.argv.json\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "\u001b[1mParser\u001b[0m Injecting argv ['hdemucs.norm_starts=999', 'hdemucs.cac=False', 'test.split=True', 'valid_apply=True', 'model=hdemucs', 'hdemucs.dconv_lstm=4', 'ema.epoch=[0.9, 0.95]', 'ema.batch=[0.9995, 0.9999]', 'seed=42', 'hdemucs.hybrid_old=True', 'svd=base', 'svd.penalty=1e-05', 'svd.dim=100', 'svd.convtr=True', 'optim.lr=0.0005'] from sig 81de367c\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "\u001b[1mExecutor:\u001b[0m Starting 1 worker processes for DDP.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:228: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  return hydra.main(\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[\u001b[36m08-18 21:49:02\u001b[0m][\u001b[34mdemucs.train\u001b[0m][\u001b[32mINFO\u001b[0m] - For logs, checkpoints and samples check /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/22d99e8f\u001b[0m\n",
      "[\u001b[36m08-18 21:49:02\u001b[0m][\u001b[34mdora.distrib\u001b[0m][\u001b[32mINFO\u001b[0m] - world_size is 1, skipping init.\u001b[0m\n",
      "GlobalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=50, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=50, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=50, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=50, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "GlobalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=50, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=50, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=50, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=50, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "LocalSelfAttn: None\n",
      "LocalCrossAttn: None\n",
      "Using Embedding: temporal\n",
      "Time Emb Dim: 6\n",
      "Space Embedding: True\n",
      "Time Embedding: True\n",
      "Val Embedding: True\n",
      "Given Embedding: True\n",
      "Null Value: None\n",
      "Pad Value: None\n",
      "Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0\n",
      "D_Model = 50\n",
      "GlobalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=50, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=50, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=50, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=50, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "GlobalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=50, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=50, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=50, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=50, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "LocalSelfAttn: None\n",
      "LocalCrossAttn: None\n",
      "Using Embedding: temporal\n",
      "Time Emb Dim: 6\n",
      "Space Embedding: True\n",
      "Time Embedding: True\n",
      "Val Embedding: True\n",
      "Given Embedding: True\n",
      "Null Value: None\n",
      "Pad Value: None\n",
      "Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0\n",
      "D_Model = 50\n",
      "GlobalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=50, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=50, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=50, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=50, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "GlobalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=50, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=50, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=50, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=50, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "LocalSelfAttn: None\n",
      "LocalCrossAttn: None\n",
      "Using Embedding: temporal\n",
      "Time Emb Dim: 6\n",
      "Space Embedding: True\n",
      "Time Embedding: True\n",
      "Val Embedding: True\n",
      "Given Embedding: True\n",
      "Null Value: None\n",
      "Pad Value: None\n",
      "Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_Model = 50\n",
      "GlobalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=50, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=50, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=50, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=50, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "GlobalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=50, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=50, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=50, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=50, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "LocalSelfAttn: None\n",
      "LocalCrossAttn: None\n",
      "Using Embedding: temporal\n",
      "Time Emb Dim: 6\n",
      "Space Embedding: True\n",
      "Time Embedding: True\n",
      "Val Embedding: True\n",
      "Given Embedding: True\n",
      "Null Value: None\n",
      "Pad Value: None\n",
      "Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0\n",
      "D_Model = 50\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/musdb/configs/mus.yaml\n",
      "[\u001b[36m08-18 21:49:06\u001b[0m][\u001b[34mdemucs.train\u001b[0m][\u001b[32mINFO\u001b[0m] - train/valid set size: 18626 14\u001b[0m\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "[\u001b[36m08-18 21:49:06\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading checkpoint model: /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/22d99e8f/checkpoint.th\u001b[0m\n",
      "[\u001b[36m08-18 21:49:08\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Replaying metrics from previous run\u001b[0m\n",
      "[\u001b[36m08-18 21:49:08\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 1 | Loss=0.1813 | Reco=0.1801 | Grad=0.1106 | Penalty=118.9137\u001b[0m\n",
      "[\u001b[36m08-18 21:49:08\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 1 | Loss=0.2333 | Reco=0.2333 | Nsdr=3.094 | Best=0.2333 | Bname=ema_epoch_0 | Penalty=146.4605\u001b[0m\n",
      "[\u001b[36m08-18 21:49:08\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 2 | Loss=0.1470 | Reco=0.1456 | Grad=0.1276 | Penalty=140.5720\u001b[0m\n",
      "[\u001b[36m08-18 21:49:08\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 2 | Loss=0.2075 | Reco=0.2075 | Nsdr=4.034 | Best=0.2075 | Bname=ema_batch_0 | Penalty=137.6151\u001b[0m\n",
      "[\u001b[36m08-18 21:49:08\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - ----------------------------------------------------------------------\u001b[0m\n",
      "[\u001b[36m08-18 21:49:08\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Training...\u001b[0m\n",
      "[\u001b[36m08-18 22:34:07\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 3 | 1164/4656 | 0.43 it/sec | Loss 0.1385 | Reco 0.1371 | Grad 0.1200 | Penalty 138.1785\u001b[0m\n",
      "[\u001b[36m08-18 23:18:57\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 3 | 2328/4656 | 0.43 it/sec | Loss 0.1387 | Reco 0.1373 | Grad 0.1219 | Penalty 142.2917\u001b[0m\n",
      "[\u001b[36m08-19 00:03:31\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 3 | 3492/4656 | 0.43 it/sec | Loss 0.1374 | Reco 0.1360 | Grad 0.1206 | Penalty 144.9306\u001b[0m\n",
      "[\u001b[36m08-19 00:47:59\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 3 | Loss=0.1367 | Reco=0.1352 | Grad=0.1180 | Penalty=146.1080\u001b[0m\n",
      "[\u001b[36m08-19 00:47:59\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - ----------------------------------------------------------------------\u001b[0m\n",
      "[\u001b[36m08-19 00:47:59\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Cross validation...\u001b[0m\n",
      "[\u001b[36m08-19 00:48:47\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 3/14 | 11.7 sec/it | Loss 0.2234 | Reco 0.2234 | Nsdr 3.400\u001b[0m\n",
      "[\u001b[36m08-19 00:49:01\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 6/14 | 0.11 it/sec | Loss 0.2036 | Reco 0.2036 | Nsdr 3.893\u001b[0m\n",
      "[\u001b[36m08-19 00:49:20\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 9/14 | 0.12 it/sec | Loss 0.2051 | Reco 0.2051 | Nsdr 4.082\u001b[0m\n",
      "[\u001b[36m08-19 00:49:36\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 12/14 | 0.14 it/sec | Loss 0.2061 | Reco 0.2061 | Nsdr 4.079\u001b[0m\n",
      "[\u001b[36m08-19 00:50:28\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 3/14 | 10.7 sec/it | Loss 0.2104 | Reco 0.2104 | Nsdr 3.940\u001b[0m\n",
      "[\u001b[36m08-19 00:50:42\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 6/14 | 0.12 it/sec | Loss 0.1938 | Reco 0.1938 | Nsdr 4.326\u001b[0m\n",
      "[\u001b[36m08-19 00:51:01\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 9/14 | 0.13 it/sec | Loss 0.1952 | Reco 0.1952 | Nsdr 4.527\u001b[0m\n",
      "[\u001b[36m08-19 00:51:17\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 12/14 | 0.14 it/sec | Loss 0.1976 | Reco 0.1976 | Nsdr 4.476\u001b[0m\n",
      "[\u001b[36m08-19 00:52:08\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 3/14 | 10.6 sec/it | Loss 0.2247 | Reco 0.2247 | Nsdr 3.447\u001b[0m\n",
      "[\u001b[36m08-19 00:52:22\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 6/14 | 0.12 it/sec | Loss 0.2097 | Reco 0.2097 | Nsdr 3.777\u001b[0m\n",
      "[\u001b[36m08-19 00:52:41\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 9/14 | 0.13 it/sec | Loss 0.2144 | Reco 0.2144 | Nsdr 3.837\u001b[0m\n",
      "[\u001b[36m08-19 00:52:57\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 12/14 | 0.14 it/sec | Loss 0.2183 | Reco 0.2183 | Nsdr 3.758\u001b[0m\n",
      "[\u001b[36m08-19 00:53:46\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 3/14 | 10.1 sec/it | Loss 0.2228 | Reco 0.2228 | Nsdr 3.543\u001b[0m\n",
      "[\u001b[36m08-19 00:54:00\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 6/14 | 0.13 it/sec | Loss 0.2040 | Reco 0.2040 | Nsdr 3.976\u001b[0m\n",
      "[\u001b[36m08-19 00:54:20\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 9/14 | 0.14 it/sec | Loss 0.2062 | Reco 0.2062 | Nsdr 4.122\u001b[0m\n",
      "[\u001b[36m08-19 00:54:35\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 12/14 | 0.15 it/sec | Loss 0.2082 | Reco 0.2082 | Nsdr 4.095\u001b[0m\n",
      "[\u001b[36m08-19 00:55:26\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 3/14 | 10.3 sec/it | Loss 0.2230 | Reco 0.2230 | Nsdr 3.534\u001b[0m\n",
      "[\u001b[36m08-19 00:55:40\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 6/14 | 0.13 it/sec | Loss 0.2044 | Reco 0.2044 | Nsdr 3.963\u001b[0m\n",
      "[\u001b[36m08-19 00:55:59\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 9/14 | 0.13 it/sec | Loss 0.2067 | Reco 0.2067 | Nsdr 4.109\u001b[0m\n",
      "[\u001b[36m08-19 00:56:15\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 12/14 | 0.14 it/sec | Loss 0.2086 | Reco 0.2086 | Nsdr 4.082\u001b[0m\n",
      "[\u001b[36m08-19 00:56:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 3 | Loss=0.1983 | Reco=0.1983 | Nsdr=4.369 | Best=0.1983 | Bname=ema_batch_0 | Penalty=151.7244\u001b[0m\n",
      "[\u001b[36m08-19 00:56:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mNew best valid loss 0.1983\u001b[0m\n",
      "[\u001b[36m08-19 00:56:31\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - ----------------------------------------------------------------------\u001b[0m\n",
      "[\u001b[36m08-19 00:56:31\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Training...\u001b[0m\n",
      "[\u001b[36m08-19 01:41:27\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 4 | 1164/4656 | 0.43 it/sec | Loss 0.1319 | Reco 0.1303 | Grad 0.1150 | Penalty 159.1007\u001b[0m\n",
      "[\u001b[36m08-19 02:26:13\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 4 | 2328/4656 | 0.43 it/sec | Loss 0.1320 | Reco 0.1304 | Grad 0.1130 | Penalty 158.4735\u001b[0m\n",
      "[\u001b[36m08-19 03:10:53\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 4 | 3492/4656 | 0.43 it/sec | Loss 0.1310 | Reco 0.1294 | Grad 0.1123 | Penalty 157.0404\u001b[0m\n",
      "[\u001b[36m08-19 03:55:32\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 4 | Loss=0.1302 | Reco=0.1287 | Grad=0.1137 | Penalty=157.1738\u001b[0m\n",
      "[\u001b[36m08-19 03:55:32\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - ----------------------------------------------------------------------\u001b[0m\n",
      "[\u001b[36m08-19 03:55:32\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Cross validation...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m08-19 03:56:15\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 3/14 | 10.6 sec/it | Loss 0.2111 | Reco 0.2111 | Nsdr 3.916\u001b[0m\n",
      "[\u001b[36m08-19 03:56:29\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 6/14 | 0.12 it/sec | Loss 0.1927 | Reco 0.1927 | Nsdr 4.346\u001b[0m\n",
      "[\u001b[36m08-19 03:56:48\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 9/14 | 0.13 it/sec | Loss 0.1930 | Reco 0.1930 | Nsdr 4.609\u001b[0m\n",
      "[\u001b[36m08-19 03:57:04\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 12/14 | 0.14 it/sec | Loss 0.1955 | Reco 0.1955 | Nsdr 4.539\u001b[0m\n",
      "[\u001b[36m08-19 03:57:56\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 3/14 | 10.9 sec/it | Loss 0.2031 | Reco 0.2031 | Nsdr 4.225\u001b[0m\n",
      "[\u001b[36m08-19 03:58:10\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 6/14 | 0.12 it/sec | Loss 0.1874 | Reco 0.1874 | Nsdr 4.601\u001b[0m\n",
      "[\u001b[36m08-19 03:58:30\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 9/14 | 0.13 it/sec | Loss 0.1881 | Reco 0.1881 | Nsdr 4.835\u001b[0m\n",
      "[\u001b[36m08-19 03:58:45\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 12/14 | 0.14 it/sec | Loss 0.1908 | Reco 0.1908 | Nsdr 4.764\u001b[0m\n",
      "[\u001b[36m08-19 03:59:36\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 3/14 | 10.5 sec/it | Loss 0.2150 | Reco 0.2150 | Nsdr 3.813\u001b[0m\n",
      "[\u001b[36m08-19 03:59:50\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 6/14 | 0.12 it/sec | Loss 0.1995 | Reco 0.1995 | Nsdr 4.186\u001b[0m\n",
      "[\u001b[36m08-19 04:00:10\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 9/14 | 0.13 it/sec | Loss 0.2032 | Reco 0.2032 | Nsdr 4.271\u001b[0m\n",
      "[\u001b[36m08-19 04:00:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 12/14 | 0.14 it/sec | Loss 0.2063 | Reco 0.2063 | Nsdr 4.208\u001b[0m\n",
      "[\u001b[36m08-19 04:01:16\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 3/14 | 10.4 sec/it | Loss 0.2175 | Reco 0.2175 | Nsdr 3.726\u001b[0m\n",
      "[\u001b[36m08-19 04:01:30\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 6/14 | 0.13 it/sec | Loss 0.1989 | Reco 0.1989 | Nsdr 4.184\u001b[0m\n",
      "[\u001b[36m08-19 04:01:50\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 9/14 | 0.13 it/sec | Loss 0.2014 | Reco 0.2014 | Nsdr 4.317\u001b[0m\n",
      "[\u001b[36m08-19 04:02:05\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 12/14 | 0.14 it/sec | Loss 0.2036 | Reco 0.2036 | Nsdr 4.280\u001b[0m\n",
      "[\u001b[36m08-19 04:02:55\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 3/14 | 10.2 sec/it | Loss 0.2182 | Reco 0.2182 | Nsdr 3.700\u001b[0m\n",
      "[\u001b[36m08-19 04:03:09\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 6/14 | 0.13 it/sec | Loss 0.1996 | Reco 0.1996 | Nsdr 4.159\u001b[0m\n",
      "[\u001b[36m08-19 04:03:29\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 9/14 | 0.13 it/sec | Loss 0.2022 | Reco 0.2022 | Nsdr 4.291\u001b[0m\n",
      "[\u001b[36m08-19 04:03:44\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 12/14 | 0.14 it/sec | Loss 0.2043 | Reco 0.2043 | Nsdr 4.255\u001b[0m\n",
      "[\u001b[36m08-19 04:03:54\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 4 | Loss=0.1920 | Reco=0.1920 | Nsdr=4.632 | Best=0.1920 | Bname=ema_batch_0 | Penalty=157.1259\u001b[0m\n",
      "[\u001b[36m08-19 04:03:54\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mNew best valid loss 0.1920\u001b[0m\n",
      "[\u001b[36m08-19 04:04:00\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - ----------------------------------------------------------------------\u001b[0m\n",
      "[\u001b[36m08-19 04:04:00\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Training...\u001b[0m\n",
      "[\u001b[36m08-19 04:48:54\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 5 | 1164/4656 | 0.43 it/sec | Loss 0.1273 | Reco 0.1256 | Grad 0.1184 | Penalty 166.5218\u001b[0m\n",
      "[\u001b[36m08-19 05:33:36\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 5 | 2328/4656 | 0.43 it/sec | Loss 0.1269 | Reco 0.1253 | Grad 0.1152 | Penalty 163.5513\u001b[0m\n",
      "[\u001b[36m08-19 06:18:27\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 5 | 3492/4656 | 0.43 it/sec | Loss 0.1268 | Reco 0.1252 | Grad 0.1141 | Penalty 163.8613\u001b[0m\n",
      "[\u001b[36m08-19 07:03:11\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 5 | Loss=0.1262 | Reco=0.1246 | Grad=0.1134 | Penalty=165.7965\u001b[0m\n",
      "[\u001b[36m08-19 07:03:11\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - ----------------------------------------------------------------------\u001b[0m\n",
      "[\u001b[36m08-19 07:03:11\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Cross validation...\u001b[0m\n",
      "[\u001b[36m08-19 07:03:53\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 3/14 | 10.4 sec/it | Loss 0.2059 | Reco 0.2059 | Nsdr 4.106\u001b[0m\n",
      "[\u001b[36m08-19 07:04:07\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 6/14 | 0.13 it/sec | Loss 0.1888 | Reco 0.1888 | Nsdr 4.540\u001b[0m\n",
      "[\u001b[36m08-19 07:04:27\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 9/14 | 0.13 it/sec | Loss 0.1889 | Reco 0.1889 | Nsdr 4.794\u001b[0m\n",
      "[\u001b[36m08-19 07:04:43\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 12/14 | 0.14 it/sec | Loss 0.1916 | Reco 0.1916 | Nsdr 4.724\u001b[0m\n",
      "[\u001b[36m08-19 07:05:33\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 3/14 | 10.5 sec/it | Loss 0.1984 | Reco 0.1984 | Nsdr 4.404\u001b[0m\n",
      "[\u001b[36m08-19 07:05:47\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 6/14 | 0.13 it/sec | Loss 0.1831 | Reco 0.1831 | Nsdr 4.798\u001b[0m\n",
      "[\u001b[36m08-19 07:06:07\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 9/14 | 0.13 it/sec | Loss 0.1836 | Reco 0.1836 | Nsdr 5.041\u001b[0m\n",
      "[\u001b[36m08-19 07:06:23\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 12/14 | 0.14 it/sec | Loss 0.1862 | Reco 0.1862 | Nsdr 4.974\u001b[0m\n",
      "[\u001b[36m08-19 07:07:13\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 3/14 | 10.2 sec/it | Loss 0.2076 | Reco 0.2076 | Nsdr 4.098\u001b[0m\n",
      "[\u001b[36m08-19 07:07:27\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 6/14 | 0.13 it/sec | Loss 0.1921 | Reco 0.1921 | Nsdr 4.491\u001b[0m\n",
      "[\u001b[36m08-19 07:07:46\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 9/14 | 0.13 it/sec | Loss 0.1949 | Reco 0.1949 | Nsdr 4.617\u001b[0m\n",
      "[\u001b[36m08-19 07:08:02\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 12/14 | 0.14 it/sec | Loss 0.1977 | Reco 0.1977 | Nsdr 4.551\u001b[0m\n",
      "[\u001b[36m08-19 07:08:51\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 3/14 | 10.1 sec/it | Loss 0.2131 | Reco 0.2131 | Nsdr 3.893\u001b[0m\n",
      "[\u001b[36m08-19 07:09:05\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 6/14 | 0.13 it/sec | Loss 0.1950 | Reco 0.1950 | Nsdr 4.354\u001b[0m\n",
      "[\u001b[36m08-19 07:09:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 9/14 | 0.14 it/sec | Loss 0.1974 | Reco 0.1974 | Nsdr 4.491\u001b[0m\n",
      "[\u001b[36m08-19 07:09:41\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 12/14 | 0.15 it/sec | Loss 0.1997 | Reco 0.1997 | Nsdr 4.445\u001b[0m\n",
      "[\u001b[36m08-19 07:10:31\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 3/14 | 10.4 sec/it | Loss 0.2140 | Reco 0.2140 | Nsdr 3.856\u001b[0m\n",
      "[\u001b[36m08-19 07:10:45\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 6/14 | 0.13 it/sec | Loss 0.1960 | Reco 0.1960 | Nsdr 4.311\u001b[0m\n",
      "[\u001b[36m08-19 07:11:05\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 9/14 | 0.13 it/sec | Loss 0.1986 | Reco 0.1986 | Nsdr 4.443\u001b[0m\n",
      "[\u001b[36m08-19 07:11:20\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 12/14 | 0.14 it/sec | Loss 0.2009 | Reco 0.2009 | Nsdr 4.399\u001b[0m\n",
      "[\u001b[36m08-19 07:11:30\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 5 | Loss=0.1880 | Reco=0.1880 | Nsdr=4.817 | Best=0.1880 | Bname=ema_batch_0 | Penalty=168.3915\u001b[0m\n",
      "[\u001b[36m08-19 07:11:30\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mNew best valid loss 0.1880\u001b[0m\n",
      "[\u001b[36m08-19 07:11:36\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - ----------------------------------------------------------------------\u001b[0m\n",
      "[\u001b[36m08-19 07:11:36\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Training...\u001b[0m\n",
      "^C\n",
      "\u001b[1mExecutor:\u001b[0m Received keyboard interrupt, trying to kill all workers.\n"
     ]
    }
   ],
   "source": [
    "#setup d_model = 50\n",
    "!tar xvf outputs.tar.gz\n",
    "\n",
    "!dora run -d -f 81de367c batch_size=4 dset.segment=8 hdemucs.channels=24 test.workers= epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc103997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs/\n",
      "outputs/xps/\n",
      "outputs/xps/e444734f/\n",
      "outputs/xps/cfa93e08/\n",
      "outputs/xps/e51eebcc/\n",
      "outputs/xps/e312f349/\n",
      "outputs/xps/b141dad5/\n",
      "outputs/xps/f435b96e/\n",
      "outputs/xps/80a68df8/\n",
      "outputs/xps/87a4323f/\n",
      "outputs/xps/5d2d6c55/\n",
      "outputs/xps/7ecf8ec1/\n",
      "outputs/xps/7d865c68/\n",
      "outputs/xps/c511e2ab/\n",
      "outputs/xps/c24d4b58/\n",
      "outputs/xps/2cfe4564/\n",
      "outputs/xps/81de367c/\n",
      "outputs/xps/9357e12e/\n",
      "outputs/xps/76a5c33b/\n",
      "outputs/xps/8e19e553/\n",
      "outputs/xps/269b2268/\n",
      "outputs/xps/1b7b2b14/\n",
      "outputs/xps/a1d90b5c/\n",
      "outputs/xps/0d19c1c6/\n",
      "outputs/xps/3d21764b/\n",
      "outputs/xps/3d21764b/.argv.json\n",
      "outputs/xps/0d19c1c6/.argv.json\n",
      "outputs/xps/a1d90b5c/.argv.json\n",
      "outputs/xps/1b7b2b14/.argv.json\n",
      "outputs/xps/269b2268/.argv.json\n",
      "outputs/xps/8e19e553/.argv.json\n",
      "outputs/xps/76a5c33b/.argv.json\n",
      "outputs/xps/9357e12e/.argv.json\n",
      "outputs/xps/81de367c/.argv.json\n",
      "outputs/xps/2cfe4564/.argv.json\n",
      "outputs/xps/c24d4b58/.argv.json\n",
      "outputs/xps/c511e2ab/.argv.json\n",
      "outputs/xps/7d865c68/.argv.json\n",
      "outputs/xps/7ecf8ec1/.argv.json\n",
      "outputs/xps/5d2d6c55/.argv.json\n",
      "outputs/xps/87a4323f/.argv.json\n",
      "outputs/xps/80a68df8/.argv.json\n",
      "outputs/xps/f435b96e/.argv.json\n",
      "outputs/xps/b141dad5/.argv.json\n",
      "outputs/xps/e312f349/.argv.json\n",
      "outputs/xps/e51eebcc/.argv.json\n",
      "outputs/xps/cfa93e08/.argv.json\n",
      "outputs/xps/e444734f/.argv.json\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "\u001b[1mParser\u001b[0m Injecting argv ['hdemucs.norm_starts=999', 'hdemucs.cac=False', 'test.split=True', 'valid_apply=True', 'model=hdemucs', 'hdemucs.dconv_lstm=4', 'ema.epoch=[0.9, 0.95]', 'ema.batch=[0.9995, 0.9999]', 'seed=42', 'hdemucs.hybrid_old=True', 'svd=base', 'svd.penalty=1e-05', 'svd.dim=100', 'svd.convtr=True', 'optim.lr=0.0005'] from sig 81de367c\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "\u001b[1mLaunch:\u001b[0m Removing existing XP folder.\n",
      "\u001b[1mExecutor:\u001b[0m Starting 1 worker processes for DDP.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:228: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  return hydra.main(\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[\u001b[36m08-19 08:04:54\u001b[0m][\u001b[34mdemucs.train\u001b[0m][\u001b[32mINFO\u001b[0m] - For logs, checkpoints and samples check /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/22d99e8f\u001b[0m\n",
      "[\u001b[36m08-19 08:04:54\u001b[0m][\u001b[34mdora.distrib\u001b[0m][\u001b[32mINFO\u001b[0m] - world_size is 1, skipping init.\u001b[0m\n",
      "GlobalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "GlobalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "LocalSelfAttn: None\n",
      "LocalCrossAttn: None\n",
      "Using Embedding: temporal\n",
      "Time Emb Dim: 6\n",
      "Space Embedding: True\n",
      "Time Embedding: True\n",
      "Val Embedding: True\n",
      "Given Embedding: True\n",
      "Null Value: None\n",
      "Pad Value: None\n",
      "Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0\n",
      "D_Model = 100\n",
      "d_layers=2\n",
      "GlobalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "GlobalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "LocalSelfAttn: None\n",
      "LocalCrossAttn: None\n",
      "Using Embedding: temporal\n",
      "Time Emb Dim: 6\n",
      "Space Embedding: True\n",
      "Time Embedding: True\n",
      "Val Embedding: True\n",
      "Given Embedding: True\n",
      "Null Value: None\n",
      "Pad Value: None\n",
      "Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0\n",
      "D_Model = 100\n",
      "d_layers=2\n",
      "GlobalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "GlobalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "LocalSelfAttn: None\n",
      "LocalCrossAttn: None\n",
      "Using Embedding: temporal\n",
      "Time Emb Dim: 6\n",
      "Space Embedding: True\n",
      "Time Embedding: True\n",
      "Val Embedding: True\n",
      "Given Embedding: True\n",
      "Null Value: None\n",
      "Pad Value: None\n",
      "Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0\n",
      "D_Model = 100\n",
      "d_layers=2\n",
      "GlobalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "GlobalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "LocalSelfAttn: None\n",
      "LocalCrossAttn: None\n",
      "Using Embedding: temporal\n",
      "Time Emb Dim: 6\n",
      "Space Embedding: True\n",
      "Time Embedding: True\n",
      "Val Embedding: True\n",
      "Given Embedding: True\n",
      "Null Value: None\n",
      "Pad Value: None\n",
      "Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_Model = 100\n",
      "d_layers=2\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/musdb/configs/mus.yaml\n",
      "[\u001b[36m08-19 08:04:58\u001b[0m][\u001b[34mdemucs.train\u001b[0m][\u001b[32mINFO\u001b[0m] - train/valid set size: 18626 14\u001b[0m\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "[\u001b[36m08-19 08:04:58\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - ----------------------------------------------------------------------\u001b[0m\n",
      "[\u001b[36m08-19 08:04:58\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Training...\u001b[0m\n",
      "[\u001b[36m08-19 08:48:29\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 1 | 1164/4656 | 0.45 it/sec | Loss 0.2049 | Reco 0.2037 | Grad 0.0978 | Penalty 113.5499\u001b[0m\n",
      "[\u001b[36m08-19 09:32:09\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 1 | 2328/4656 | 0.45 it/sec | Loss 0.1948 | Reco 0.1936 | Grad 0.0994 | Penalty 117.6548\u001b[0m\n",
      "[\u001b[36m08-19 10:15:34\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 1 | 3492/4656 | 0.45 it/sec | Loss 0.1885 | Reco 0.1874 | Grad 0.1037 | Penalty 113.8409\u001b[0m\n",
      "[\u001b[36m08-19 10:59:06\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 1 | Loss=0.1829 | Reco=0.1817 | Grad=0.1089 | Penalty=118.4762\u001b[0m\n",
      "[\u001b[36m08-19 10:59:06\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - ----------------------------------------------------------------------\u001b[0m\n",
      "[\u001b[36m08-19 10:59:06\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Cross validation...\u001b[0m\n",
      "[\u001b[36m08-19 10:59:52\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 1 | 3/14 | 11.4 sec/it | Loss 0.2425 | Reco 0.2425 | Nsdr 2.803\u001b[0m\n",
      "[\u001b[36m08-19 11:00:06\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 1 | 6/14 | 0.12 it/sec | Loss 0.2312 | Reco 0.2312 | Nsdr 2.943\u001b[0m\n",
      "[\u001b[36m08-19 11:00:26\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 1 | 9/14 | 0.13 it/sec | Loss 0.2331 | Reco 0.2331 | Nsdr 3.110\u001b[0m\n",
      "[\u001b[36m08-19 11:00:41\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 1 | 12/14 | 0.14 it/sec | Loss 0.2348 | Reco 0.2348 | Nsdr 3.134\u001b[0m\n",
      "[\u001b[36m08-19 11:01:37\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 1 | 3/14 | 11.7 sec/it | Loss 0.2521 | Reco 0.2521 | Nsdr 2.472\u001b[0m\n",
      "[\u001b[36m08-19 11:01:51\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 1 | 6/14 | 0.12 it/sec | Loss 0.2346 | Reco 0.2346 | Nsdr 2.831\u001b[0m\n",
      "[\u001b[36m08-19 11:02:11\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 1 | 9/14 | 0.12 it/sec | Loss 0.2394 | Reco 0.2394 | Nsdr 2.897\u001b[0m\n",
      "[\u001b[36m08-19 11:02:27\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 1 | 12/14 | 0.13 it/sec | Loss 0.2446 | Reco 0.2446 | Nsdr 2.790\u001b[0m\n",
      "[\u001b[36m08-19 11:03:20\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 1 | 3/14 | 11.0 sec/it | Loss 0.2623 | Reco 0.2623 | Nsdr 2.093\u001b[0m\n",
      "[\u001b[36m08-19 11:03:34\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 1 | 6/14 | 0.12 it/sec | Loss 0.2428 | Reco 0.2428 | Nsdr 2.510\u001b[0m\n",
      "[\u001b[36m08-19 11:03:54\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 1 | 9/14 | 0.13 it/sec | Loss 0.2495 | Reco 0.2495 | Nsdr 2.525\u001b[0m\n",
      "[\u001b[36m08-19 11:04:09\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 1 | 12/14 | 0.14 it/sec | Loss 0.2552 | Reco 0.2552 | Nsdr 2.397\u001b[0m\n",
      "[\u001b[36m08-19 11:05:03\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 1 | 3/14 | 11.2 sec/it | Loss 0.2424 | Reco 0.2424 | Nsdr 2.804\u001b[0m\n",
      "[\u001b[36m08-19 11:05:17\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 1 | 6/14 | 0.12 it/sec | Loss 0.2311 | Reco 0.2311 | Nsdr 2.948\u001b[0m\n",
      "[\u001b[36m08-19 11:05:37\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 1 | 9/14 | 0.13 it/sec | Loss 0.2330 | Reco 0.2330 | Nsdr 3.114\u001b[0m\n",
      "[\u001b[36m08-19 11:05:52\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 1 | 12/14 | 0.14 it/sec | Loss 0.2347 | Reco 0.2347 | Nsdr 3.138\u001b[0m\n",
      "[\u001b[36m08-19 11:06:46\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 1 | 3/14 | 11.1 sec/it | Loss 0.2425 | Reco 0.2425 | Nsdr 2.801\u001b[0m\n",
      "[\u001b[36m08-19 11:07:01\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 1 | 6/14 | 0.12 it/sec | Loss 0.2312 | Reco 0.2312 | Nsdr 2.941\u001b[0m\n",
      "[\u001b[36m08-19 11:07:21\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 1 | 9/14 | 0.13 it/sec | Loss 0.2331 | Reco 0.2331 | Nsdr 3.111\u001b[0m\n",
      "[\u001b[36m08-19 11:07:36\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 1 | 12/14 | 0.14 it/sec | Loss 0.2347 | Reco 0.2347 | Nsdr 3.136\u001b[0m\n",
      "[\u001b[36m08-19 11:07:46\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 1 | Loss=0.2340 | Reco=0.2340 | Nsdr=3.089 | Best=0.2340 | Bname=ema_epoch_0 | Penalty=138.8992\u001b[0m\n",
      "[\u001b[36m08-19 11:07:46\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mNew best valid loss 0.2340\u001b[0m\n",
      "[\u001b[36m08-19 11:07:48\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - ----------------------------------------------------------------------\u001b[0m\n",
      "[\u001b[36m08-19 11:07:48\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Training...\u001b[0m\n",
      "[\u001b[36m08-19 11:51:21\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 2 | 1164/4656 | 0.45 it/sec | Loss 0.1570 | Reco 0.1556 | Grad 0.1234 | Penalty 135.4673\u001b[0m\n",
      "[\u001b[36m08-19 12:36:03\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 2 | 2328/4656 | 0.44 it/sec | Loss 0.1535 | Reco 0.1522 | Grad 0.1246 | Penalty 133.6295\u001b[0m\n",
      "[\u001b[36m08-19 13:20:34\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 2 | 3492/4656 | 0.44 it/sec | Loss 0.1508 | Reco 0.1495 | Grad 0.1219 | Penalty 133.5703\u001b[0m\n",
      "[\u001b[36m08-19 14:04:12\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 2 | Loss=0.1490 | Reco=0.1477 | Grad=0.1213 | Penalty=134.1384\u001b[0m\n",
      "[\u001b[36m08-19 14:04:12\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - ----------------------------------------------------------------------\u001b[0m\n",
      "[\u001b[36m08-19 14:04:12\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Cross validation...\u001b[0m\n",
      "[\u001b[36m08-19 14:04:55\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 2 | 3/14 | 10.6 sec/it | Loss 0.2306 | Reco 0.2306 | Nsdr 3.212\u001b[0m\n",
      "[\u001b[36m08-19 14:05:09\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 2 | 6/14 | 0.12 it/sec | Loss 0.2202 | Reco 0.2202 | Nsdr 3.327\u001b[0m\n",
      "[\u001b[36m08-19 14:05:28\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 2 | 9/14 | 0.13 it/sec | Loss 0.2192 | Reco 0.2192 | Nsdr 3.608\u001b[0m\n",
      "[\u001b[36m08-19 14:05:44\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 2 | 12/14 | 0.14 it/sec | Loss 0.2190 | Reco 0.2190 | Nsdr 3.658\u001b[0m\n",
      "[\u001b[36m08-19 14:06:36\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 2 | 3/14 | 10.8 sec/it | Loss 0.2203 | Reco 0.2203 | Nsdr 3.590\u001b[0m\n",
      "[\u001b[36m08-19 14:06:50\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 2 | 6/14 | 0.12 it/sec | Loss 0.2050 | Reco 0.2050 | Nsdr 3.902\u001b[0m\n",
      "[\u001b[36m08-19 14:07:09\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 2 | 9/14 | 0.13 it/sec | Loss 0.2076 | Reco 0.2076 | Nsdr 4.056\u001b[0m\n",
      "[\u001b[36m08-19 14:07:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 2 | 12/14 | 0.14 it/sec | Loss 0.2107 | Reco 0.2107 | Nsdr 4.000\u001b[0m\n",
      "[\u001b[36m08-19 14:08:16\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 2 | 3/14 | 10.6 sec/it | Loss 0.2449 | Reco 0.2449 | Nsdr 2.694\u001b[0m\n",
      "[\u001b[36m08-19 14:08:30\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 2 | 6/14 | 0.12 it/sec | Loss 0.2292 | Reco 0.2292 | Nsdr 3.011\u001b[0m\n",
      "[\u001b[36m08-19 14:08:49\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 2 | 9/14 | 0.13 it/sec | Loss 0.2349 | Reco 0.2349 | Nsdr 3.046\u001b[0m\n",
      "[\u001b[36m08-19 14:09:04\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 2 | 12/14 | 0.14 it/sec | Loss 0.2400 | Reco 0.2400 | Nsdr 2.946\u001b[0m\n",
      "[\u001b[36m08-19 14:09:54\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 2 | 3/14 | 10.3 sec/it | Loss 0.2306 | Reco 0.2306 | Nsdr 3.249\u001b[0m\n",
      "[\u001b[36m08-19 14:10:08\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 2 | 6/14 | 0.13 it/sec | Loss 0.2206 | Reco 0.2206 | Nsdr 3.346\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m08-19 14:10:27\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 2 | 9/14 | 0.13 it/sec | Loss 0.2215 | Reco 0.2215 | Nsdr 3.561\u001b[0m\n",
      "[\u001b[36m08-19 14:10:43\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 2 | 12/14 | 0.15 it/sec | Loss 0.2230 | Reco 0.2230 | Nsdr 3.581\u001b[0m\n",
      "[\u001b[36m08-19 14:11:32\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 2 | 3/14 | 10.2 sec/it | Loss 0.2310 | Reco 0.2310 | Nsdr 3.237\u001b[0m\n",
      "[\u001b[36m08-19 14:11:46\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 2 | 6/14 | 0.13 it/sec | Loss 0.2208 | Reco 0.2208 | Nsdr 3.340\u001b[0m\n",
      "[\u001b[36m08-19 14:12:05\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 2 | 9/14 | 0.14 it/sec | Loss 0.2218 | Reco 0.2218 | Nsdr 3.552\u001b[0m\n",
      "[\u001b[36m08-19 14:12:21\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 2 | 12/14 | 0.15 it/sec | Loss 0.2233 | Reco 0.2233 | Nsdr 3.570\u001b[0m\n",
      "[\u001b[36m08-19 14:12:30\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 2 | Loss=0.2108 | Reco=0.2108 | Nsdr=3.915 | Best=0.2108 | Bname=ema_batch_0 | Penalty=138.2845\u001b[0m\n",
      "[\u001b[36m08-19 14:12:30\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mNew best valid loss 0.2108\u001b[0m\n",
      "[\u001b[36m08-19 14:12:36\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - ----------------------------------------------------------------------\u001b[0m\n",
      "[\u001b[36m08-19 14:12:36\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Training...\u001b[0m\n",
      "[\u001b[36m08-19 14:56:12\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 3 | 1164/4656 | 0.45 it/sec | Loss 0.1407 | Reco 0.1393 | Grad 0.1142 | Penalty 138.9367\u001b[0m\n",
      "[\u001b[36m08-19 15:39:46\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 3 | 2328/4656 | 0.45 it/sec | Loss 0.1388 | Reco 0.1374 | Grad 0.1136 | Penalty 140.6505\u001b[0m\n",
      "[\u001b[36m08-19 16:23:21\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 3 | 3492/4656 | 0.45 it/sec | Loss 0.1377 | Reco 0.1363 | Grad 0.1132 | Penalty 140.3619\u001b[0m\n",
      "[\u001b[36m08-19 17:06:44\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 3 | Loss=0.1367 | Reco=0.1353 | Grad=0.1135 | Penalty=140.9547\u001b[0m\n",
      "[\u001b[36m08-19 17:06:44\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - ----------------------------------------------------------------------\u001b[0m\n",
      "[\u001b[36m08-19 17:06:44\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Cross validation...\u001b[0m\n",
      "[\u001b[36m08-19 17:07:27\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 3/14 | 10.6 sec/it | Loss 0.2071 | Reco 0.2071 | Nsdr 3.978\u001b[0m\n",
      "[\u001b[36m08-19 17:07:41\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 6/14 | 0.13 it/sec | Loss 0.1934 | Reco 0.1934 | Nsdr 4.294\u001b[0m\n",
      "[\u001b[36m08-19 17:08:00\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 9/14 | 0.13 it/sec | Loss 0.1960 | Reco 0.1960 | Nsdr 4.466\u001b[0m\n",
      "[\u001b[36m08-19 17:08:15\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 12/14 | 0.14 it/sec | Loss 0.1982 | Reco 0.1982 | Nsdr 4.421\u001b[0m\n",
      "[\u001b[36m08-19 17:09:05\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 3/14 | 10.3 sec/it | Loss 0.2088 | Reco 0.2088 | Nsdr 3.995\u001b[0m\n",
      "[\u001b[36m08-19 17:09:19\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 6/14 | 0.13 it/sec | Loss 0.1931 | Reco 0.1931 | Nsdr 4.359\u001b[0m\n",
      "[\u001b[36m08-19 17:09:38\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 9/14 | 0.13 it/sec | Loss 0.1951 | Reco 0.1951 | Nsdr 4.541\u001b[0m\n",
      "[\u001b[36m08-19 17:09:54\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 12/14 | 0.15 it/sec | Loss 0.1974 | Reco 0.1974 | Nsdr 4.488\u001b[0m\n",
      "[\u001b[36m08-19 17:10:44\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 3/14 | 10.3 sec/it | Loss 0.2284 | Reco 0.2284 | Nsdr 3.302\u001b[0m\n",
      "[\u001b[36m08-19 17:10:58\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 6/14 | 0.13 it/sec | Loss 0.2136 | Reco 0.2136 | Nsdr 3.621\u001b[0m\n",
      "[\u001b[36m08-19 17:11:17\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 9/14 | 0.14 it/sec | Loss 0.2185 | Reco 0.2185 | Nsdr 3.674\u001b[0m\n",
      "[\u001b[36m08-19 17:11:32\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 12/14 | 0.15 it/sec | Loss 0.2225 | Reco 0.2225 | Nsdr 3.597\u001b[0m\n",
      "[\u001b[36m08-19 17:12:21\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 3/14 | 10.1 sec/it | Loss 0.2208 | Reco 0.2208 | Nsdr 3.583\u001b[0m\n",
      "[\u001b[36m08-19 17:12:35\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 6/14 | 0.13 it/sec | Loss 0.2087 | Reco 0.2087 | Nsdr 3.761\u001b[0m\n",
      "[\u001b[36m08-19 17:12:54\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 9/14 | 0.14 it/sec | Loss 0.2106 | Reco 0.2106 | Nsdr 3.948\u001b[0m\n",
      "[\u001b[36m08-19 17:13:10\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 12/14 | 0.15 it/sec | Loss 0.2128 | Reco 0.2128 | Nsdr 3.933\u001b[0m\n",
      "[\u001b[36m08-19 17:14:00\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 3/14 | 10.2 sec/it | Loss 0.2215 | Reco 0.2215 | Nsdr 3.562\u001b[0m\n",
      "[\u001b[36m08-19 17:14:13\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 6/14 | 0.13 it/sec | Loss 0.2097 | Reco 0.2097 | Nsdr 3.724\u001b[0m\n",
      "[\u001b[36m08-19 17:14:32\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 9/14 | 0.14 it/sec | Loss 0.2116 | Reco 0.2116 | Nsdr 3.912\u001b[0m\n",
      "[\u001b[36m08-19 17:14:48\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 3 | 12/14 | 0.15 it/sec | Loss 0.2137 | Reco 0.2137 | Nsdr 3.901\u001b[0m\n",
      "[\u001b[36m08-19 17:14:58\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 3 | Loss=0.1984 | Reco=0.1984 | Nsdr=4.368 | Best=0.1984 | Bname=ema_batch_0 | Penalty=141.1921\u001b[0m\n",
      "[\u001b[36m08-19 17:14:58\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mNew best valid loss 0.1984\u001b[0m\n",
      "[\u001b[36m08-19 17:15:02\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - ----------------------------------------------------------------------\u001b[0m\n",
      "[\u001b[36m08-19 17:15:02\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Training...\u001b[0m\n",
      "[\u001b[36m08-19 17:58:50\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 4 | 1164/4656 | 0.44 it/sec | Loss 0.1329 | Reco 0.1313 | Grad 0.1148 | Penalty 154.4765\u001b[0m\n",
      "[\u001b[36m08-19 18:42:26\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 4 | 2328/4656 | 0.44 it/sec | Loss 0.1317 | Reco 0.1302 | Grad 0.1141 | Penalty 150.4152\u001b[0m\n",
      "[\u001b[36m08-19 19:26:02\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 4 | 3492/4656 | 0.44 it/sec | Loss 0.1311 | Reco 0.1296 | Grad 0.1136 | Penalty 149.6174\u001b[0m\n",
      "[\u001b[36m08-19 20:09:52\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 4 | Loss=0.1304 | Reco=0.1289 | Grad=0.1126 | Penalty=151.3420\u001b[0m\n",
      "[\u001b[36m08-19 20:09:52\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - ----------------------------------------------------------------------\u001b[0m\n",
      "[\u001b[36m08-19 20:09:52\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Cross validation...\u001b[0m\n",
      "[\u001b[36m08-19 20:10:36\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 3/14 | 10.7 sec/it | Loss 0.2036 | Reco 0.2036 | Nsdr 4.182\u001b[0m\n",
      "[\u001b[36m08-19 20:10:50\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 6/14 | 0.12 it/sec | Loss 0.1885 | Reco 0.1885 | Nsdr 4.510\u001b[0m\n",
      "[\u001b[36m08-19 20:11:09\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 9/14 | 0.13 it/sec | Loss 0.1900 | Reco 0.1900 | Nsdr 4.723\u001b[0m\n",
      "[\u001b[36m08-19 20:11:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 12/14 | 0.14 it/sec | Loss 0.1916 | Reco 0.1916 | Nsdr 4.678\u001b[0m\n",
      "[\u001b[36m08-19 20:12:17\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 3/14 | 10.8 sec/it | Loss 0.2000 | Reco 0.2000 | Nsdr 4.321\u001b[0m\n",
      "[\u001b[36m08-19 20:12:31\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 6/14 | 0.12 it/sec | Loss 0.1856 | Reco 0.1856 | Nsdr 4.671\u001b[0m\n",
      "[\u001b[36m08-19 20:12:50\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 9/14 | 0.13 it/sec | Loss 0.1881 | Reco 0.1881 | Nsdr 4.839\u001b[0m\n",
      "[\u001b[36m08-19 20:13:06\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 12/14 | 0.14 it/sec | Loss 0.1901 | Reco 0.1901 | Nsdr 4.789\u001b[0m\n",
      "[\u001b[36m08-19 20:13:56\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 3/14 | 10.4 sec/it | Loss 0.2144 | Reco 0.2144 | Nsdr 3.831\u001b[0m\n",
      "[\u001b[36m08-19 20:14:10\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 6/14 | 0.13 it/sec | Loss 0.2000 | Reco 0.2000 | Nsdr 4.165\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m08-19 20:14:30\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 9/14 | 0.13 it/sec | Loss 0.2043 | Reco 0.2043 | Nsdr 4.243\u001b[0m\n",
      "[\u001b[36m08-19 20:14:45\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 12/14 | 0.14 it/sec | Loss 0.2075 | Reco 0.2075 | Nsdr 4.170\u001b[0m\n",
      "[\u001b[36m08-19 20:15:36\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 3/14 | 10.5 sec/it | Loss 0.2137 | Reco 0.2137 | Nsdr 3.842\u001b[0m\n",
      "[\u001b[36m08-19 20:15:50\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 6/14 | 0.13 it/sec | Loss 0.2000 | Reco 0.2000 | Nsdr 4.137\u001b[0m\n",
      "[\u001b[36m08-19 20:16:09\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 9/14 | 0.13 it/sec | Loss 0.2027 | Reco 0.2027 | Nsdr 4.286\u001b[0m\n",
      "[\u001b[36m08-19 20:16:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 12/14 | 0.14 it/sec | Loss 0.2051 | Reco 0.2051 | Nsdr 4.242\u001b[0m\n",
      "[\u001b[36m08-19 20:17:16\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 3/14 | 10.4 sec/it | Loss 0.2148 | Reco 0.2148 | Nsdr 3.804\u001b[0m\n",
      "[\u001b[36m08-19 20:17:30\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 6/14 | 0.13 it/sec | Loss 0.2014 | Reco 0.2014 | Nsdr 4.075\u001b[0m\n",
      "[\u001b[36m08-19 20:17:49\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 9/14 | 0.13 it/sec | Loss 0.2041 | Reco 0.2041 | Nsdr 4.227\u001b[0m\n",
      "[\u001b[36m08-19 20:18:05\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 12/14 | 0.14 it/sec | Loss 0.2065 | Reco 0.2065 | Nsdr 4.188\u001b[0m\n",
      "[\u001b[36m08-19 20:18:14\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 4 | Loss=0.1915 | Reco=0.1915 | Nsdr=4.653 | Best=0.1915 | Bname=ema_batch_0 | Penalty=151.2920\u001b[0m\n",
      "[\u001b[36m08-19 20:18:14\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mNew best valid loss 0.1915\u001b[0m\n",
      "[\u001b[36m08-19 20:18:24\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - ----------------------------------------------------------------------\u001b[0m\n",
      "[\u001b[36m08-19 20:18:24\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Training...\u001b[0m\n",
      "[\u001b[36m08-19 21:02:07\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 5 | 1164/4656 | 0.44 it/sec | Loss 0.1291 | Reco 0.1276 | Grad 0.1118 | Penalty 151.6367\u001b[0m\n",
      "[\u001b[36m08-19 21:45:45\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 5 | 2328/4656 | 0.44 it/sec | Loss 0.1280 | Reco 0.1264 | Grad 0.1150 | Penalty 153.0315\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#setup d_model = 100,d_layers = 2\n",
    "\n",
    "!tar xvf outputs.tar.gz\n",
    "\n",
    "!dora run --clear -d -f 81de367c batch_size=4 dset.segment=8 hdemucs.channels=24 test.workers= epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d571b52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs/\n",
      "outputs/xps/\n",
      "outputs/xps/e444734f/\n",
      "outputs/xps/cfa93e08/\n",
      "outputs/xps/e51eebcc/\n",
      "outputs/xps/e312f349/\n",
      "outputs/xps/b141dad5/\n",
      "outputs/xps/f435b96e/\n",
      "outputs/xps/80a68df8/\n",
      "outputs/xps/87a4323f/\n",
      "outputs/xps/5d2d6c55/\n",
      "outputs/xps/7ecf8ec1/\n",
      "outputs/xps/7d865c68/\n",
      "outputs/xps/c511e2ab/\n",
      "outputs/xps/c24d4b58/\n",
      "outputs/xps/2cfe4564/\n",
      "outputs/xps/81de367c/\n",
      "outputs/xps/9357e12e/\n",
      "outputs/xps/76a5c33b/\n",
      "outputs/xps/8e19e553/\n",
      "outputs/xps/269b2268/\n",
      "outputs/xps/1b7b2b14/\n",
      "outputs/xps/a1d90b5c/\n",
      "outputs/xps/0d19c1c6/\n",
      "outputs/xps/3d21764b/\n",
      "outputs/xps/3d21764b/.argv.json\n",
      "outputs/xps/0d19c1c6/.argv.json\n",
      "outputs/xps/a1d90b5c/.argv.json\n",
      "outputs/xps/1b7b2b14/.argv.json\n",
      "outputs/xps/269b2268/.argv.json\n",
      "outputs/xps/8e19e553/.argv.json\n",
      "outputs/xps/76a5c33b/.argv.json\n",
      "outputs/xps/9357e12e/.argv.json\n",
      "outputs/xps/81de367c/.argv.json\n",
      "outputs/xps/2cfe4564/.argv.json\n",
      "outputs/xps/c24d4b58/.argv.json\n",
      "outputs/xps/c511e2ab/.argv.json\n",
      "outputs/xps/7d865c68/.argv.json\n",
      "outputs/xps/7ecf8ec1/.argv.json\n",
      "outputs/xps/5d2d6c55/.argv.json\n",
      "outputs/xps/87a4323f/.argv.json\n",
      "outputs/xps/80a68df8/.argv.json\n",
      "outputs/xps/f435b96e/.argv.json\n",
      "outputs/xps/b141dad5/.argv.json\n",
      "outputs/xps/e312f349/.argv.json\n",
      "outputs/xps/e51eebcc/.argv.json\n",
      "outputs/xps/cfa93e08/.argv.json\n",
      "outputs/xps/e444734f/.argv.json\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "\u001b[1mParser\u001b[0m Injecting argv ['hdemucs.norm_starts=999', 'hdemucs.cac=False', 'test.split=True', 'valid_apply=True', 'model=hdemucs', 'hdemucs.dconv_lstm=4', 'ema.epoch=[0.9, 0.95]', 'ema.batch=[0.9995, 0.9999]', 'seed=42', 'hdemucs.hybrid_old=True', 'svd=base', 'svd.penalty=1e-05', 'svd.dim=100', 'svd.convtr=True', 'optim.lr=0.0005'] from sig 81de367c\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "\u001b[1mExecutor:\u001b[0m Starting 1 worker processes for DDP.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:228: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  return hydra.main(\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[\u001b[36m08-21 05:50:38\u001b[0m][\u001b[34mdemucs.train\u001b[0m][\u001b[32mINFO\u001b[0m] - For logs, checkpoints and samples check /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/22d99e8f\u001b[0m\n",
      "[\u001b[36m08-21 05:50:38\u001b[0m][\u001b[34mdora.distrib\u001b[0m][\u001b[32mINFO\u001b[0m] - world_size is 1, skipping init.\u001b[0m\n",
      "GlobalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "GlobalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "LocalSelfAttn: None\n",
      "LocalCrossAttn: None\n",
      "Using Embedding: temporal\n",
      "Time Emb Dim: 6\n",
      "Space Embedding: True\n",
      "Time Embedding: True\n",
      "Val Embedding: True\n",
      "Given Embedding: True\n",
      "Null Value: None\n",
      "Pad Value: None\n",
      "Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0\n",
      "D_Model = 100\n",
      "e_layers=3\n",
      "GlobalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "GlobalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "LocalSelfAttn: None\n",
      "LocalCrossAttn: None\n",
      "Using Embedding: temporal\n",
      "Time Emb Dim: 6\n",
      "Space Embedding: True\n",
      "Time Embedding: True\n",
      "Val Embedding: True\n",
      "Given Embedding: True\n",
      "Null Value: None\n",
      "Pad Value: None\n",
      "Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0\n",
      "D_Model = 100\n",
      "e_layers=3\n",
      "GlobalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "GlobalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "LocalSelfAttn: None\n",
      "LocalCrossAttn: None\n",
      "Using Embedding: temporal\n",
      "Time Emb Dim: 6\n",
      "Space Embedding: True\n",
      "Time Embedding: True\n",
      "Val Embedding: True\n",
      "Given Embedding: True\n",
      "Null Value: None\n",
      "Pad Value: None\n",
      "Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0\n",
      "D_Model = 100\n",
      "e_layers=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GlobalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "GlobalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "LocalSelfAttn: None\n",
      "LocalCrossAttn: None\n",
      "Using Embedding: temporal\n",
      "Time Emb Dim: 6\n",
      "Space Embedding: True\n",
      "Time Embedding: True\n",
      "Val Embedding: True\n",
      "Given Embedding: True\n",
      "Null Value: None\n",
      "Pad Value: None\n",
      "Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0\n",
      "D_Model = 100\n",
      "e_layers=3\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/musdb/configs/mus.yaml\n",
      "[\u001b[36m08-21 05:50:46\u001b[0m][\u001b[34mdemucs.train\u001b[0m][\u001b[32mINFO\u001b[0m] - train/valid set size: 18626 14\u001b[0m\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "[\u001b[36m08-21 05:50:46\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading checkpoint model: /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/22d99e8f/checkpoint.th\u001b[0m\n",
      "[\u001b[36m08-21 05:50:50\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Replaying metrics from previous run\u001b[0m\n",
      "[\u001b[36m08-21 05:50:50\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 1 | Loss=0.1827 | Reco=0.1816 | Grad=0.1089 | Penalty=110.4969\u001b[0m\n",
      "[\u001b[36m08-21 05:50:50\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 1 | Loss=0.2407 | Reco=0.2407 | Nsdr=2.794 | Best=0.2407 | Bname=main | Penalty=119.8113\u001b[0m\n",
      "[\u001b[36m08-21 05:50:50\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 2 | Loss=0.1508 | Reco=0.1495 | Grad=0.1266 | Penalty=129.7709\u001b[0m\n",
      "[\u001b[36m08-21 05:50:50\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 2 | Loss=0.2113 | Reco=0.2113 | Nsdr=3.791 | Best=0.2113 | Bname=main | Penalty=130.5532\u001b[0m\n",
      "[\u001b[36m08-21 05:50:50\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 3 | Loss=0.1384 | Reco=0.1371 | Grad=0.1197 | Penalty=132.8613\u001b[0m\n",
      "[\u001b[36m08-21 05:50:50\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 3 | Loss=0.1984 | Reco=0.1984 | Nsdr=4.361 | Best=0.1984 | Bname=ema_batch_0 | Penalty=135.6760\u001b[0m\n",
      "[\u001b[36m08-21 05:50:50\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 4 | Loss=0.1310 | Reco=0.1295 | Grad=0.1155 | Penalty=145.8887\u001b[0m\n",
      "[\u001b[36m08-21 05:50:50\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 4 | Loss=0.1918 | Reco=0.1918 | Nsdr=4.630 | Best=0.1918 | Bname=ema_batch_0 | Penalty=223.3117\u001b[0m\n",
      "[\u001b[36m08-21 05:50:50\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - ----------------------------------------------------------------------\u001b[0m\n",
      "[\u001b[36m08-21 05:50:50\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Training...\u001b[0m\n",
      "[\u001b[36m08-21 06:36:35\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 5 | 1164/4656 | 0.42 it/sec | Loss 0.1292 | Reco 0.1277 | Grad 0.1133 | Penalty 156.2100\u001b[0m\n",
      "[\u001b[36m08-21 07:22:01\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 5 | 2328/4656 | 0.43 it/sec | Loss 0.1274 | Reco 0.1259 | Grad 0.1128 | Penalty 155.1157\u001b[0m\n",
      "[\u001b[36m08-21 08:07:18\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 5 | 3492/4656 | 0.43 it/sec | Loss 0.1267 | Reco 0.1252 | Grad 0.1140 | Penalty 154.6140\u001b[0m\n",
      "[\u001b[36m08-21 08:52:33\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 5 | Loss=0.1266 | Reco=0.1250 | Grad=0.1144 | Penalty=154.3063\u001b[0m\n",
      "[\u001b[36m08-21 08:52:33\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - ----------------------------------------------------------------------\u001b[0m\n",
      "[\u001b[36m08-21 08:52:33\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Cross validation...\u001b[0m\n",
      "[\u001b[36m08-21 08:53:21\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 3/14 | 11.7 sec/it | Loss 0.1965 | Reco 0.1965 | Nsdr 4.441\u001b[0m\n",
      "[\u001b[36m08-21 08:53:35\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 6/14 | 0.11 it/sec | Loss 0.1843 | Reco 0.1843 | Nsdr 4.720\u001b[0m\n",
      "[\u001b[36m08-21 08:53:56\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 9/14 | 0.12 it/sec | Loss 0.1864 | Reco 0.1864 | Nsdr 4.897\u001b[0m\n",
      "[\u001b[36m08-21 08:54:12\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 12/14 | 0.13 it/sec | Loss 0.1878 | Reco 0.1878 | Nsdr 4.873\u001b[0m\n",
      "[\u001b[36m08-21 08:55:09\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 3/14 | 11.9 sec/it | Loss 0.1972 | Reco 0.1972 | Nsdr 4.431\u001b[0m\n",
      "[\u001b[36m08-21 08:55:24\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 6/14 | 0.11 it/sec | Loss 0.1824 | Reco 0.1824 | Nsdr 4.822\u001b[0m\n",
      "[\u001b[36m08-21 08:55:44\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 9/14 | 0.12 it/sec | Loss 0.1841 | Reco 0.1841 | Nsdr 5.013\u001b[0m\n",
      "[\u001b[36m08-21 08:56:01\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 12/14 | 0.13 it/sec | Loss 0.1860 | Reco 0.1860 | Nsdr 4.964\u001b[0m\n",
      "[\u001b[36m08-21 08:56:54\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 3/14 | 11.0 sec/it | Loss 0.2067 | Reco 0.2067 | Nsdr 4.110\u001b[0m\n",
      "[\u001b[36m08-21 08:57:09\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 6/14 | 0.12 it/sec | Loss 0.1919 | Reco 0.1919 | Nsdr 4.486\u001b[0m\n",
      "[\u001b[36m08-21 08:57:30\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 9/14 | 0.13 it/sec | Loss 0.1952 | Reco 0.1952 | Nsdr 4.604\u001b[0m\n",
      "[\u001b[36m08-21 08:57:46\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 12/14 | 0.14 it/sec | Loss 0.1984 | Reco 0.1984 | Nsdr 4.520\u001b[0m\n",
      "[\u001b[36m08-21 08:58:39\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 3/14 | 11.0 sec/it | Loss 0.2077 | Reco 0.2077 | Nsdr 3.996\u001b[0m\n",
      "[\u001b[36m08-21 08:58:54\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 6/14 | 0.12 it/sec | Loss 0.1941 | Reco 0.1941 | Nsdr 4.321\u001b[0m\n",
      "[\u001b[36m08-21 08:59:15\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 9/14 | 0.13 it/sec | Loss 0.1985 | Reco 0.1985 | Nsdr 4.415\u001b[0m\n",
      "[\u001b[36m08-21 08:59:31\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 12/14 | 0.14 it/sec | Loss 0.2029 | Reco 0.2029 | Nsdr 4.312\u001b[0m\n",
      "[\u001b[36m08-21 09:00:24\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 3/14 | 10.9 sec/it | Loss 0.2097 | Reco 0.2097 | Nsdr 3.917\u001b[0m\n",
      "[\u001b[36m08-21 09:00:39\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 6/14 | 0.12 it/sec | Loss 0.1959 | Reco 0.1959 | Nsdr 4.244\u001b[0m\n",
      "[\u001b[36m08-21 09:01:00\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 9/14 | 0.13 it/sec | Loss 0.2006 | Reco 0.2006 | Nsdr 4.329\u001b[0m\n",
      "[\u001b[36m08-21 09:01:17\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 5 | 12/14 | 0.14 it/sec | Loss 0.2051 | Reco 0.2051 | Nsdr 4.229\u001b[0m\n",
      "[\u001b[36m08-21 09:01:27\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 5 | Loss=0.1875 | Reco=0.1875 | Nsdr=4.819 | Best=0.1875 | Bname=ema_batch_0 | Penalty=159.7478\u001b[0m\n",
      "[\u001b[36m08-21 09:01:27\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mNew best valid loss 0.1875\u001b[0m\n",
      "[\u001b[36m08-21 09:01:33\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - ----------------------------------------------------------------------\u001b[0m\n",
      "[\u001b[36m08-21 09:01:33\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Training...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\r\n",
      "    return _run_code(code, main_globals, None,\r\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\r\n",
      "    exec(code, run_globals)\r\n",
      "  File \"/home/paperspace/.local/lib/python3.8/site-packages/dora/__main__.py\", line 172, in <module>\r\n",
      "\u001b[1mExecutor:\u001b[0m Received keyboard interrupt, trying to kill all workers.\r\n"
     ]
    }
   ],
   "source": [
    "#setup d_model = 100,e_layers = 3\n",
    "\n",
    "!tar xvf outputs.tar.gz\n",
    "\n",
    "!dora run -d -f 81de367c batch_size=4 dset.segment=8 hdemucs.channels=24 test.workers= epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3aec03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs/\n",
      "outputs/xps/\n",
      "outputs/xps/e444734f/\n",
      "outputs/xps/cfa93e08/\n",
      "outputs/xps/e51eebcc/\n",
      "outputs/xps/e312f349/\n",
      "outputs/xps/b141dad5/\n",
      "outputs/xps/f435b96e/\n",
      "outputs/xps/80a68df8/\n",
      "outputs/xps/87a4323f/\n",
      "outputs/xps/5d2d6c55/\n",
      "outputs/xps/7ecf8ec1/\n",
      "outputs/xps/7d865c68/\n",
      "outputs/xps/c511e2ab/\n",
      "outputs/xps/c24d4b58/\n",
      "outputs/xps/2cfe4564/\n",
      "outputs/xps/81de367c/\n",
      "outputs/xps/9357e12e/\n",
      "outputs/xps/76a5c33b/\n",
      "outputs/xps/8e19e553/\n",
      "outputs/xps/269b2268/\n",
      "outputs/xps/1b7b2b14/\n",
      "outputs/xps/a1d90b5c/\n",
      "outputs/xps/0d19c1c6/\n",
      "outputs/xps/3d21764b/\n",
      "outputs/xps/3d21764b/.argv.json\n",
      "outputs/xps/0d19c1c6/.argv.json\n",
      "outputs/xps/a1d90b5c/.argv.json\n",
      "outputs/xps/1b7b2b14/.argv.json\n",
      "outputs/xps/269b2268/.argv.json\n",
      "outputs/xps/8e19e553/.argv.json\n",
      "outputs/xps/76a5c33b/.argv.json\n",
      "outputs/xps/9357e12e/.argv.json\n",
      "outputs/xps/81de367c/.argv.json\n",
      "outputs/xps/2cfe4564/.argv.json\n",
      "outputs/xps/c24d4b58/.argv.json\n",
      "outputs/xps/c511e2ab/.argv.json\n",
      "outputs/xps/7d865c68/.argv.json\n",
      "outputs/xps/7ecf8ec1/.argv.json\n",
      "outputs/xps/5d2d6c55/.argv.json\n",
      "outputs/xps/87a4323f/.argv.json\n",
      "outputs/xps/80a68df8/.argv.json\n",
      "outputs/xps/f435b96e/.argv.json\n",
      "outputs/xps/b141dad5/.argv.json\n",
      "outputs/xps/e312f349/.argv.json\n",
      "outputs/xps/e51eebcc/.argv.json\n",
      "outputs/xps/cfa93e08/.argv.json\n",
      "outputs/xps/e444734f/.argv.json\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "\u001b[1mParser\u001b[0m Injecting argv ['hdemucs.norm_starts=999', 'hdemucs.cac=False', 'test.split=True', 'valid_apply=True', 'model=hdemucs', 'hdemucs.dconv_lstm=4', 'ema.epoch=[0.9, 0.95]', 'ema.batch=[0.9995, 0.9999]', 'seed=42', 'hdemucs.hybrid_old=True', 'svd=base', 'svd.penalty=1e-05', 'svd.dim=100', 'svd.convtr=True', 'optim.lr=0.0005'] from sig 81de367c\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "\u001b[1mExecutor:\u001b[0m Starting 1 worker processes for DDP.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:228: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  return hydra.main(\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[\u001b[36m08-23 06:11:02\u001b[0m][\u001b[34mdemucs.train\u001b[0m][\u001b[32mINFO\u001b[0m] - For logs, checkpoints and samples check /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/22d99e8f\u001b[0m\n",
      "[\u001b[36m08-23 06:11:02\u001b[0m][\u001b[34mdora.distrib\u001b[0m][\u001b[32mINFO\u001b[0m] - world_size is 1, skipping init.\u001b[0m\n",
      "GlobalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "GlobalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "LocalSelfAttn: None\n",
      "LocalCrossAttn: None\n",
      "Using Embedding: temporal\n",
      "Time Emb Dim: 6\n",
      "Space Embedding: True\n",
      "Time Embedding: True\n",
      "Val Embedding: True\n",
      "Given Embedding: True\n",
      "Null Value: None\n",
      "Pad Value: None\n",
      "Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0\n",
      "D_Model = 100\n",
      "e_layers=3\n",
      "e_layers=4\n",
      "GlobalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "GlobalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "LocalSelfAttn: None\n",
      "LocalCrossAttn: None\n",
      "Using Embedding: temporal\n",
      "Time Emb Dim: 6\n",
      "Space Embedding: True\n",
      "Time Embedding: True\n",
      "Val Embedding: True\n",
      "Given Embedding: True\n",
      "Null Value: None\n",
      "Pad Value: None\n",
      "Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0\n",
      "D_Model = 100\n",
      "e_layers=3\n",
      "e_layers=4\n",
      "GlobalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "GlobalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "LocalSelfAttn: None\n",
      "LocalCrossAttn: None\n",
      "Using Embedding: temporal\n",
      "Time Emb Dim: 6\n",
      "Space Embedding: True\n",
      "Time Embedding: True\n",
      "Val Embedding: True\n",
      "Given Embedding: True\n",
      "Null Value: None\n",
      "Pad Value: None\n",
      "Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0\n",
      "D_Model = 100\n",
      "e_layers=3\n",
      "e_layers=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GlobalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "GlobalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=240, bias=True)\n",
      "  (out_projection): Linear(in_features=240, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "LocalSelfAttn: None\n",
      "LocalCrossAttn: None\n",
      "Using Embedding: temporal\n",
      "Time Emb Dim: 6\n",
      "Space Embedding: True\n",
      "Time Embedding: True\n",
      "Val Embedding: True\n",
      "Given Embedding: True\n",
      "Null Value: None\n",
      "Pad Value: None\n",
      "Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0\n",
      "D_Model = 100\n",
      "e_layers=3\n",
      "e_layers=4\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/musdb/configs/mus.yaml\n",
      "[\u001b[36m08-23 06:11:11\u001b[0m][\u001b[34mdemucs.train\u001b[0m][\u001b[32mINFO\u001b[0m] - train/valid set size: 18626 14\u001b[0m\n",
      "/home/paperspace/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "[\u001b[36m08-23 06:11:12\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading checkpoint model: /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/22d99e8f/checkpoint.th\u001b[0m\n",
      "[\u001b[36m08-23 06:11:15\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Replaying metrics from previous run\u001b[0m\n",
      "[\u001b[36m08-23 06:11:15\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 1 | Loss=0.1821 | Reco=0.1808 | Grad=0.1121 | Penalty=134.0644\u001b[0m\n",
      "[\u001b[36m08-23 06:11:15\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 1 | Loss=0.2413 | Reco=0.2413 | Nsdr=2.884 | Best=0.2413 | Bname=ema_epoch_1 | Penalty=183.8978\u001b[0m\n",
      "[\u001b[36m08-23 06:11:15\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 2 | Loss=0.1524 | Reco=0.1510 | Grad=0.1267 | Penalty=142.2176\u001b[0m\n",
      "[\u001b[36m08-23 06:11:15\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 2 | Loss=0.2176 | Reco=0.2176 | Nsdr=3.697 | Best=0.2176 | Bname=ema_batch_0 | Penalty=186.4905\u001b[0m\n",
      "[\u001b[36m08-23 06:11:15\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 3 | Loss=0.1385 | Reco=0.1370 | Grad=0.1218 | Penalty=145.5541\u001b[0m\n",
      "[\u001b[36m08-23 06:11:15\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 3 | Loss=0.1999 | Reco=0.1999 | Nsdr=4.332 | Best=0.1999 | Bname=ema_batch_0 | Penalty=149.7616\u001b[0m\n",
      "[\u001b[36m08-23 06:11:15\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - ----------------------------------------------------------------------\u001b[0m\n",
      "[\u001b[36m08-23 06:11:15\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Training...\u001b[0m\n",
      "[\u001b[36m08-23 06:59:36\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 4 | 1164/4656 | 0.40 it/sec | Loss 0.1333 | Reco 0.1318 | Grad 0.1132 | Penalty 152.1529\u001b[0m\n",
      "[\u001b[36m08-23 07:47:44\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 4 | 2328/4656 | 0.40 it/sec | Loss 0.1328 | Reco 0.1313 | Grad 0.1128 | Penalty 149.8284\u001b[0m\n",
      "[\u001b[36m08-23 08:36:07\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 4 | 3492/4656 | 0.40 it/sec | Loss 0.1323 | Reco 0.1308 | Grad 0.1134 | Penalty 149.7794\u001b[0m\n",
      "[\u001b[36m08-23 09:24:19\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mTrain Summary | Epoch 4 | Loss=0.1314 | Reco=0.1299 | Grad=0.1136 | Penalty=150.3730\u001b[0m\n",
      "[\u001b[36m08-23 09:24:19\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - ----------------------------------------------------------------------\u001b[0m\n",
      "[\u001b[36m08-23 09:24:19\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Cross validation...\u001b[0m\n",
      "[\u001b[36m08-23 09:25:09\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 3/14 | 12.4 sec/it | Loss 0.2060 | Reco 0.2060 | Nsdr 4.078\u001b[0m\n",
      "[\u001b[36m08-23 09:25:25\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 6/14 | 0.11 it/sec | Loss 0.1910 | Reco 0.1910 | Nsdr 4.412\u001b[0m\n",
      "[\u001b[36m08-23 09:25:47\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 9/14 | 0.12 it/sec | Loss 0.1934 | Reco 0.1934 | Nsdr 4.583\u001b[0m\n",
      "[\u001b[36m08-23 09:26:04\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 12/14 | 0.12 it/sec | Loss 0.1960 | Reco 0.1960 | Nsdr 4.515\u001b[0m\n",
      "[\u001b[36m08-23 09:27:03\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 3/14 | 12.1 sec/it | Loss 0.2027 | Reco 0.2027 | Nsdr 4.217\u001b[0m\n",
      "[\u001b[36m08-23 09:27:19\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 6/14 | 0.11 it/sec | Loss 0.1880 | Reco 0.1880 | Nsdr 4.583\u001b[0m\n",
      "[\u001b[36m08-23 09:27:40\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 9/14 | 0.12 it/sec | Loss 0.1894 | Reco 0.1894 | Nsdr 4.798\u001b[0m\n",
      "[\u001b[36m08-23 09:27:58\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 12/14 | 0.13 it/sec | Loss 0.1916 | Reco 0.1916 | Nsdr 4.741\u001b[0m\n",
      "[\u001b[36m08-23 09:28:54\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 3/14 | 11.7 sec/it | Loss 0.2198 | Reco 0.2198 | Nsdr 3.647\u001b[0m\n",
      "[\u001b[36m08-23 09:29:10\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 6/14 | 0.11 it/sec | Loss 0.2040 | Reco 0.2040 | Nsdr 4.033\u001b[0m\n",
      "[\u001b[36m08-23 09:29:31\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 9/14 | 0.12 it/sec | Loss 0.2075 | Reco 0.2075 | Nsdr 4.134\u001b[0m\n",
      "[\u001b[36m08-23 09:29:49\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 12/14 | 0.13 it/sec | Loss 0.2107 | Reco 0.2107 | Nsdr 4.071\u001b[0m\n",
      "[\u001b[36m08-23 09:30:46\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 3/14 | 11.7 sec/it | Loss 0.2224 | Reco 0.2224 | Nsdr 3.550\u001b[0m\n",
      "[\u001b[36m08-23 09:31:01\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 6/14 | 0.11 it/sec | Loss 0.2058 | Reco 0.2058 | Nsdr 3.914\u001b[0m\n",
      "[\u001b[36m08-23 09:31:23\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 9/14 | 0.12 it/sec | Loss 0.2090 | Reco 0.2090 | Nsdr 4.032\u001b[0m\n",
      "[\u001b[36m08-23 09:31:40\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 12/14 | 0.13 it/sec | Loss 0.2121 | Reco 0.2121 | Nsdr 3.979\u001b[0m\n",
      "[\u001b[36m08-23 09:32:39\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 3/14 | 12.1 sec/it | Loss 0.2235 | Reco 0.2235 | Nsdr 3.514\u001b[0m\n",
      "[\u001b[36m08-23 09:32:54\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 6/14 | 0.11 it/sec | Loss 0.2071 | Reco 0.2071 | Nsdr 3.866\u001b[0m\n",
      "[\u001b[36m08-23 09:33:16\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 9/14 | 0.12 it/sec | Loss 0.2105 | Reco 0.2105 | Nsdr 3.979\u001b[0m\n",
      "[\u001b[36m08-23 09:33:33\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Valid | Epoch 4 | 12/14 | 0.13 it/sec | Loss 0.2136 | Reco 0.2136 | Nsdr 3.928\u001b[0m\n",
      "[\u001b[36m08-23 09:33:44\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mValid Summary | Epoch 4 | Loss=0.1925 | Reco=0.1925 | Nsdr=4.624 | Best=0.1925 | Bname=ema_batch_0 | Penalty=153.4557\u001b[0m\n",
      "[\u001b[36m08-23 09:33:44\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - \u001b[1mNew best valid loss 0.1925\u001b[0m\n",
      "[\u001b[36m08-23 09:33:52\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - ----------------------------------------------------------------------\u001b[0m\n",
      "[\u001b[36m08-23 09:33:52\u001b[0m][\u001b[34mdemucs.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Training...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#setup d_model = 100,e_layers = 3,d_layers = 4\n",
    "\n",
    "!tar xvf outputs.tar.gz\n",
    "\n",
    "!dora run -d -f 81de367c batch_size=4 dset.segment=8 hdemucs.channels=24 test.workers= epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a972d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a84a970",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
