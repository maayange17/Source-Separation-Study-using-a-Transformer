/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:228: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  return hydra.main(
[[36m08-24 10:06:17[0m][[34mdemucs.train[0m][[32mINFO[0m] - For logs, checkpoints and samples check /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/22d99e8f[0m
[[36m08-24 10:06:17[0m][[34mdora.distrib[0m][[32mINFO[0m] - world_size is 1, skipping init.[0m
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:228: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  return hydra.main(
[[36m08-24 10:06:21[0m][[34mdemucs.train[0m][[32mINFO[0m] - For logs, checkpoints and samples check /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/22d99e8f[0m
[[36m08-24 10:06:21[0m][[34mdora.distrib[0m][[32mINFO[0m] - world_size is 1, skipping init.[0m
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
e_layers=3
e_layers=4
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
e_layers=3
e_layers=4
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
e_layers=3
e_layers=4
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
e_layers=3
e_layers=4
/home/paperspace/.local/lib/python3.8/site-packages/musdb/configs/mus.yaml
[[36m08-24 10:06:22[0m][[34mdemucs.train[0m][[32mINFO[0m] - train/valid set size: 18626 14[0m
[[36m08-24 10:06:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Loading checkpoint model: /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/22d99e8f/checkpoint.th[0m
[[36m08-24 10:06:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Replaying metrics from previous run[0m
[[36m08-24 10:06:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 1 | Loss=0.1821 | Reco=0.1808 | Grad=0.1121 | Penalty=134.0644[0m
[[36m08-24 10:06:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 1 | Loss=0.2413 | Reco=0.2413 | Nsdr=2.884 | Best=0.2413 | Bname=ema_epoch_1 | Penalty=183.8978[0m
[[36m08-24 10:06:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 2 | Loss=0.1524 | Reco=0.1510 | Grad=0.1267 | Penalty=142.2176[0m
[[36m08-24 10:06:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 2 | Loss=0.2176 | Reco=0.2176 | Nsdr=3.697 | Best=0.2176 | Bname=ema_batch_0 | Penalty=186.4905[0m
[[36m08-24 10:06:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 3 | Loss=0.1385 | Reco=0.1370 | Grad=0.1218 | Penalty=145.5541[0m
[[36m08-24 10:06:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 3 | Loss=0.1999 | Reco=0.1999 | Nsdr=4.332 | Best=0.1999 | Bname=ema_batch_0 | Penalty=149.7616[0m
[[36m08-24 10:06:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 4 | Loss=0.1314 | Reco=0.1299 | Grad=0.1136 | Penalty=150.3730[0m
[[36m08-24 10:06:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 4 | Loss=0.1925 | Reco=0.1925 | Nsdr=4.624 | Best=0.1925 | Bname=ema_batch_0 | Penalty=153.4557[0m
[[36m08-24 10:06:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 5 | Loss=0.1257 | Reco=0.1242 | Grad=0.1086 | Penalty=156.4121[0m
[[36m08-24 10:06:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 5 | Loss=0.1879 | Reco=0.1879 | Nsdr=4.822 | Best=0.1879 | Bname=ema_batch_0 | Penalty=157.3792[0m
[[36m08-24 10:06:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 6 | Loss=0.1218 | Reco=0.1202 | Grad=0.1065 | Penalty=161.6284[0m
[[36m08-24 10:06:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 6 | Loss=0.1849 | Reco=0.1849 | Nsdr=4.960 | Best=0.1849 | Bname=ema_batch_0 | Penalty=177.9117[0m
[[36m08-24 10:06:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 7 | Loss=0.1198 | Reco=0.1181 | Grad=0.1065 | Penalty=176.4031[0m
[[36m08-24 10:06:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 7 | Loss=0.1833 | Reco=0.1833 | Nsdr=5.035 | Best=0.1833 | Bname=ema_batch_0 | Penalty=180.9828[0m
[[36m08-24 10:06:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-24 10:06:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
/home/paperspace/.local/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
/home/paperspace/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
e_layers=3
e_layers=4
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
e_layers=3
e_layers=4
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
e_layers=3
e_layers=4
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
e_layers=3
e_layers=4
/home/paperspace/.local/lib/python3.8/site-packages/musdb/configs/mus.yaml
[[36m08-24 10:06:28[0m][[34mdemucs.train[0m][[32mINFO[0m] - train/valid set size: 18626 14[0m
/home/paperspace/.local/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
/home/paperspace/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Error executing job with overrides: ['hdemucs.norm_starts=999', 'hdemucs.cac=False', 'test.split=True', 'valid_apply=True', 'model=hdemucs', 'hdemucs.dconv_lstm=4', 'ema.epoch=[0.9, 0.95]', 'ema.batch=[0.9995, 0.9999]', 'seed=42', 'hdemucs.hybrid_old=True', 'svd=base', 'svd.penalty=1e-05', 'svd.dim=100', 'svd.convtr=True', 'optim.lr=0.0005', 'batch_size=4', 'dset.segment=8', 'hdemucs.channels=24', 'test.workers=', 'epochs=20']
Traceback (most recent call last):
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/train.py", line 148, in main
    solver = get_solver(args)
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/train.py", line 110, in get_solver
    return Solver(loaders, model, optimizer, args)
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/solver.py", line 50, in __init__
    self.emas[kind].append(ModelEMA(self.model, decay, device=device))
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/ema.py", line 32, in __init__
    self._init()
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/ema.py", line 40, in _init
    self.state[key] = val.detach().to(device, copy=True)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 7.94 GiB total capacity; 242.01 MiB already allocated; 1.62 MiB free; 248.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Error executing job with overrides: ['hdemucs.norm_starts=999', 'hdemucs.cac=False', 'test.split=True', 'valid_apply=True', 'model=hdemucs', 'hdemucs.dconv_lstm=4', 'ema.epoch=[0.9, 0.95]', 'ema.batch=[0.9995, 0.9999]', 'seed=42', 'hdemucs.hybrid_old=True', 'svd=base', 'svd.penalty=1e-05', 'svd.dim=100', 'svd.convtr=True', 'optim.lr=0.0005', 'batch_size=4', 'dset.segment=8', 'hdemucs.channels=24', 'test.workers=', 'epochs=20']
Traceback (most recent call last):
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/train.py", line 149, in main
    solver.train()
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/solver.py", line 195, in train
    metrics['train'] = self._run_one_epoch(epoch)
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/solver.py", line 317, in _run_one_epoch
    estimate = self.dmodel(mix)
  File "/home/paperspace/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/hdemucs.py", line 755, in forward
    x = self._ispec(zout, length)
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/hdemucs.py", line 597, in _ispec
    z = F.pad(z, (2, 2))
  File "/home/paperspace/.local/lib/python3.8/site-packages/torch/nn/functional.py", line 4174, in _pad
    return _VF.constant_pad_nd(input, pad, value)
RuntimeError: CUDA out of memory. Tried to allocate 134.00 MiB (GPU 0; 7.94 GiB total capacity; 5.85 GiB already allocated; 37.62 MiB free; 5.95 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mParser[0m Injecting argv ['hdemucs.norm_starts=999', 'hdemucs.cac=False', 'test.split=True', 'valid_apply=True', 'model=hdemucs', 'hdemucs.dconv_lstm=4', 'ema.epoch=[0.9, 0.95]', 'ema.batch=[0.9995, 0.9999]', 'seed=42', 'hdemucs.hybrid_old=True', 'svd=base', 'svd.penalty=1e-05', 'svd.dim=100', 'svd.convtr=True', 'optim.lr=0.0005'] from sig 81de367c
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mExecutor:[0m Starting 1 worker processes for DDP.
[1mExecutor:[0m Worker 0 died, killing all workers
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mParser[0m Injecting argv ['hdemucs.norm_starts=999', 'hdemucs.cac=False', 'test.split=True', 'valid_apply=True', 'model=hdemucs', 'hdemucs.dconv_lstm=4', 'ema.epoch=[0.9, 0.95]', 'ema.batch=[0.9995, 0.9999]', 'seed=42', 'hdemucs.hybrid_old=True', 'svd=base', 'svd.penalty=1e-05', 'svd.dim=100', 'svd.convtr=True', 'optim.lr=0.0005'] from sig 81de367c
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mExecutor:[0m Starting 1 worker processes for DDP.
[1mExecutor:[0m Worker 0 died, killing all workers
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:228: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  return hydra.main(
[[36m08-24 10:07:34[0m][[34mdemucs.train[0m][[32mINFO[0m] - For logs, checkpoints and samples check /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/22d99e8f[0m
[[36m08-24 10:07:34[0m][[34mdora.distrib[0m][[32mINFO[0m] - world_size is 1, skipping init.[0m
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
e_layers=3
e_layers=4
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
e_layers=3
e_layers=4
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
e_layers=3
e_layers=4
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
e_layers=3
e_layers=4
/home/paperspace/.local/lib/python3.8/site-packages/musdb/configs/mus.yaml
[[36m08-24 10:07:38[0m][[34mdemucs.train[0m][[32mINFO[0m] - train/valid set size: 18626 14[0m
[[36m08-24 10:07:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Loading checkpoint model: /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/22d99e8f/checkpoint.th[0m
[[36m08-24 10:07:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Replaying metrics from previous run[0m
[[36m08-24 10:07:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 1 | Loss=0.1821 | Reco=0.1808 | Grad=0.1121 | Penalty=134.0644[0m
[[36m08-24 10:07:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 1 | Loss=0.2413 | Reco=0.2413 | Nsdr=2.884 | Best=0.2413 | Bname=ema_epoch_1 | Penalty=183.8978[0m
[[36m08-24 10:07:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 2 | Loss=0.1524 | Reco=0.1510 | Grad=0.1267 | Penalty=142.2176[0m
[[36m08-24 10:07:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 2 | Loss=0.2176 | Reco=0.2176 | Nsdr=3.697 | Best=0.2176 | Bname=ema_batch_0 | Penalty=186.4905[0m
[[36m08-24 10:07:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 3 | Loss=0.1385 | Reco=0.1370 | Grad=0.1218 | Penalty=145.5541[0m
[[36m08-24 10:07:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 3 | Loss=0.1999 | Reco=0.1999 | Nsdr=4.332 | Best=0.1999 | Bname=ema_batch_0 | Penalty=149.7616[0m
[[36m08-24 10:07:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 4 | Loss=0.1314 | Reco=0.1299 | Grad=0.1136 | Penalty=150.3730[0m
[[36m08-24 10:07:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 4 | Loss=0.1925 | Reco=0.1925 | Nsdr=4.624 | Best=0.1925 | Bname=ema_batch_0 | Penalty=153.4557[0m
[[36m08-24 10:07:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 5 | Loss=0.1257 | Reco=0.1242 | Grad=0.1086 | Penalty=156.4121[0m
[[36m08-24 10:07:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 5 | Loss=0.1879 | Reco=0.1879 | Nsdr=4.822 | Best=0.1879 | Bname=ema_batch_0 | Penalty=157.3792[0m
[[36m08-24 10:07:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 6 | Loss=0.1218 | Reco=0.1202 | Grad=0.1065 | Penalty=161.6284[0m
[[36m08-24 10:07:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 6 | Loss=0.1849 | Reco=0.1849 | Nsdr=4.960 | Best=0.1849 | Bname=ema_batch_0 | Penalty=177.9117[0m
[[36m08-24 10:07:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 7 | Loss=0.1198 | Reco=0.1181 | Grad=0.1065 | Penalty=176.4031[0m
[[36m08-24 10:07:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 7 | Loss=0.1833 | Reco=0.1833 | Nsdr=5.035 | Best=0.1833 | Bname=ema_batch_0 | Penalty=180.9828[0m
[[36m08-24 10:07:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-24 10:07:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
/home/paperspace/.local/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
/home/paperspace/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:228: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  return hydra.main(
[[36m08-24 10:08:05[0m][[34mdemucs.train[0m][[32mINFO[0m] - For logs, checkpoints and samples check /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/22d99e8f[0m
[[36m08-24 10:08:05[0m][[34mdora.distrib[0m][[32mINFO[0m] - world_size is 1, skipping init.[0m
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
/home/paperspace/.local/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
Error executing job with overrides: ['hdemucs.norm_starts=999', 'hdemucs.cac=False', 'test.split=True', 'valid_apply=True', 'model=hdemucs', 'hdemucs.dconv_lstm=4', 'ema.epoch=[0.9, 0.95]', 'ema.batch=[0.9995, 0.9999]', 'seed=42', 'hdemucs.hybrid_old=True', 'svd=base', 'svd.penalty=1e-05', 'svd.dim=100', 'svd.convtr=True', 'optim.lr=0.0005', 'batch_size=4', 'dset.segment=8', 'hdemucs.channels=24', 'test.workers=', 'epochs=20']
Traceback (most recent call last):
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/train.py", line 148, in main
    solver = get_solver(args)
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/train.py", line 48, in get_solver
    model = get_model(args)
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/train.py", line 40, in get_model
    model = klass(**extra, **kw)
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/states.py", line 146, in __init__
    init(self, *args, **kwargs)
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/hdemucs.py", line 524, in __init__
    enc = HEncLayer(chin_z, chout_z,
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/hdemucs.py", line 100, in __init__
    self.dconv = DConv(chout, **dconv_kw)
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/demucs.py", line 167, in __init__
    mods.insert(3, CutSpacetimeformer(hidden))
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/demucs.py", line 247, in __init__
    self.Layer = stf.spacetimeformer_model.nn.model.Spacetimeformer(d_x = 1, d_yc = channels, d_yt = 2*channels, embed_method='temporal',
  File "/home/paperspace/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/home/paperspace/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/home/paperspace/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/home/paperspace/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/home/paperspace/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mParser[0m Injecting argv ['hdemucs.norm_starts=999', 'hdemucs.cac=False', 'test.split=True', 'valid_apply=True', 'model=hdemucs', 'hdemucs.dconv_lstm=4', 'ema.epoch=[0.9, 0.95]', 'ema.batch=[0.9995, 0.9999]', 'seed=42', 'hdemucs.hybrid_old=True', 'svd=base', 'svd.penalty=1e-05', 'svd.dim=100', 'svd.convtr=True', 'optim.lr=0.0005'] from sig 81de367c
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mExecutor:[0m Starting 1 worker processes for DDP.
[1mExecutor:[0m Worker 0 died, killing all workers
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:228: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  return hydra.main(
[[36m08-24 10:08:11[0m][[34mdemucs.train[0m][[32mINFO[0m] - For logs, checkpoints and samples check /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/22d99e8f[0m
[[36m08-24 10:08:11[0m][[34mdora.distrib[0m][[32mINFO[0m] - world_size is 1, skipping init.[0m
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
/home/paperspace/.local/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
Error executing job with overrides: ['hdemucs.norm_starts=999', 'hdemucs.cac=False', 'test.split=True', 'valid_apply=True', 'model=hdemucs', 'hdemucs.dconv_lstm=4', 'ema.epoch=[0.9, 0.95]', 'ema.batch=[0.9995, 0.9999]', 'seed=42', 'hdemucs.hybrid_old=True', 'svd=base', 'svd.penalty=1e-05', 'svd.dim=100', 'svd.convtr=True', 'optim.lr=0.0005', 'batch_size=4', 'dset.segment=8', 'hdemucs.channels=24', 'test.workers=', 'epochs=20']
Traceback (most recent call last):
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/train.py", line 148, in main
    solver = get_solver(args)
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/train.py", line 48, in get_solver
    model = get_model(args)
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/train.py", line 40, in get_model
    model = klass(**extra, **kw)
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/states.py", line 146, in __init__
    init(self, *args, **kwargs)
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/hdemucs.py", line 524, in __init__
    enc = HEncLayer(chin_z, chout_z,
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/hdemucs.py", line 100, in __init__
    self.dconv = DConv(chout, **dconv_kw)
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/demucs.py", line 167, in __init__
    mods.insert(3, CutSpacetimeformer(hidden))
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/demucs.py", line 247, in __init__
    self.Layer = stf.spacetimeformer_model.nn.model.Spacetimeformer(d_x = 1, d_yc = channels, d_yt = 2*channels, embed_method='temporal',
  File "/home/paperspace/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 899, in to
    return self._apply(convert)
  File "/home/paperspace/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/home/paperspace/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 570, in _apply
    module._apply(fn)
  File "/home/paperspace/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 593, in _apply
    param_applied = fn(param)
  File "/home/paperspace/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 897, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mParser[0m Injecting argv ['hdemucs.norm_starts=999', 'hdemucs.cac=False', 'test.split=True', 'valid_apply=True', 'model=hdemucs', 'hdemucs.dconv_lstm=4', 'ema.epoch=[0.9, 0.95]', 'ema.batch=[0.9995, 0.9999]', 'seed=42', 'hdemucs.hybrid_old=True', 'svd=base', 'svd.penalty=1e-05', 'svd.dim=100', 'svd.convtr=True', 'optim.lr=0.0005'] from sig 81de367c
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mExecutor:[0m Starting 1 worker processes for DDP.
[1mExecutor:[0m Worker 0 died, killing all workers
[[36m08-24 10:56:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 8 | 1164/4656 | 0.40 it/sec | Loss 0.1158 | Reco 0.1141 | Grad 0.0975 | Penalty 175.5214[0m
[[36m08-24 11:44:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 8 | 2328/4656 | 0.40 it/sec | Loss 0.1162 | Reco 0.1144 | Grad 0.0978 | Penalty 175.2982[0m
[[36m08-24 12:32:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 8 | 3492/4656 | 0.40 it/sec | Loss 0.1162 | Reco 0.1144 | Grad 0.0989 | Penalty 183.1579[0m
[[36m08-24 13:20:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 8 | Loss=0.1158 | Reco=0.1139 | Grad=0.0993 | Penalty=182.7995[0m
[[36m08-24 13:20:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-24 13:20:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m08-24 13:21:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 11.6 sec/it | Loss 0.2012 | Reco 0.2012 | Nsdr 4.329[0m
[[36m08-24 13:21:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.11 it/sec | Loss 0.1840 | Reco 0.1840 | Nsdr 4.792[0m
[[36m08-24 13:22:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.12 it/sec | Loss 0.1848 | Reco 0.1848 | Nsdr 5.021[0m
[[36m08-24 13:22:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.13 it/sec | Loss 0.1862 | Reco 0.1862 | Nsdr 5.011[0m
[[36m08-24 13:23:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 11.8 sec/it | Loss 0.1904 | Reco 0.1904 | Nsdr 4.735[0m
[[36m08-24 13:23:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.11 it/sec | Loss 0.1771 | Reco 0.1771 | Nsdr 5.087[0m
[[36m08-24 13:24:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.12 it/sec | Loss 0.1782 | Reco 0.1782 | Nsdr 5.305[0m
[[36m08-24 13:24:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.13 it/sec | Loss 0.1792 | Reco 0.1792 | Nsdr 5.286[0m
[[36m08-24 13:25:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 11.1 sec/it | Loss 0.1935 | Reco 0.1935 | Nsdr 4.625[0m
[[36m08-24 13:25:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.12 it/sec | Loss 0.1800 | Reco 0.1800 | Nsdr 4.985[0m
[[36m08-24 13:25:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.12 it/sec | Loss 0.1819 | Reco 0.1819 | Nsdr 5.173[0m
[[36m08-24 13:26:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.13 it/sec | Loss 0.1838 | Reco 0.1838 | Nsdr 5.129[0m
[[36m08-24 13:27:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 11.4 sec/it | Loss 0.2076 | Reco 0.2076 | Nsdr 4.087[0m
[[36m08-24 13:27:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.11 it/sec | Loss 0.1919 | Reco 0.1919 | Nsdr 4.474[0m
[[36m08-24 13:27:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.12 it/sec | Loss 0.1951 | Reco 0.1951 | Nsdr 4.601[0m
[[36m08-24 13:28:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.13 it/sec | Loss 0.1973 | Reco 0.1973 | Nsdr 4.561[0m
[[36m08-24 13:28:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 11.5 sec/it | Loss 0.2102 | Reco 0.2102 | Nsdr 3.994[0m
[[36m08-24 13:29:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.11 it/sec | Loss 0.1944 | Reco 0.1944 | Nsdr 4.371[0m
[[36m08-24 13:29:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.12 it/sec | Loss 0.1978 | Reco 0.1978 | Nsdr 4.488[0m
[[36m08-24 13:29:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.13 it/sec | Loss 0.2002 | Reco 0.2002 | Nsdr 4.446[0m
[[36m08-24 13:30:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 8 | Loss=0.1809 | Reco=0.1809 | Nsdr=5.139 | Best=0.1809 | Bname=ema_batch_0 | Penalty=184.4274[0m
[[36m08-24 13:30:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1809[0m
[[36m08-24 13:30:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-24 13:30:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m08-24 14:18:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 9 | 1164/4656 | 0.40 it/sec | Loss 0.1210 | Reco 0.1191 | Grad 0.1107 | Penalty 190.0772[0m
[[36m08-24 15:07:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 9 | 2328/4656 | 0.40 it/sec | Loss 0.1194 | Reco 0.1175 | Grad 0.1125 | Penalty 191.9382[0m
[[36m08-24 15:58:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 9 | 3492/4656 | 0.39 it/sec | Loss 0.1190 | Reco 0.1171 | Grad 0.1122 | Penalty 192.9591[0m
[[36m08-24 16:47:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 9 | Loss=0.1187 | Reco=0.1167 | Grad=0.1106 | Penalty=197.7084[0m
[[36m08-24 16:47:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-24 16:47:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m08-24 16:48:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 12.1 sec/it | Loss 0.1901 | Reco 0.1901 | Nsdr 4.698[0m
[[36m08-24 16:48:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.11 it/sec | Loss 0.1793 | Reco 0.1793 | Nsdr 4.957[0m
[[36m08-24 16:49:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.12 it/sec | Loss 0.1821 | Reco 0.1821 | Nsdr 5.107[0m
[[36m08-24 16:49:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.13 it/sec | Loss 0.1827 | Reco 0.1827 | Nsdr 5.114[0m
[[36m08-24 16:50:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 11.6 sec/it | Loss 0.1894 | Reco 0.1894 | Nsdr 4.783[0m
[[36m08-24 16:50:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.11 it/sec | Loss 0.1759 | Reco 0.1759 | Nsdr 5.144[0m
[[36m08-24 16:51:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.12 it/sec | Loss 0.1768 | Reco 0.1768 | Nsdr 5.363[0m
[[36m08-24 16:51:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.13 it/sec | Loss 0.1779 | Reco 0.1779 | Nsdr 5.344[0m
[[36m08-24 16:52:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 11.2 sec/it | Loss 0.1912 | Reco 0.1912 | Nsdr 4.717[0m
[[36m08-24 16:52:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.12 it/sec | Loss 0.1779 | Reco 0.1779 | Nsdr 5.074[0m
[[36m08-24 16:52:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.12 it/sec | Loss 0.1798 | Reco 0.1798 | Nsdr 5.258[0m
[[36m08-24 16:53:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.13 it/sec | Loss 0.1815 | Reco 0.1815 | Nsdr 5.223[0m
[[36m08-24 16:54:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 11.1 sec/it | Loss 0.2039 | Reco 0.2039 | Nsdr 4.223[0m
[[36m08-24 16:54:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.12 it/sec | Loss 0.1892 | Reco 0.1892 | Nsdr 4.584[0m
[[36m08-24 16:54:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.12 it/sec | Loss 0.1926 | Reco 0.1926 | Nsdr 4.704[0m
[[36m08-24 16:55:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.13 it/sec | Loss 0.1946 | Reco 0.1946 | Nsdr 4.671[0m
[[36m08-24 16:55:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 11.3 sec/it | Loss 0.2069 | Reco 0.2069 | Nsdr 4.111[0m
[[36m08-24 16:56:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.12 it/sec | Loss 0.1920 | Reco 0.1920 | Nsdr 4.467[0m
[[36m08-24 16:56:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.12 it/sec | Loss 0.1957 | Reco 0.1957 | Nsdr 4.578[0m
[[36m08-24 16:56:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.13 it/sec | Loss 0.1979 | Reco 0.1979 | Nsdr 4.541[0m
[[36m08-24 16:57:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 9 | Loss=0.1792 | Reco=0.1792 | Nsdr=5.211 | Best=0.1792 | Bname=ema_batch_0 | Penalty=201.8311[0m
[[36m08-24 16:57:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1792[0m
[[36m08-24 16:57:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-24 16:57:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m08-24 17:45:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 10 | 1164/4656 | 0.40 it/sec | Loss 0.1175 | Reco 0.1155 | Grad 0.1110 | Penalty 197.4584[0m
[[36m08-24 18:33:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 10 | 2328/4656 | 0.40 it/sec | Loss 0.1170 | Reco 0.1150 | Grad 0.1081 | Penalty 196.8083[0m
[[36m08-24 19:22:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 10 | 3492/4656 | 0.40 it/sec | Loss 0.1162 | Reco 0.1142 | Grad 0.1071 | Penalty 195.5800[0m
[[36m08-24 20:12:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 10 | Loss=0.1163 | Reco=0.1143 | Grad=0.1075 | Penalty=195.5660[0m
[[36m08-24 20:12:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-24 20:12:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m08-24 20:12:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 11.8 sec/it | Loss 0.1930 | Reco 0.1930 | Nsdr 4.628[0m
[[36m08-24 20:13:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 0.11 it/sec | Loss 0.1803 | Reco 0.1803 | Nsdr 4.945[0m
[[36m08-24 20:13:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.12 it/sec | Loss 0.1805 | Reco 0.1805 | Nsdr 5.194[0m
[[36m08-24 20:13:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.13 it/sec | Loss 0.1810 | Reco 0.1810 | Nsdr 5.193[0m
[[36m08-24 20:14:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 12.2 sec/it | Loss 0.1881 | Reco 0.1881 | Nsdr 4.847[0m
[[36m08-24 20:15:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 0.11 it/sec | Loss 0.1747 | Reco 0.1747 | Nsdr 5.199[0m
[[36m08-24 20:15:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.12 it/sec | Loss 0.1755 | Reco 0.1755 | Nsdr 5.425[0m
[[36m08-24 20:15:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.13 it/sec | Loss 0.1763 | Reco 0.1763 | Nsdr 5.416[0m
[[36m08-24 20:16:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 11.3 sec/it | Loss 0.1902 | Reco 0.1902 | Nsdr 4.768[0m
[[36m08-24 20:16:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 0.12 it/sec | Loss 0.1766 | Reco 0.1766 | Nsdr 5.133[0m
[[36m08-24 20:17:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.12 it/sec | Loss 0.1782 | Reco 0.1782 | Nsdr 5.330[0m
[[36m08-24 20:17:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.13 it/sec | Loss 0.1795 | Reco 0.1795 | Nsdr 5.308[0m
[[36m08-24 20:18:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 11.5 sec/it | Loss 0.2015 | Reco 0.2015 | Nsdr 4.324[0m
[[36m08-24 20:18:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 0.11 it/sec | Loss 0.1875 | Reco 0.1875 | Nsdr 4.666[0m
[[36m08-24 20:19:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.12 it/sec | Loss 0.1908 | Reco 0.1908 | Nsdr 4.790[0m
[[36m08-24 20:19:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.13 it/sec | Loss 0.1928 | Reco 0.1928 | Nsdr 4.758[0m
[[36m08-24 20:20:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 11.6 sec/it | Loss 0.2052 | Reco 0.2052 | Nsdr 4.183[0m
[[36m08-24 20:20:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 0.11 it/sec | Loss 0.1908 | Reco 0.1908 | Nsdr 4.526[0m
[[36m08-24 20:21:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.12 it/sec | Loss 0.1945 | Reco 0.1945 | Nsdr 4.638[0m
[[36m08-24 20:21:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.13 it/sec | Loss 0.1966 | Reco 0.1966 | Nsdr 4.606[0m
[[36m08-24 20:21:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 10 | Loss=0.1778 | Reco=0.1778 | Nsdr=5.278 | Best=0.1778 | Bname=ema_batch_0 | Penalty=195.5359[0m
[[36m08-24 20:21:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1778[0m
[[36m08-24 20:21:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-24 20:21:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m08-24 21:09:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 11 | 1164/4656 | 0.40 it/sec | Loss 0.1143 | Reco 0.1124 | Grad 0.1078 | Penalty 193.6183[0m
[[36m08-24 21:58:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 11 | 2328/4656 | 0.40 it/sec | Loss 0.1151 | Reco 0.1131 | Grad 0.1062 | Penalty 195.2381[0m
[[36m08-24 22:46:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 11 | 3492/4656 | 0.40 it/sec | Loss 0.1152 | Reco 0.1132 | Grad 0.1065 | Penalty 195.6009[0m
[[36m08-24 23:34:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 11 | Loss=0.1145 | Reco=0.1125 | Grad=0.1056 | Penalty=195.5242[0m
[[36m08-24 23:34:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-24 23:34:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m08-24 23:35:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 11.3 sec/it | Loss 0.1886 | Reco 0.1886 | Nsdr 4.821[0m
[[36m08-24 23:35:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.11 it/sec | Loss 0.1776 | Reco 0.1776 | Nsdr 5.073[0m
[[36m08-24 23:36:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.12 it/sec | Loss 0.1793 | Reco 0.1793 | Nsdr 5.266[0m
[[36m08-24 23:36:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.13 it/sec | Loss 0.1803 | Reco 0.1803 | Nsdr 5.253[0m
[[36m08-24 23:37:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 11.1 sec/it | Loss 0.1896 | Reco 0.1896 | Nsdr 4.819[0m
[[36m08-24 23:37:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.12 it/sec | Loss 0.1757 | Reco 0.1757 | Nsdr 5.186[0m
[[36m08-24 23:37:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.12 it/sec | Loss 0.1755 | Reco 0.1755 | Nsdr 5.446[0m
[[36m08-24 23:38:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.13 it/sec | Loss 0.1761 | Reco 0.1761 | Nsdr 5.445[0m
[[36m08-24 23:39:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 11.3 sec/it | Loss 0.1889 | Reco 0.1889 | Nsdr 4.840[0m
[[36m08-24 23:39:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.12 it/sec | Loss 0.1756 | Reco 0.1756 | Nsdr 5.197[0m
[[36m08-24 23:39:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.12 it/sec | Loss 0.1766 | Reco 0.1766 | Nsdr 5.413[0m
[[36m08-24 23:39:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.13 it/sec | Loss 0.1777 | Reco 0.1777 | Nsdr 5.392[0m
[[36m08-24 23:40:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 11.4 sec/it | Loss 0.1989 | Reco 0.1989 | Nsdr 4.431[0m
[[36m08-24 23:41:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.11 it/sec | Loss 0.1856 | Reco 0.1856 | Nsdr 4.751[0m
[[36m08-24 23:41:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.12 it/sec | Loss 0.1890 | Reco 0.1890 | Nsdr 4.874[0m
[[36m08-24 23:41:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.13 it/sec | Loss 0.1908 | Reco 0.1908 | Nsdr 4.846[0m
[[36m08-24 23:42:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 11.1 sec/it | Loss 0.2029 | Reco 0.2029 | Nsdr 4.276[0m
[[36m08-24 23:42:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.12 it/sec | Loss 0.1893 | Reco 0.1893 | Nsdr 4.600[0m
[[36m08-24 23:43:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.12 it/sec | Loss 0.1930 | Reco 0.1930 | Nsdr 4.707[0m
[[36m08-24 23:43:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.13 it/sec | Loss 0.1950 | Reco 0.1950 | Nsdr 4.679[0m
[[36m08-24 23:43:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 11 | Loss=0.1773 | Reco=0.1773 | Nsdr=5.312 | Best=0.1773 | Bname=ema_batch_0 | Penalty=196.5583[0m
[[36m08-24 23:43:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1773[0m
[[36m08-24 23:43:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-24 23:43:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m08-25 00:32:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 12 | 1164/4656 | 0.40 it/sec | Loss 0.1130 | Reco 0.1110 | Grad 0.1056 | Penalty 195.8780[0m
[[36m08-25 01:20:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 12 | 2328/4656 | 0.40 it/sec | Loss 0.1138 | Reco 0.1119 | Grad 0.1039 | Penalty 195.9175[0m
[[36m08-25 02:08:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 12 | 3492/4656 | 0.40 it/sec | Loss 0.1140 | Reco 0.1121 | Grad 0.1059 | Penalty 196.4358[0m
[[36m08-25 02:57:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 12 | Loss=0.1135 | Reco=0.1115 | Grad=0.1049 | Penalty=196.9831[0m
[[36m08-25 02:57:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-25 02:57:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m08-25 02:57:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 11.7 sec/it | Loss 0.2008 | Reco 0.2008 | Nsdr 4.486[0m
[[36m08-25 02:58:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.11 it/sec | Loss 0.1842 | Reco 0.1842 | Nsdr 4.896[0m
[[36m08-25 02:58:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.12 it/sec | Loss 0.1815 | Reco 0.1815 | Nsdr 5.245[0m
[[36m08-25 02:58:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.13 it/sec | Loss 0.1817 | Reco 0.1817 | Nsdr 5.251[0m
[[36m08-25 02:59:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 11.4 sec/it | Loss 0.1880 | Reco 0.1880 | Nsdr 4.881[0m
[[36m08-25 02:59:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.11 it/sec | Loss 0.1743 | Reco 0.1743 | Nsdr 5.248[0m
[[36m08-25 03:00:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.12 it/sec | Loss 0.1742 | Reco 0.1742 | Nsdr 5.510[0m
[[36m08-25 03:00:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.13 it/sec | Loss 0.1747 | Reco 0.1747 | Nsdr 5.515[0m
[[36m08-25 03:01:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 11.4 sec/it | Loss 0.1874 | Reco 0.1874 | Nsdr 4.912[0m
[[36m08-25 03:01:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.11 it/sec | Loss 0.1743 | Reco 0.1743 | Nsdr 5.261[0m
[[36m08-25 03:02:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.12 it/sec | Loss 0.1751 | Reco 0.1751 | Nsdr 5.487[0m
[[36m08-25 03:02:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.13 it/sec | Loss 0.1761 | Reco 0.1761 | Nsdr 5.473[0m
[[36m08-25 03:03:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 11.8 sec/it | Loss 0.1982 | Reco 0.1982 | Nsdr 4.472[0m
[[36m08-25 03:03:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.11 it/sec | Loss 0.1849 | Reco 0.1849 | Nsdr 4.795[0m
[[36m08-25 03:04:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.12 it/sec | Loss 0.1880 | Reco 0.1880 | Nsdr 4.926[0m
[[36m08-25 03:04:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.13 it/sec | Loss 0.1897 | Reco 0.1897 | Nsdr 4.902[0m
[[36m08-25 03:05:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 11.6 sec/it | Loss 0.2025 | Reco 0.2025 | Nsdr 4.302[0m
[[36m08-25 03:05:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.11 it/sec | Loss 0.1889 | Reco 0.1889 | Nsdr 4.623[0m
[[36m08-25 03:05:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.12 it/sec | Loss 0.1924 | Reco 0.1924 | Nsdr 4.738[0m
[[36m08-25 03:06:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.13 it/sec | Loss 0.1943 | Reco 0.1943 | Nsdr 4.712[0m
[[36m08-25 03:06:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 12 | Loss=0.1760 | Reco=0.1760 | Nsdr=5.383 | Best=0.1760 | Bname=ema_batch_0 | Penalty=198.6272[0m
[[36m08-25 03:06:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1760[0m
[[36m08-25 03:06:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-25 03:06:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m08-25 03:54:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 13 | 1164/4656 | 0.40 it/sec | Loss 0.1122 | Reco 0.1102 | Grad 0.1025 | Penalty 198.3217[0m
[[36m08-25 04:43:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 13 | 2328/4656 | 0.40 it/sec | Loss 0.1126 | Reco 0.1106 | Grad 0.1028 | Penalty 198.5136[0m
[[36m08-25 05:31:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 13 | 3492/4656 | 0.40 it/sec | Loss 1.1137 | Reco 1.1112 | Grad 285.5510 | Penalty 246.5860[0m
[[36m08-25 06:19:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 13 | Loss=6.8605 | Reco=6.8488 | Grad=1407.6669 | Penalty=1174.7572[0m
[[36m08-25 06:19:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-25 06:19:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m08-25 06:20:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 11.4 sec/it | Loss 0.3262 | Reco 0.3262 | Nsdr -1.197[0m
[[36m08-25 06:20:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 6/14 | 0.11 it/sec | Loss 0.3187 | Reco 0.3187 | Nsdr -0.695[0m
[[36m08-25 06:21:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 9/14 | 0.12 it/sec | Loss 0.3276 | Reco 0.3276 | Nsdr -0.457[0m
[[36m08-25 06:21:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 12/14 | 0.13 it/sec | Loss 0.3306 | Reco 0.3306 | Nsdr -0.571[0m
[[36m08-25 06:22:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 11.4 sec/it | Loss 0.6980 | Reco 0.6980 | Nsdr -5.866[0m
[[36m08-25 06:22:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 6/14 | 0.11 it/sec | Loss 0.6726 | Reco 0.6726 | Nsdr -5.953[0m
[[36m08-25 06:23:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 9/14 | 0.12 it/sec | Loss 0.6830 | Reco 0.6830 | Nsdr -5.841[0m
[[36m08-25 06:23:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 12/14 | 0.13 it/sec | Loss 0.6876 | Reco 0.6876 | Nsdr -5.822[0m
[[36m08-25 06:24:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 11.7 sec/it | Loss 0.2143 | Reco 0.2143 | Nsdr 3.823[0m
[[36m08-25 06:24:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 6/14 | 0.11 it/sec | Loss 0.2063 | Reco 0.2063 | Nsdr 3.903[0m
[[36m08-25 06:24:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 9/14 | 0.12 it/sec | Loss 0.2120 | Reco 0.2120 | Nsdr 3.950[0m
[[36m08-25 06:25:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 12/14 | 0.13 it/sec | Loss 0.2127 | Reco 0.2127 | Nsdr 3.959[0m
[[36m08-25 06:26:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 11.2 sec/it | Loss 0.2353 | Reco 0.2353 | Nsdr 3.001[0m
[[36m08-25 06:26:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 6/14 | 0.12 it/sec | Loss 0.2308 | Reco 0.2308 | Nsdr 2.962[0m
[[36m08-25 06:26:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 9/14 | 0.12 it/sec | Loss 0.2385 | Reco 0.2385 | Nsdr 2.964[0m
[[36m08-25 06:27:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 12/14 | 0.13 it/sec | Loss 0.2395 | Reco 0.2395 | Nsdr 2.958[0m
[[36m08-25 06:27:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 11.2 sec/it | Loss 0.2260 | Reco 0.2260 | Nsdr 3.327[0m
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:228: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  return hydra.main(
[[36m08-25 06:46:06[0m][[34mdemucs.train[0m][[32mINFO[0m] - For logs, checkpoints and samples check /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/22d99e8f[0m
[[36m08-25 06:46:06[0m][[34mdora.distrib[0m][[32mINFO[0m] - world_size is 1, skipping init.[0m
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
/home/paperspace/.local/lib/python3.8/site-packages/musdb/configs/mus.yaml
[[36m08-25 06:46:15[0m][[34mdemucs.train[0m][[32mINFO[0m] - train/valid set size: 18626 14[0m
[[36m08-25 06:46:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-25 06:46:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
/home/paperspace/.local/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
/home/paperspace/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
[[36m08-25 07:31:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 1 | 1164/4656 | 0.43 it/sec | Loss 0.2023 | Reco 0.2012 | Grad 0.1009 | Penalty 110.0660[0m
[[36m08-25 08:17:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 1 | 2328/4656 | 0.43 it/sec | Loss 0.1926 | Reco 0.1914 | Grad 0.1006 | Penalty 122.4590[0m
[[36m08-25 09:02:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 1 | 3492/4656 | 0.43 it/sec | Loss 0.1867 | Reco 0.1854 | Grad 0.1047 | Penalty 125.3398[0m
[[36m08-25 09:47:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 1 | Loss=0.1814 | Reco=0.1801 | Grad=0.1099 | Penalty=131.4058[0m
[[36m08-25 09:47:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-25 09:47:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m08-25 09:48:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 3/14 | 10.7 sec/it | Loss 0.2373 | Reco 0.2373 | Nsdr 2.958[0m
[[36m08-25 09:48:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 6/14 | 0.12 it/sec | Loss 0.2225 | Reco 0.2225 | Nsdr 3.187[0m
[[36m08-25 09:48:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 9/14 | 0.13 it/sec | Loss 0.2237 | Reco 0.2237 | Nsdr 3.395[0m
[[36m08-25 09:49:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 12/14 | 0.14 it/sec | Loss 0.2259 | Reco 0.2259 | Nsdr 3.396[0m
[[36m08-25 09:50:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 3/14 | 10.8 sec/it | Loss 0.2508 | Reco 0.2508 | Nsdr 2.550[0m
[[36m08-25 09:50:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 6/14 | 0.12 it/sec | Loss 0.2332 | Reco 0.2332 | Nsdr 2.902[0m
[[36m08-25 09:50:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 9/14 | 0.13 it/sec | Loss 0.2380 | Reco 0.2380 | Nsdr 2.967[0m
[[36m08-25 09:50:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 12/14 | 0.14 it/sec | Loss 0.2429 | Reco 0.2429 | Nsdr 2.864[0m
[[36m08-25 09:51:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 3/14 | 10.7 sec/it | Loss 0.2592 | Reco 0.2592 | Nsdr 2.244[0m
[[36m08-25 09:52:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 6/14 | 0.12 it/sec | Loss 0.2408 | Reco 0.2408 | Nsdr 2.624[0m
[[36m08-25 09:52:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 9/14 | 0.13 it/sec | Loss 0.2466 | Reco 0.2466 | Nsdr 2.658[0m
[[36m08-25 09:52:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 12/14 | 0.14 it/sec | Loss 0.2517 | Reco 0.2517 | Nsdr 2.553[0m
[[36m08-25 09:53:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 3/14 | 10.7 sec/it | Loss 0.2372 | Reco 0.2372 | Nsdr 2.961[0m
[[36m08-25 09:53:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 6/14 | 0.12 it/sec | Loss 0.2225 | Reco 0.2225 | Nsdr 3.179[0m
[[36m08-25 09:54:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 9/14 | 0.13 it/sec | Loss 0.2237 | Reco 0.2237 | Nsdr 3.386[0m
[[36m08-25 09:54:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 12/14 | 0.14 it/sec | Loss 0.2260 | Reco 0.2260 | Nsdr 3.391[0m
[[36m08-25 09:55:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 3/14 | 10.7 sec/it | Loss 0.2372 | Reco 0.2372 | Nsdr 2.959[0m
[[36m08-25 09:55:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 6/14 | 0.12 it/sec | Loss 0.2226 | Reco 0.2226 | Nsdr 3.177[0m
[[36m08-25 09:55:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 9/14 | 0.13 it/sec | Loss 0.2238 | Reco 0.2238 | Nsdr 3.381[0m
[[36m08-25 09:56:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 12/14 | 0.14 it/sec | Loss 0.2260 | Reco 0.2260 | Nsdr 3.388[0m
[[36m08-25 09:56:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 1 | Loss=0.2256 | Reco=0.2256 | Nsdr=3.343 | Best=0.2256 | Bname=main | Penalty=146.1252[0m
[[36m08-25 09:56:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.2256[0m
[[36m08-25 09:56:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-25 09:56:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m08-25 10:41:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 2 | 1164/4656 | 0.43 it/sec | Loss 0.1597 | Reco 0.1579 | Grad 0.1362 | Penalty 183.4175[0m
[[36m08-25 11:27:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 2 | 2328/4656 | 0.43 it/sec | Loss 0.1554 | Reco 0.1535 | Grad 0.1329 | Penalty 188.2643[0m
[[36m08-25 12:13:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 2 | 3492/4656 | 0.42 it/sec | Loss 0.1525 | Reco 0.1507 | Grad 0.1323 | Penalty 183.8904[0m
[[36m08-25 12:59:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 2 | Loss=0.1501 | Reco=0.1483 | Grad=0.1282 | Penalty=178.2698[0m
[[36m08-25 12:59:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-25 12:59:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m08-25 12:59:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 3/14 | 10.9 sec/it | Loss 0.2212 | Reco 0.2212 | Nsdr 3.581[0m
[[36m08-25 13:00:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 6/14 | 0.12 it/sec | Loss 0.2015 | Reco 0.2015 | Nsdr 4.069[0m
[[36m08-25 13:00:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 9/14 | 0.13 it/sec | Loss 0.2032 | Reco 0.2032 | Nsdr 4.237[0m
[[36m08-25 13:00:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 12/14 | 0.14 it/sec | Loss 0.2059 | Reco 0.2059 | Nsdr 4.172[0m
[[36m08-25 13:01:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 3/14 | 10.7 sec/it | Loss 0.2181 | Reco 0.2181 | Nsdr 3.669[0m
[[36m08-25 13:01:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 6/14 | 0.12 it/sec | Loss 0.2024 | Reco 0.2024 | Nsdr 4.013[0m
[[36m08-25 13:02:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 9/14 | 0.13 it/sec | Loss 0.2050 | Reco 0.2050 | Nsdr 4.162[0m
[[36m08-25 13:02:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 12/14 | 0.14 it/sec | Loss 0.2087 | Reco 0.2087 | Nsdr 4.082[0m
[[36m08-25 13:03:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 3/14 | 10.8 sec/it | Loss 0.2438 | Reco 0.2438 | Nsdr 2.730[0m
[[36m08-25 13:03:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 6/14 | 0.12 it/sec | Loss 0.2281 | Reco 0.2281 | Nsdr 3.057[0m
[[36m08-25 13:03:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 9/14 | 0.13 it/sec | Loss 0.2342 | Reco 0.2342 | Nsdr 3.083[0m
[[36m08-25 13:04:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 12/14 | 0.14 it/sec | Loss 0.2400 | Reco 0.2400 | Nsdr 2.955[0m
[[36m08-25 13:05:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 3/14 | 11.0 sec/it | Loss 0.2261 | Reco 0.2261 | Nsdr 3.357[0m
[[36m08-25 13:05:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 6/14 | 0.12 it/sec | Loss 0.2094 | Reco 0.2094 | Nsdr 3.701[0m
[[36m08-25 13:05:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 9/14 | 0.12 it/sec | Loss 0.2111 | Reco 0.2111 | Nsdr 3.888[0m
[[36m08-25 13:05:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 12/14 | 0.13 it/sec | Loss 0.2144 | Reco 0.2144 | Nsdr 3.840[0m
[[36m08-25 13:06:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 3/14 | 10.4 sec/it | Loss 0.2264 | Reco 0.2264 | Nsdr 3.341[0m
[[36m08-25 13:07:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 6/14 | 0.12 it/sec | Loss 0.2097 | Reco 0.2097 | Nsdr 3.679[0m
[[36m08-25 13:07:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 9/14 | 0.13 it/sec | Loss 0.2114 | Reco 0.2114 | Nsdr 3.872[0m
[[36m08-25 13:07:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 12/14 | 0.14 it/sec | Loss 0.2147 | Reco 0.2147 | Nsdr 3.826[0m
[[36m08-25 13:07:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 2 | Loss=0.2067 | Reco=0.2067 | Nsdr=4.071 | Best=0.2067 | Bname=main | Penalty=155.8489[0m
[[36m08-25 13:07:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.2067[0m
[[36m08-25 13:07:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-25 13:07:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m08-25 13:53:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 3 | 1164/4656 | 0.43 it/sec | Loss 0.1388 | Reco 0.1371 | Grad 0.1175 | Penalty 163.2219[0m
[[36m08-25 14:38:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 3 | 2328/4656 | 0.43 it/sec | Loss 0.1384 | Reco 0.1368 | Grad 0.1183 | Penalty 163.9258[0m
[[36m08-25 15:24:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 3 | 3492/4656 | 0.43 it/sec | Loss 0.1377 | Reco 0.1361 | Grad 0.1172 | Penalty 161.6153[0m
[[36m08-25 16:09:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 3 | Loss=0.1366 | Reco=0.1350 | Grad=0.1178 | Penalty=162.6560[0m
[[36m08-25 16:09:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-25 16:09:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m08-25 16:10:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 3/14 | 10.6 sec/it | Loss 0.2157 | Reco 0.2157 | Nsdr 3.757[0m
[[36m08-25 16:10:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 6/14 | 0.12 it/sec | Loss 0.1978 | Reco 0.1978 | Nsdr 4.197[0m
[[36m08-25 16:10:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 9/14 | 0.13 it/sec | Loss 0.1980 | Reco 0.1980 | Nsdr 4.420[0m
[[36m08-25 16:11:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 12/14 | 0.14 it/sec | Loss 0.1999 | Reco 0.1999 | Nsdr 4.379[0m
[[36m08-25 16:11:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 3/14 | 10.5 sec/it | Loss 0.2081 | Reco 0.2081 | Nsdr 4.037[0m
[[36m08-25 16:12:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 6/14 | 0.12 it/sec | Loss 0.1914 | Reco 0.1914 | Nsdr 4.458[0m
[[36m08-25 16:12:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 9/14 | 0.13 it/sec | Loss 0.1929 | Reco 0.1929 | Nsdr 4.645[0m
[[36m08-25 16:12:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 12/14 | 0.14 it/sec | Loss 0.1955 | Reco 0.1955 | Nsdr 4.578[0m
[[36m08-25 16:13:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 3/14 | 11.0 sec/it | Loss 0.2262 | Reco 0.2262 | Nsdr 3.349[0m
[[36m08-25 16:13:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 6/14 | 0.12 it/sec | Loss 0.2115 | Reco 0.2115 | Nsdr 3.689[0m
[[36m08-25 16:14:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 9/14 | 0.13 it/sec | Loss 0.2166 | Reco 0.2166 | Nsdr 3.743[0m
[[36m08-25 16:14:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 12/14 | 0.14 it/sec | Loss 0.2221 | Reco 0.2221 | Nsdr 3.614[0m
[[36m08-25 16:15:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 3/14 | 10.6 sec/it | Loss 0.2196 | Reco 0.2196 | Nsdr 3.617[0m
[[36m08-25 16:15:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 6/14 | 0.12 it/sec | Loss 0.2026 | Reco 0.2026 | Nsdr 4.015[0m
[[36m08-25 16:15:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 9/14 | 0.13 it/sec | Loss 0.2042 | Reco 0.2042 | Nsdr 4.198[0m
[[36m08-25 16:16:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 12/14 | 0.14 it/sec | Loss 0.2074 | Reco 0.2074 | Nsdr 4.132[0m
[[36m08-25 16:17:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 3/14 | 10.6 sec/it | Loss 0.2200 | Reco 0.2200 | Nsdr 3.597[0m
[[36m08-25 16:17:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 6/14 | 0.12 it/sec | Loss 0.2032 | Reco 0.2032 | Nsdr 3.988[0m
[[36m08-25 16:17:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 9/14 | 0.13 it/sec | Loss 0.2048 | Reco 0.2048 | Nsdr 4.172[0m
[[36m08-25 16:17:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 12/14 | 0.14 it/sec | Loss 0.2081 | Reco 0.2081 | Nsdr 4.109[0m
[[36m08-25 16:18:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 3 | Loss=0.1962 | Reco=0.1962 | Nsdr=4.467 | Best=0.1962 | Bname=ema_batch_0 | Penalty=163.4064[0m
[[36m08-25 16:18:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1962[0m
[[36m08-25 16:18:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-25 16:18:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m08-25 17:03:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 4 | 1164/4656 | 0.43 it/sec | Loss 0.1328 | Reco 0.1311 | Grad 0.1148 | Penalty 165.6287[0m
[[36m08-25 17:49:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 4 | 2328/4656 | 0.43 it/sec | Loss 0.1321 | Reco 0.1304 | Grad 0.1171 | Penalty 164.3820[0m
[[36m08-25 18:35:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 4 | 3492/4656 | 0.43 it/sec | Loss 0.1318 | Reco 0.1302 | Grad 0.1176 | Penalty 163.4800[0m
[[36m08-25 19:20:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 4 | Loss=0.1306 | Reco=0.1290 | Grad=0.1159 | Penalty=163.0077[0m
[[36m08-25 19:20:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-25 19:20:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m08-25 19:21:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 3/14 | 11.0 sec/it | Loss 0.2017 | Reco 0.2017 | Nsdr 4.228[0m
[[36m08-25 19:21:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 6/14 | 0.12 it/sec | Loss 0.1875 | Reco 0.1875 | Nsdr 4.590[0m
[[36m08-25 19:22:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 9/14 | 0.13 it/sec | Loss 0.1898 | Reco 0.1898 | Nsdr 4.754[0m
[[36m08-25 19:22:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 12/14 | 0.14 it/sec | Loss 0.1942 | Reco 0.1942 | Nsdr 4.626[0m
[[36m08-25 19:23:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 3/14 | 11.0 sec/it | Loss 0.2013 | Reco 0.2013 | Nsdr 4.307[0m
[[36m08-25 19:23:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 6/14 | 0.12 it/sec | Loss 0.1855 | Reco 0.1855 | Nsdr 4.727[0m
[[36m08-25 19:23:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 9/14 | 0.13 it/sec | Loss 0.1868 | Reco 0.1868 | Nsdr 4.922[0m
[[36m08-25 19:24:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 12/14 | 0.14 it/sec | Loss 0.1892 | Reco 0.1892 | Nsdr 4.854[0m
[[36m08-25 19:24:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 3/14 | 10.7 sec/it | Loss 0.2139 | Reco 0.2139 | Nsdr 3.827[0m
[[36m08-25 19:25:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 6/14 | 0.12 it/sec | Loss 0.1989 | Reco 0.1989 | Nsdr 4.213[0m
[[36m08-25 19:25:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 9/14 | 0.13 it/sec | Loss 0.2025 | Reco 0.2025 | Nsdr 4.312[0m
[[36m08-25 19:25:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 12/14 | 0.14 it/sec | Loss 0.2068 | Reco 0.2068 | Nsdr 4.197[0m
[[36m08-25 19:26:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 3/14 | 10.8 sec/it | Loss 0.2126 | Reco 0.2126 | Nsdr 3.871[0m
[[36m08-25 19:26:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 6/14 | 0.12 it/sec | Loss 0.1970 | Reco 0.1970 | Nsdr 4.254[0m
[[36m08-25 19:27:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 9/14 | 0.13 it/sec | Loss 0.1991 | Reco 0.1991 | Nsdr 4.417[0m
[[36m08-25 19:27:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 12/14 | 0.14 it/sec | Loss 0.2027 | Reco 0.2027 | Nsdr 4.329[0m
[[36m08-25 19:28:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 3/14 | 11.1 sec/it | Loss 0.2135 | Reco 0.2135 | Nsdr 3.833[0m
[[36m08-25 19:28:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 6/14 | 0.12 it/sec | Loss 0.1979 | Reco 0.1979 | Nsdr 4.213[0m
[[36m08-25 19:29:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 9/14 | 0.13 it/sec | Loss 0.2000 | Reco 0.2000 | Nsdr 4.374[0m
[[36m08-25 19:29:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 12/14 | 0.14 it/sec | Loss 0.2037 | Reco 0.2037 | Nsdr 4.287[0m
[[36m08-25 19:29:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 4 | Loss=0.1903 | Reco=0.1903 | Nsdr=4.723 | Best=0.1903 | Bname=ema_batch_0 | Penalty=160.3199[0m
[[36m08-25 19:29:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1903[0m
[[36m08-25 19:29:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-25 19:29:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m08-25 20:15:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 5 | 1164/4656 | 0.43 it/sec | Loss 0.1286 | Reco 0.1270 | Grad 0.1139 | Penalty 160.5180[0m
[[36m08-25 21:00:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 5 | 2328/4656 | 0.43 it/sec | Loss 0.1281 | Reco 0.1265 | Grad 0.1125 | Penalty 161.2662[0m
[[36m08-25 21:46:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 5 | 3492/4656 | 0.43 it/sec | Loss 0.1268 | Reco 0.1251 | Grad 0.1117 | Penalty 161.6879[0m
[[36m08-25 22:31:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 5 | Loss=0.1263 | Reco=0.1247 | Grad=0.1116 | Penalty=163.1950[0m
[[36m08-25 22:31:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-25 22:31:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m08-25 22:32:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 3/14 | 10.6 sec/it | Loss 0.1977 | Reco 0.1977 | Nsdr 4.397[0m
[[36m08-25 22:32:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 6/14 | 0.12 it/sec | Loss 0.1845 | Reco 0.1845 | Nsdr 4.734[0m
[[36m08-25 22:32:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 9/14 | 0.13 it/sec | Loss 0.1869 | Reco 0.1869 | Nsdr 4.892[0m
[[36m08-25 22:33:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 12/14 | 0.14 it/sec | Loss 0.1886 | Reco 0.1886 | Nsdr 4.853[0m
[[36m08-25 22:33:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 3/14 | 10.6 sec/it | Loss 0.1973 | Reco 0.1973 | Nsdr 4.468[0m
[[36m08-25 22:34:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 6/14 | 0.12 it/sec | Loss 0.1815 | Reco 0.1815 | Nsdr 4.899[0m
[[36m08-25 22:34:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 9/14 | 0.13 it/sec | Loss 0.1829 | Reco 0.1829 | Nsdr 5.088[0m
[[36m08-25 22:34:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 12/14 | 0.14 it/sec | Loss 0.1852 | Reco 0.1852 | Nsdr 5.019[0m
[[36m08-25 22:35:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 3/14 | 10.6 sec/it | Loss 0.2062 | Reco 0.2062 | Nsdr 4.127[0m
[[36m08-25 22:35:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 6/14 | 0.12 it/sec | Loss 0.1912 | Reco 0.1912 | Nsdr 4.527[0m
[[36m08-25 22:36:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 9/14 | 0.13 it/sec | Loss 0.1941 | Reco 0.1941 | Nsdr 4.652[0m
[[36m08-25 22:36:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 12/14 | 0.14 it/sec | Loss 0.1978 | Reco 0.1978 | Nsdr 4.542[0m
[[36m08-25 22:37:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 3/14 | 10.8 sec/it | Loss 0.2085 | Reco 0.2085 | Nsdr 4.029[0m
[[36m08-25 22:37:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 6/14 | 0.12 it/sec | Loss 0.1935 | Reco 0.1935 | Nsdr 4.411[0m
[[36m08-25 22:37:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 9/14 | 0.13 it/sec | Loss 0.1958 | Reco 0.1958 | Nsdr 4.565[0m
[[36m08-25 22:38:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 12/14 | 0.14 it/sec | Loss 0.1991 | Reco 0.1991 | Nsdr 4.477[0m
[[36m08-25 22:39:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 3/14 | 10.6 sec/it | Loss 0.2096 | Reco 0.2096 | Nsdr 3.984[0m
[[36m08-25 22:39:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 6/14 | 0.12 it/sec | Loss 0.1947 | Reco 0.1947 | Nsdr 4.358[0m
[[36m08-25 22:39:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 9/14 | 0.13 it/sec | Loss 0.1970 | Reco 0.1970 | Nsdr 4.511[0m
[[36m08-25 22:39:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 12/14 | 0.14 it/sec | Loss 0.2004 | Reco 0.2004 | Nsdr 4.424[0m
[[36m08-25 22:40:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 5 | Loss=0.1866 | Reco=0.1866 | Nsdr=4.876 | Best=0.1866 | Bname=ema_batch_0 | Penalty=185.5913[0m
[[36m08-25 22:40:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1866[0m
[[36m08-25 22:40:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-25 22:40:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m08-25 23:25:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 6 | 1164/4656 | 0.43 it/sec | Loss 0.1265 | Reco 0.1248 | Grad 0.1144 | Penalty 172.7512[0m
[[36m08-26 00:11:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 6 | 2328/4656 | 0.43 it/sec | Loss 0.1246 | Reco 0.1229 | Grad 0.1144 | Penalty 169.2685[0m
[[36m08-26 00:56:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 6 | 3492/4656 | 0.43 it/sec | Loss 0.1238 | Reco 0.1221 | Grad 0.1132 | Penalty 173.1200[0m
[[36m08-26 01:41:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 6 | Loss=0.1231 | Reco=0.1214 | Grad=0.1142 | Penalty=171.9149[0m
[[36m08-26 01:41:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-26 01:41:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m08-26 01:42:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 3/14 | 11.0 sec/it | Loss 0.1986 | Reco 0.1986 | Nsdr 4.358[0m
[[36m08-26 01:42:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 6/14 | 0.12 it/sec | Loss 0.1838 | Reco 0.1838 | Nsdr 4.708[0m
[[36m08-26 01:43:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 9/14 | 0.13 it/sec | Loss 0.1862 | Reco 0.1862 | Nsdr 4.879[0m
[[36m08-26 01:43:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 12/14 | 0.14 it/sec | Loss 0.1881 | Reco 0.1881 | Nsdr 4.853[0m
[[36m08-26 01:44:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 3/14 | 10.8 sec/it | Loss 0.1943 | Reco 0.1943 | Nsdr 4.586[0m
[[36m08-26 01:44:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 6/14 | 0.12 it/sec | Loss 0.1791 | Reco 0.1791 | Nsdr 5.004[0m
[[36m08-26 01:44:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 9/14 | 0.13 it/sec | Loss 0.1804 | Reco 0.1804 | Nsdr 5.198[0m
[[36m08-26 01:45:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 12/14 | 0.14 it/sec | Loss 0.1825 | Reco 0.1825 | Nsdr 5.144[0m
[[36m08-26 01:46:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 3/14 | 11.1 sec/it | Loss 0.2005 | Reco 0.2005 | Nsdr 4.355[0m
[[36m08-26 01:46:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 6/14 | 0.12 it/sec | Loss 0.1857 | Reco 0.1857 | Nsdr 4.763[0m
[[36m08-26 01:46:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 9/14 | 0.12 it/sec | Loss 0.1881 | Reco 0.1881 | Nsdr 4.904[0m
[[36m08-26 01:46:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 12/14 | 0.13 it/sec | Loss 0.1914 | Reco 0.1914 | Nsdr 4.805[0m
[[36m08-26 01:47:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 3/14 | 10.6 sec/it | Loss 0.2055 | Reco 0.2055 | Nsdr 4.144[0m
[[36m08-26 01:48:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 6/14 | 0.12 it/sec | Loss 0.1907 | Reco 0.1907 | Nsdr 4.527[0m
[[36m08-26 01:48:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 9/14 | 0.13 it/sec | Loss 0.1932 | Reco 0.1932 | Nsdr 4.672[0m
[[36m08-26 01:48:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 12/14 | 0.14 it/sec | Loss 0.1964 | Reco 0.1964 | Nsdr 4.584[0m
[[36m08-26 01:49:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 3/14 | 10.7 sec/it | Loss 0.2070 | Reco 0.2070 | Nsdr 4.087[0m
[[36m08-26 01:49:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 6/14 | 0.12 it/sec | Loss 0.1923 | Reco 0.1923 | Nsdr 4.465[0m
[[36m08-26 01:50:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 9/14 | 0.13 it/sec | Loss 0.1948 | Reco 0.1948 | Nsdr 4.605[0m
[[36m08-26 01:50:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 12/14 | 0.14 it/sec | Loss 0.1981 | Reco 0.1981 | Nsdr 4.516[0m
[[36m08-26 01:50:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 6 | Loss=0.1836 | Reco=0.1836 | Nsdr=5.008 | Best=0.1836 | Bname=ema_batch_0 | Penalty=167.6331[0m
[[36m08-26 01:50:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1836[0m
[[36m08-26 01:50:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-26 01:50:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m08-26 02:36:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 7 | 1164/4656 | 0.43 it/sec | Loss 0.1197 | Reco 0.1180 | Grad 0.1157 | Penalty 166.8658[0m
[[36m08-26 03:21:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 7 | 2328/4656 | 0.43 it/sec | Loss 0.1209 | Reco 0.1192 | Grad 0.1163 | Penalty 166.6629[0m
[[36m08-26 04:07:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 7 | 3492/4656 | 0.43 it/sec | Loss 0.1210 | Reco 0.1193 | Grad 0.1159 | Penalty 167.5927[0m
[[36m08-26 04:52:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 7 | Loss=0.1204 | Reco=0.1188 | Grad=0.1147 | Penalty=169.4046[0m
[[36m08-26 04:52:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-26 04:52:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m08-26 04:53:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 3/14 | 10.5 sec/it | Loss 0.2054 | Reco 0.2054 | Nsdr 4.238[0m
[[36m08-26 04:53:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 6/14 | 0.12 it/sec | Loss 0.1882 | Reco 0.1882 | Nsdr 4.676[0m
[[36m08-26 04:53:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 9/14 | 0.13 it/sec | Loss 0.1869 | Reco 0.1869 | Nsdr 4.957[0m
[[36m08-26 04:54:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 12/14 | 0.14 it/sec | Loss 0.1871 | Reco 0.1871 | Nsdr 4.981[0m
[[36m08-26 04:54:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 3/14 | 10.4 sec/it | Loss 0.1940 | Reco 0.1940 | Nsdr 4.616[0m
[[36m08-26 04:55:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 6/14 | 0.12 it/sec | Loss 0.1783 | Reco 0.1783 | Nsdr 5.054[0m
[[36m08-26 04:55:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 9/14 | 0.13 it/sec | Loss 0.1791 | Reco 0.1791 | Nsdr 5.268[0m
[[36m08-26 04:55:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 12/14 | 0.14 it/sec | Loss 0.1806 | Reco 0.1806 | Nsdr 5.239[0m
[[36m08-26 04:56:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 3/14 | 10.5 sec/it | Loss 0.1965 | Reco 0.1965 | Nsdr 4.521[0m
[[36m08-26 04:56:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 6/14 | 0.12 it/sec | Loss 0.1819 | Reco 0.1819 | Nsdr 4.926[0m
[[36m08-26 04:57:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 9/14 | 0.13 it/sec | Loss 0.1840 | Reco 0.1840 | Nsdr 5.084[0m
[[36m08-26 04:57:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 12/14 | 0.14 it/sec | Loss 0.1869 | Reco 0.1869 | Nsdr 4.997[0m
[[36m08-26 04:58:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 3/14 | 10.5 sec/it | Loss 0.2037 | Reco 0.2037 | Nsdr 4.235[0m
[[36m08-26 04:58:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 6/14 | 0.12 it/sec | Loss 0.1890 | Reco 0.1890 | Nsdr 4.624[0m
[[36m08-26 04:58:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 9/14 | 0.13 it/sec | Loss 0.1914 | Reco 0.1914 | Nsdr 4.768[0m
[[36m08-26 04:59:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 12/14 | 0.14 it/sec | Loss 0.1943 | Reco 0.1943 | Nsdr 4.687[0m
[[36m08-26 05:00:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 3/14 | 10.5 sec/it | Loss 0.2051 | Reco 0.2051 | Nsdr 4.178[0m
[[36m08-26 05:00:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 6/14 | 0.12 it/sec | Loss 0.1905 | Reco 0.1905 | Nsdr 4.557[0m
[[36m08-26 05:00:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 9/14 | 0.13 it/sec | Loss 0.1932 | Reco 0.1932 | Nsdr 4.689[0m
[[36m08-26 05:00:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 12/14 | 0.14 it/sec | Loss 0.1964 | Reco 0.1964 | Nsdr 4.603[0m
[[36m08-26 05:01:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 7 | Loss=0.1817 | Reco=0.1817 | Nsdr=5.108 | Best=0.1817 | Bname=ema_batch_0 | Penalty=174.2735[0m
[[36m08-26 05:01:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1817[0m
[[36m08-26 05:01:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-26 05:01:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m08-26 05:46:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 8 | 1164/4656 | 0.43 it/sec | Loss 0.1187 | Reco 0.1169 | Grad 0.1179 | Penalty 174.1811[0m
[[36m08-26 06:32:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 8 | 2328/4656 | 0.43 it/sec | Loss 0.1198 | Reco 0.1180 | Grad 0.1147 | Penalty 174.1124[0m
[[36m08-26 07:17:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 8 | 3492/4656 | 0.43 it/sec | Loss 0.1189 | Reco 0.1172 | Grad 0.1142 | Penalty 174.0995[0m
[[36m08-26 08:03:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 8 | Loss=0.1183 | Reco=0.1166 | Grad=0.1127 | Penalty=174.2467[0m
[[36m08-26 08:03:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-26 08:03:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m08-26 08:03:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 10.7 sec/it | Loss 0.1925 | Reco 0.1925 | Nsdr 4.594[0m
[[36m08-26 08:04:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.12 it/sec | Loss 0.1793 | Reco 0.1793 | Nsdr 4.971[0m
[[36m08-26 08:04:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.13 it/sec | Loss 0.1824 | Reco 0.1824 | Nsdr 5.106[0m
[[36m08-26 08:04:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.14 it/sec | Loss 0.1841 | Reco 0.1841 | Nsdr 5.065[0m
[[36m08-26 08:05:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 11.0 sec/it | Loss 0.1898 | Reco 0.1898 | Nsdr 4.787[0m
[[36m08-26 08:05:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.12 it/sec | Loss 0.1756 | Reco 0.1756 | Nsdr 5.170[0m
[[36m08-26 08:06:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.13 it/sec | Loss 0.1764 | Reco 0.1764 | Nsdr 5.381[0m
[[36m08-26 08:06:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.14 it/sec | Loss 0.1777 | Reco 0.1777 | Nsdr 5.357[0m
[[36m08-26 08:07:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 10.7 sec/it | Loss 0.1938 | Reco 0.1938 | Nsdr 4.634[0m
[[36m08-26 08:07:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.12 it/sec | Loss 0.1792 | Reco 0.1792 | Nsdr 5.052[0m
[[36m08-26 08:07:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.13 it/sec | Loss 0.1811 | Reco 0.1811 | Nsdr 5.204[0m
[[36m08-26 08:08:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.14 it/sec | Loss 0.1835 | Reco 0.1835 | Nsdr 5.137[0m
[[36m08-26 08:09:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 11.0 sec/it | Loss 0.2018 | Reco 0.2018 | Nsdr 4.310[0m
[[36m08-26 08:09:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.12 it/sec | Loss 0.1873 | Reco 0.1873 | Nsdr 4.703[0m
[[36m08-26 08:09:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.13 it/sec | Loss 0.1900 | Reco 0.1900 | Nsdr 4.836[0m
[[36m08-26 08:10:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.14 it/sec | Loss 0.1929 | Reco 0.1929 | Nsdr 4.755[0m
[[36m08-26 08:10:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 10.5 sec/it | Loss 0.2038 | Reco 0.2038 | Nsdr 4.227[0m
[[36m08-26 08:11:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.12 it/sec | Loss 0.1896 | Reco 0.1896 | Nsdr 4.606[0m
[[36m08-26 08:11:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.13 it/sec | Loss 0.1923 | Reco 0.1923 | Nsdr 4.737[0m
[[36m08-26 08:11:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.14 it/sec | Loss 0.1954 | Reco 0.1954 | Nsdr 4.652[0m
[[36m08-26 08:11:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 8 | Loss=0.1788 | Reco=0.1788 | Nsdr=5.234 | Best=0.1788 | Bname=ema_batch_0 | Penalty=175.4759[0m
[[36m08-26 08:11:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1788[0m
[[36m08-26 08:11:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-26 08:11:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m08-26 08:57:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 9 | 1164/4656 | 0.43 it/sec | Loss 0.1170 | Reco 0.1153 | Grad 0.1087 | Penalty 173.1897[0m
[[36m08-26 09:43:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 9 | 2328/4656 | 0.42 it/sec | Loss 0.1166 | Reco 0.1149 | Grad 0.1080 | Penalty 173.2986[0m
[[36m08-26 10:29:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 9 | 3492/4656 | 0.42 it/sec | Loss 0.1167 | Reco 0.1149 | Grad 0.1108 | Penalty 174.7179[0m
[[36m08-26 11:15:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 9 | Loss=0.1161 | Reco=0.1143 | Grad=0.1098 | Penalty=176.8193[0m
[[36m08-26 11:15:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-26 11:15:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m08-26 11:16:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 11.0 sec/it | Loss 0.2027 | Reco 0.2027 | Nsdr 4.319[0m
[[36m08-26 11:16:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.12 it/sec | Loss 0.1854 | Reco 0.1854 | Nsdr 4.791[0m
[[36m08-26 11:16:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.13 it/sec | Loss 0.1845 | Reco 0.1845 | Nsdr 5.065[0m
[[36m08-26 11:17:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.14 it/sec | Loss 0.1845 | Reco 0.1845 | Nsdr 5.093[0m
[[36m08-26 11:18:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 10.8 sec/it | Loss 0.1900 | Reco 0.1900 | Nsdr 4.792[0m
[[36m08-26 11:18:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.12 it/sec | Loss 0.1751 | Reco 0.1751 | Nsdr 5.207[0m
[[36m08-26 11:18:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.13 it/sec | Loss 0.1757 | Reco 0.1757 | Nsdr 5.412[0m
[[36m08-26 11:18:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.14 it/sec | Loss 0.1768 | Reco 0.1768 | Nsdr 5.403[0m
[[36m08-26 11:19:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 10.6 sec/it | Loss 0.1912 | Reco 0.1912 | Nsdr 4.746[0m
[[36m08-26 11:20:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.12 it/sec | Loss 0.1768 | Reco 0.1768 | Nsdr 5.155[0m
[[36m08-26 11:20:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.13 it/sec | Loss 0.1786 | Reco 0.1786 | Nsdr 5.315[0m
[[36m08-26 11:20:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.14 it/sec | Loss 0.1807 | Reco 0.1807 | Nsdr 5.258[0m
[[36m08-26 11:21:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 11.0 sec/it | Loss 0.2010 | Reco 0.2010 | Nsdr 4.354[0m
[[36m08-26 11:21:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.12 it/sec | Loss 0.1868 | Reco 0.1868 | Nsdr 4.743[0m
[[36m08-26 11:22:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.13 it/sec | Loss 0.1894 | Reco 0.1894 | Nsdr 4.873[0m
[[36m08-26 11:22:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.14 it/sec | Loss 0.1921 | Reco 0.1921 | Nsdr 4.799[0m
[[36m08-26 11:23:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 10.6 sec/it | Loss 0.2031 | Reco 0.2031 | Nsdr 4.265[0m
[[36m08-26 11:23:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.12 it/sec | Loss 0.1891 | Reco 0.1891 | Nsdr 4.641[0m
[[36m08-26 11:23:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.13 it/sec | Loss 0.1921 | Reco 0.1921 | Nsdr 4.759[0m
[[36m08-26 11:24:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.14 it/sec | Loss 0.1949 | Reco 0.1949 | Nsdr 4.681[0m
[[36m08-26 11:24:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 9 | Loss=0.1777 | Reco=0.1777 | Nsdr=5.281 | Best=0.1777 | Bname=ema_batch_0 | Penalty=184.2159[0m
[[36m08-26 11:24:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1777[0m
[[36m08-26 11:24:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-26 11:24:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m08-26 12:10:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 10 | 1164/4656 | 0.42 it/sec | Loss 0.1160 | Reco 0.1142 | Grad 0.1099 | Penalty 182.0435[0m
[[36m08-26 12:55:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 10 | 2328/4656 | 0.42 it/sec | Loss 0.1151 | Reco 0.1133 | Grad 0.1086 | Penalty 180.4731[0m
[[36m08-26 13:41:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 10 | 3492/4656 | 0.42 it/sec | Loss 0.1154 | Reco 0.1135 | Grad 0.1095 | Penalty 185.9846[0m
[[36m08-26 14:27:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 10 | Loss=0.1147 | Reco=0.1128 | Grad=0.1087 | Penalty=189.0758[0m
[[36m08-26 14:27:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-26 14:27:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m08-26 14:28:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 10.6 sec/it | Loss 0.2058 | Reco 0.2058 | Nsdr 4.168[0m
[[36m08-26 14:28:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 0.12 it/sec | Loss 0.1870 | Reco 0.1870 | Nsdr 4.641[0m
[[36m08-26 14:28:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.13 it/sec | Loss 0.1868 | Reco 0.1868 | Nsdr 4.866[0m
[[36m08-26 14:29:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.14 it/sec | Loss 0.1871 | Reco 0.1871 | Nsdr 4.908[0m
[[36m08-26 14:29:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 10.9 sec/it | Loss 0.1885 | Reco 0.1885 | Nsdr 4.864[0m
[[36m08-26 14:30:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 0.12 it/sec | Loss 0.1741 | Reco 0.1741 | Nsdr 5.257[0m
[[36m08-26 14:30:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.13 it/sec | Loss 0.1745 | Reco 0.1745 | Nsdr 5.476[0m
[[36m08-26 14:30:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.14 it/sec | Loss 0.1753 | Reco 0.1753 | Nsdr 5.475[0m
[[36m08-26 14:31:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 10.6 sec/it | Loss 0.1898 | Reco 0.1898 | Nsdr 4.814[0m
[[36m08-26 14:31:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 0.12 it/sec | Loss 0.1755 | Reco 0.1755 | Nsdr 5.219[0m
[[36m08-26 14:32:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.13 it/sec | Loss 0.1768 | Reco 0.1768 | Nsdr 5.396[0m
[[36m08-26 14:32:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.14 it/sec | Loss 0.1786 | Reco 0.1786 | Nsdr 5.354[0m
[[36m08-26 14:33:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 11.0 sec/it | Loss 0.2001 | Reco 0.2001 | Nsdr 4.396[0m
[[36m08-26 14:33:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 0.12 it/sec | Loss 0.1863 | Reco 0.1863 | Nsdr 4.766[0m
[[36m08-26 14:33:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.13 it/sec | Loss 0.1891 | Reco 0.1891 | Nsdr 4.886[0m
[[36m08-26 14:34:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.14 it/sec | Loss 0.1918 | Reco 0.1918 | Nsdr 4.815[0m
[[36m08-26 14:35:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 11.1 sec/it | Loss 0.2025 | Reco 0.2025 | Nsdr 4.295[0m
[[36m08-26 14:35:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 0.12 it/sec | Loss 0.1889 | Reco 0.1889 | Nsdr 4.652[0m
[[36m08-26 14:35:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.12 it/sec | Loss 0.1920 | Reco 0.1920 | Nsdr 4.763[0m
[[36m08-26 14:36:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.13 it/sec | Loss 0.1949 | Reco 0.1949 | Nsdr 4.685[0m
[[36m08-26 14:36:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 10 | Loss=0.1763 | Reco=0.1763 | Nsdr=5.353 | Best=0.1763 | Bname=ema_batch_0 | Penalty=186.0696[0m
[[36m08-26 14:36:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1763[0m
[[36m08-26 14:36:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-26 14:36:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m08-26 15:21:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 11 | 1164/4656 | 0.43 it/sec | Loss 0.1136 | Reco 0.1117 | Grad 0.1083 | Penalty 186.9136[0m
[[36m08-26 16:07:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 11 | 2328/4656 | 0.43 it/sec | Loss 0.1141 | Reco 0.1123 | Grad 0.1092 | Penalty 187.1095[0m
[[36m08-26 16:53:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 11 | 3492/4656 | 0.43 it/sec | Loss 0.1141 | Reco 0.1123 | Grad 0.1082 | Penalty 188.7969[0m
[[36m08-26 17:38:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 11 | Loss=0.1137 | Reco=0.1118 | Grad=0.1087 | Penalty=188.6343[0m
[[36m08-26 17:38:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-26 17:38:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m08-26 17:39:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 11.0 sec/it | Loss 0.1943 | Reco 0.1943 | Nsdr 4.603[0m
[[36m08-26 17:39:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.12 it/sec | Loss 0.1796 | Reco 0.1796 | Nsdr 5.003[0m
[[36m08-26 17:39:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.13 it/sec | Loss 0.1807 | Reco 0.1807 | Nsdr 5.211[0m
[[36m08-26 17:40:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.14 it/sec | Loss 0.1810 | Reco 0.1810 | Nsdr 5.225[0m
[[36m08-26 17:41:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 10.8 sec/it | Loss 0.1900 | Reco 0.1900 | Nsdr 4.817[0m
[[36m08-26 17:41:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.12 it/sec | Loss 0.1746 | Reco 0.1746 | Nsdr 5.246[0m
[[36m08-26 17:41:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.13 it/sec | Loss 0.1746 | Reco 0.1746 | Nsdr 5.485[0m
[[36m08-26 17:41:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.14 it/sec | Loss 0.1750 | Reco 0.1750 | Nsdr 5.500[0m
[[36m08-26 17:42:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 10.9 sec/it | Loss 0.1896 | Reco 0.1896 | Nsdr 4.833[0m
[[36m08-26 17:43:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.12 it/sec | Loss 0.1749 | Reco 0.1749 | Nsdr 5.251[0m
[[36m08-26 17:43:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.13 it/sec | Loss 0.1758 | Reco 0.1758 | Nsdr 5.451[0m
[[36m08-26 17:43:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.14 it/sec | Loss 0.1771 | Reco 0.1771 | Nsdr 5.428[0m
[[36m08-26 17:44:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 11.1 sec/it | Loss 0.1983 | Reco 0.1983 | Nsdr 4.465[0m
[[36m08-26 17:44:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.12 it/sec | Loss 0.1848 | Reco 0.1848 | Nsdr 4.826[0m
[[36m08-26 17:45:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.13 it/sec | Loss 0.1878 | Reco 0.1878 | Nsdr 4.941[0m
[[36m08-26 17:45:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.14 it/sec | Loss 0.1906 | Reco 0.1906 | Nsdr 4.868[0m
[[36m08-26 17:46:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 10.5 sec/it | Loss 0.2011 | Reco 0.2011 | Nsdr 4.348[0m
[[36m08-26 17:46:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.12 it/sec | Loss 0.1878 | Reco 0.1878 | Nsdr 4.694[0m
[[36m08-26 17:46:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.13 it/sec | Loss 0.1913 | Reco 0.1913 | Nsdr 4.795[0m
[[36m08-26 17:47:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.14 it/sec | Loss 0.1942 | Reco 0.1942 | Nsdr 4.716[0m
[[36m08-26 17:47:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 11 | Loss=0.1757 | Reco=0.1757 | Nsdr=5.387 | Best=0.1757 | Bname=ema_batch_0 | Penalty=188.2310[0m
[[36m08-26 17:47:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1757[0m
[[36m08-26 17:47:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-26 17:47:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m08-26 18:33:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 12 | 1164/4656 | 0.42 it/sec | Loss 0.1124 | Reco 0.1105 | Grad 0.1077 | Penalty 189.3409[0m
[[36m08-26 19:19:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 12 | 2328/4656 | 0.42 it/sec | Loss 0.1128 | Reco 0.1109 | Grad 0.1061 | Penalty 188.7448[0m
[[36m08-26 20:05:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 12 | 3492/4656 | 0.42 it/sec | Loss 0.1131 | Reco 0.1112 | Grad 0.1061 | Penalty 189.8004[0m
[[36m08-26 20:51:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 12 | Loss=0.1128 | Reco=0.1109 | Grad=0.1057 | Penalty=190.0854[0m
[[36m08-26 20:51:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-26 20:51:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m08-26 20:52:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 10.5 sec/it | Loss 0.1977 | Reco 0.1977 | Nsdr 4.486[0m
[[36m08-26 20:52:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.12 it/sec | Loss 0.1810 | Reco 0.1810 | Nsdr 4.949[0m
[[36m08-26 20:53:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.13 it/sec | Loss 0.1809 | Reco 0.1809 | Nsdr 5.193[0m
[[36m08-26 20:53:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.14 it/sec | Loss 0.1820 | Reco 0.1820 | Nsdr 5.173[0m
[[36m08-26 20:54:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 10.7 sec/it | Loss 0.1878 | Reco 0.1878 | Nsdr 4.897[0m
[[36m08-26 20:54:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.12 it/sec | Loss 0.1733 | Reco 0.1733 | Nsdr 5.304[0m
[[36m08-26 20:54:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.13 it/sec | Loss 0.1732 | Reco 0.1732 | Nsdr 5.552[0m
[[36m08-26 20:55:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.14 it/sec | Loss 0.1735 | Reco 0.1735 | Nsdr 5.575[0m
[[36m08-26 20:55:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 10.6 sec/it | Loss 0.1887 | Reco 0.1887 | Nsdr 4.869[0m
[[36m08-26 20:56:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.12 it/sec | Loss 0.1741 | Reco 0.1741 | Nsdr 5.288[0m
[[36m08-26 20:56:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.13 it/sec | Loss 0.1748 | Reco 0.1748 | Nsdr 5.490[0m
[[36m08-26 20:56:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.14 it/sec | Loss 0.1758 | Reco 0.1758 | Nsdr 5.481[0m
[[36m08-26 20:57:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 10.8 sec/it | Loss 0.1978 | Reco 0.1978 | Nsdr 4.492[0m
[[36m08-26 20:57:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.12 it/sec | Loss 0.1842 | Reco 0.1842 | Nsdr 4.858[0m
[[36m08-26 20:58:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.13 it/sec | Loss 0.1871 | Reco 0.1871 | Nsdr 4.978[0m
[[36m08-26 20:58:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.14 it/sec | Loss 0.1897 | Reco 0.1897 | Nsdr 4.912[0m
[[36m08-26 20:59:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 10.7 sec/it | Loss 0.2005 | Reco 0.2005 | Nsdr 4.376[0m
[[36m08-26 20:59:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.12 it/sec | Loss 0.1875 | Reco 0.1875 | Nsdr 4.714[0m
[[36m08-26 20:59:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.13 it/sec | Loss 0.1910 | Reco 0.1910 | Nsdr 4.814[0m
[[36m08-26 21:00:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.14 it/sec | Loss 0.1938 | Reco 0.1938 | Nsdr 4.739[0m
[[36m08-26 21:00:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 12 | Loss=0.1740 | Reco=0.1740 | Nsdr=5.472 | Best=0.1740 | Bname=ema_batch_0 | Penalty=190.1844[0m
[[36m08-26 21:00:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1740[0m
[[36m08-26 21:00:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-26 21:00:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m08-26 21:46:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 13 | 1164/4656 | 0.43 it/sec | Loss 0.1104 | Reco 0.1085 | Grad 0.1120 | Penalty 191.7627[0m
[[36m08-26 22:31:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 13 | 2328/4656 | 0.43 it/sec | Loss 0.1103 | Reco 0.1084 | Grad 0.1110 | Penalty 192.6260[0m
[[36m08-26 23:16:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 13 | 3492/4656 | 0.43 it/sec | Loss 0.1110 | Reco 0.1090 | Grad 0.1113 | Penalty 192.1813[0m
[[36m08-27 00:02:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 13 | Loss=0.1109 | Reco=0.1090 | Grad=0.1110 | Penalty=192.9601[0m
[[36m08-27 00:02:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-27 00:02:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m08-27 00:02:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 10.9 sec/it | Loss 0.1944 | Reco 0.1944 | Nsdr 4.660[0m
[[36m08-27 00:03:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 6/14 | 0.12 it/sec | Loss 0.1787 | Reco 0.1787 | Nsdr 5.089[0m
[[36m08-27 00:03:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 9/14 | 0.13 it/sec | Loss 0.1785 | Reco 0.1785 | Nsdr 5.346[0m
[[36m08-27 00:03:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 12/14 | 0.14 it/sec | Loss 0.1792 | Reco 0.1792 | Nsdr 5.331[0m
[[36m08-27 00:04:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 10.7 sec/it | Loss 0.1900 | Reco 0.1900 | Nsdr 4.855[0m
[[36m08-27 00:04:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 6/14 | 0.12 it/sec | Loss 0.1743 | Reco 0.1743 | Nsdr 5.299[0m
[[36m08-27 00:05:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 9/14 | 0.13 it/sec | Loss 0.1740 | Reco 0.1740 | Nsdr 5.537[0m
[[36m08-27 00:05:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 12/14 | 0.14 it/sec | Loss 0.1740 | Reco 0.1740 | Nsdr 5.560[0m
[[36m08-27 00:06:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 10.9 sec/it | Loss 0.1891 | Reco 0.1891 | Nsdr 4.871[0m
[[36m08-27 00:06:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 6/14 | 0.12 it/sec | Loss 0.1738 | Reco 0.1738 | Nsdr 5.314[0m
[[36m08-27 00:06:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 9/14 | 0.13 it/sec | Loss 0.1741 | Reco 0.1741 | Nsdr 5.534[0m
[[36m08-27 00:07:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 12/14 | 0.14 it/sec | Loss 0.1749 | Reco 0.1749 | Nsdr 5.532[0m
[[36m08-27 00:08:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 10.7 sec/it | Loss 0.1970 | Reco 0.1970 | Nsdr 4.525[0m
[[36m08-27 00:08:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 6/14 | 0.12 it/sec | Loss 0.1833 | Reco 0.1833 | Nsdr 4.894[0m
[[36m08-27 00:08:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 9/14 | 0.13 it/sec | Loss 0.1863 | Reco 0.1863 | Nsdr 5.014[0m
[[36m08-27 00:08:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 12/14 | 0.14 it/sec | Loss 0.1887 | Reco 0.1887 | Nsdr 4.953[0m
[[36m08-27 00:09:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 10.6 sec/it | Loss 0.2004 | Reco 0.2004 | Nsdr 4.389[0m
[[36m08-27 00:10:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 6/14 | 0.12 it/sec | Loss 0.1873 | Reco 0.1873 | Nsdr 4.725[0m
[[36m08-27 00:10:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 9/14 | 0.13 it/sec | Loss 0.1908 | Reco 0.1908 | Nsdr 4.822[0m
[[36m08-27 00:10:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 12/14 | 0.14 it/sec | Loss 0.1935 | Reco 0.1935 | Nsdr 4.751[0m
[[36m08-27 00:10:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 13 | Loss=0.1746 | Reco=0.1746 | Nsdr=5.457 | Best=0.1740 | Bname=ema_batch_0 | Penalty=200.4596[0m
[[36m08-27 00:10:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-27 00:10:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m08-27 00:56:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 14 | 1164/4656 | 0.43 it/sec | Loss 0.1121 | Reco 0.1101 | Grad 0.1088 | Penalty 200.6410[0m
[[36m08-27 01:41:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 14 | 2328/4656 | 0.43 it/sec | Loss 0.1111 | Reco 0.1091 | Grad 0.1081 | Penalty 197.7586[0m
[[36m08-27 02:27:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 14 | 3492/4656 | 0.43 it/sec | Loss 0.1109 | Reco 0.1089 | Grad 0.1075 | Penalty 197.1642[0m
[[36m08-27 03:12:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 14 | Loss=0.1106 | Reco=0.1086 | Grad=0.1073 | Penalty=196.8181[0m
[[36m08-27 03:12:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-27 03:12:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m08-27 03:13:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 3/14 | 10.8 sec/it | Loss 0.1938 | Reco 0.1938 | Nsdr 4.641[0m
[[36m08-27 03:13:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 6/14 | 0.12 it/sec | Loss 0.1793 | Reco 0.1793 | Nsdr 5.030[0m
[[36m08-27 03:14:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 9/14 | 0.13 it/sec | Loss 0.1801 | Reco 0.1801 | Nsdr 5.249[0m
[[36m08-27 03:14:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 12/14 | 0.14 it/sec | Loss 0.1796 | Reco 0.1796 | Nsdr 5.290[0m
[[36m08-27 03:15:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 3/14 | 10.7 sec/it | Loss 0.1844 | Reco 0.1844 | Nsdr 5.047[0m
[[36m08-27 03:15:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 6/14 | 0.12 it/sec | Loss 0.1711 | Reco 0.1711 | Nsdr 5.411[0m
[[36m08-27 03:15:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 9/14 | 0.13 it/sec | Loss 0.1711 | Reco 0.1711 | Nsdr 5.657[0m
[[36m08-27 03:16:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 12/14 | 0.14 it/sec | Loss 0.1713 | Reco 0.1713 | Nsdr 5.680[0m
[[36m08-27 03:16:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 3/14 | 10.5 sec/it | Loss 0.1878 | Reco 0.1878 | Nsdr 4.933[0m
[[36m08-27 03:17:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 6/14 | 0.12 it/sec | Loss 0.1730 | Reco 0.1730 | Nsdr 5.356[0m
[[36m08-27 03:17:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 9/14 | 0.13 it/sec | Loss 0.1729 | Reco 0.1729 | Nsdr 5.596[0m
[[36m08-27 03:17:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 12/14 | 0.14 it/sec | Loss 0.1734 | Reco 0.1734 | Nsdr 5.607[0m
[[36m08-27 03:18:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 3/14 | 10.7 sec/it | Loss 0.1966 | Reco 0.1966 | Nsdr 4.550[0m
[[36m08-27 03:18:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 6/14 | 0.12 it/sec | Loss 0.1827 | Reco 0.1827 | Nsdr 4.920[0m
[[36m08-27 03:19:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 9/14 | 0.13 it/sec | Loss 0.1857 | Reco 0.1857 | Nsdr 5.042[0m
[[36m08-27 03:19:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 12/14 | 0.14 it/sec | Loss 0.1879 | Reco 0.1879 | Nsdr 4.990[0m
[[36m08-27 03:20:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 3/14 | 10.8 sec/it | Loss 0.2000 | Reco 0.2000 | Nsdr 4.407[0m
[[36m08-27 03:20:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 6/14 | 0.12 it/sec | Loss 0.1869 | Reco 0.1869 | Nsdr 4.739[0m
[[36m08-27 03:20:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 9/14 | 0.13 it/sec | Loss 0.1905 | Reco 0.1905 | Nsdr 4.836[0m
[[36m08-27 03:21:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 12/14 | 0.14 it/sec | Loss 0.1932 | Reco 0.1932 | Nsdr 4.768[0m
[[36m08-27 03:21:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 14 | Loss=0.1721 | Reco=0.1721 | Nsdr=5.571 | Best=0.1721 | Bname=ema_batch_0 | Penalty=200.0208[0m
[[36m08-27 03:21:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1721[0m
[[36m08-27 03:21:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-27 03:21:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m08-27 04:07:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 15 | 1164/4656 | 0.42 it/sec | Loss 0.1112 | Reco 0.1092 | Grad 0.1023 | Penalty 197.9067[0m
[[36m08-27 04:52:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 15 | 2328/4656 | 0.43 it/sec | Loss 0.1103 | Reco 0.1084 | Grad 0.1046 | Penalty 196.5870[0m
[[36m08-27 05:38:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 15 | 3492/4656 | 0.43 it/sec | Loss 0.1100 | Reco 0.1080 | Grad 0.1045 | Penalty 196.5809[0m
[[36m08-27 06:23:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 15 | Loss=0.1097 | Reco=0.1077 | Grad=0.1046 | Penalty=196.8861[0m
[[36m08-27 06:23:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-27 06:23:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m08-27 06:24:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 3/14 | 10.5 sec/it | Loss 0.1881 | Reco 0.1881 | Nsdr 4.841[0m
[[36m08-27 06:24:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 6/14 | 0.12 it/sec | Loss 0.1747 | Reco 0.1747 | Nsdr 5.155[0m
[[36m08-27 06:24:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 9/14 | 0.13 it/sec | Loss 0.1752 | Reco 0.1752 | Nsdr 5.374[0m
[[36m08-27 06:25:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 12/14 | 0.14 it/sec | Loss 0.1751 | Reco 0.1751 | Nsdr 5.427[0m
[[36m08-27 06:25:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 3/14 | 11.1 sec/it | Loss 0.1852 | Reco 0.1852 | Nsdr 5.026[0m
[[36m08-27 06:26:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 6/14 | 0.12 it/sec | Loss 0.1715 | Reco 0.1715 | Nsdr 5.407[0m
[[36m08-27 06:26:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 9/14 | 0.13 it/sec | Loss 0.1714 | Reco 0.1714 | Nsdr 5.652[0m
[[36m08-27 06:26:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 12/14 | 0.14 it/sec | Loss 0.1717 | Reco 0.1717 | Nsdr 5.668[0m
[[36m08-27 06:27:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 3/14 | 10.5 sec/it | Loss 0.1869 | Reco 0.1869 | Nsdr 4.969[0m
[[36m08-27 06:27:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 6/14 | 0.12 it/sec | Loss 0.1723 | Reco 0.1723 | Nsdr 5.390[0m
[[36m08-27 06:28:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 9/14 | 0.13 it/sec | Loss 0.1724 | Reco 0.1724 | Nsdr 5.612[0m
[[36m08-27 06:28:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 12/14 | 0.14 it/sec | Loss 0.1728 | Reco 0.1728 | Nsdr 5.624[0m
[[36m08-27 06:29:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 3/14 | 10.5 sec/it | Loss 0.1953 | Reco 0.1953 | Nsdr 4.610[0m
[[36m08-27 06:29:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 6/14 | 0.12 it/sec | Loss 0.1818 | Reco 0.1818 | Nsdr 4.968[0m
[[36m08-27 06:29:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 9/14 | 0.13 it/sec | Loss 0.1846 | Reco 0.1846 | Nsdr 5.090[0m
[[36m08-27 06:30:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 12/14 | 0.14 it/sec | Loss 0.1868 | Reco 0.1868 | Nsdr 5.042[0m
[[36m08-27 06:31:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 3/14 | 10.5 sec/it | Loss 0.1991 | Reco 0.1991 | Nsdr 4.439[0m
[[36m08-27 06:31:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 6/14 | 0.12 it/sec | Loss 0.1864 | Reco 0.1864 | Nsdr 4.762[0m
[[36m08-27 06:31:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 9/14 | 0.13 it/sec | Loss 0.1901 | Reco 0.1901 | Nsdr 4.859[0m
[[36m08-27 06:31:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 12/14 | 0.14 it/sec | Loss 0.1926 | Reco 0.1926 | Nsdr 4.797[0m
[[36m08-27 06:32:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 15 | Loss=0.1725 | Reco=0.1725 | Nsdr=5.559 | Best=0.1721 | Bname=ema_batch_0 | Penalty=206.3172[0m
[[36m08-27 06:32:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-27 06:32:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m08-27 07:17:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 16 | 1164/4656 | 0.43 it/sec | Loss 0.1091 | Reco 0.1071 | Grad 0.1052 | Penalty 204.3673[0m
[[36m08-27 08:03:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 16 | 2328/4656 | 0.43 it/sec | Loss 0.1090 | Reco 0.1070 | Grad 0.1052 | Penalty 206.7252[0m
[[36m08-27 08:48:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 16 | 3492/4656 | 0.43 it/sec | Loss 0.1083 | Reco 0.1063 | Grad 0.1059 | Penalty 205.7953[0m
[[36m08-27 09:33:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 16 | Loss=0.1087 | Reco=0.1066 | Grad=0.1074 | Penalty=204.5904[0m
[[36m08-27 09:33:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-27 09:33:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m08-27 09:34:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 3/14 | 10.6 sec/it | Loss 0.1916 | Reco 0.1916 | Nsdr 4.812[0m
[[36m08-27 09:34:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 6/14 | 0.12 it/sec | Loss 0.1783 | Reco 0.1783 | Nsdr 5.149[0m
[[36m08-27 09:35:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 9/14 | 0.13 it/sec | Loss 0.1789 | Reco 0.1789 | Nsdr 5.344[0m
[[36m08-27 09:35:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 12/14 | 0.14 it/sec | Loss 0.1785 | Reco 0.1785 | Nsdr 5.394[0m
[[36m08-27 09:36:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 3/14 | 10.7 sec/it | Loss 0.1829 | Reco 0.1829 | Nsdr 5.103[0m
[[36m08-27 09:36:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 6/14 | 0.12 it/sec | Loss 0.1705 | Reco 0.1705 | Nsdr 5.427[0m
[[36m08-27 09:36:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 9/14 | 0.13 it/sec | Loss 0.1707 | Reco 0.1707 | Nsdr 5.672[0m
[[36m08-27 09:37:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 12/14 | 0.14 it/sec | Loss 0.1706 | Reco 0.1706 | Nsdr 5.710[0m
[[36m08-27 09:37:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 3/14 | 10.7 sec/it | Loss 0.1846 | Reco 0.1846 | Nsdr 5.063[0m
[[36m08-27 09:38:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 6/14 | 0.12 it/sec | Loss 0.1711 | Reco 0.1711 | Nsdr 5.438[0m
[[36m08-27 09:38:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 9/14 | 0.13 it/sec | Loss 0.1713 | Reco 0.1713 | Nsdr 5.666[0m
[[36m08-27 09:38:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 12/14 | 0.14 it/sec | Loss 0.1715 | Reco 0.1715 | Nsdr 5.685[0m
[[36m08-27 09:39:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 3/14 | 10.8 sec/it | Loss 0.1953 | Reco 0.1953 | Nsdr 4.616[0m
[[36m08-27 09:39:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 6/14 | 0.12 it/sec | Loss 0.1816 | Reco 0.1816 | Nsdr 4.980[0m
[[36m08-27 09:40:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 9/14 | 0.13 it/sec | Loss 0.1842 | Reco 0.1842 | Nsdr 5.115[0m
[[36m08-27 09:40:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 12/14 | 0.14 it/sec | Loss 0.1860 | Reco 0.1860 | Nsdr 5.082[0m
[[36m08-27 09:41:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 3/14 | 10.9 sec/it | Loss 0.1991 | Reco 0.1991 | Nsdr 4.455[0m
[[36m08-27 09:41:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 6/14 | 0.12 it/sec | Loss 0.1863 | Reco 0.1863 | Nsdr 4.774[0m
[[36m08-27 09:41:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 9/14 | 0.13 it/sec | Loss 0.1898 | Reco 0.1898 | Nsdr 4.878[0m
[[36m08-27 09:42:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 12/14 | 0.14 it/sec | Loss 0.1922 | Reco 0.1922 | Nsdr 4.823[0m
[[36m08-27 09:42:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 16 | Loss=0.1714 | Reco=0.1714 | Nsdr=5.601 | Best=0.1714 | Bname=ema_batch_0 | Penalty=207.0594[0m
[[36m08-27 09:42:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1714[0m
[[36m08-27 09:42:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-27 09:42:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m08-27 10:27:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 17 | 1164/4656 | 0.43 it/sec | Loss 0.1088 | Reco 0.1068 | Grad 0.1022 | Penalty 201.3713[0m
[[36m08-27 11:13:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 17 | 2328/4656 | 0.43 it/sec | Loss 0.1085 | Reco 0.1064 | Grad 0.1028 | Penalty 201.8147[0m
[[36m08-27 11:58:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 17 | 3492/4656 | 0.43 it/sec | Loss 0.1090 | Reco 0.1067 | Grad 0.1061 | Penalty 229.8512[0m
[[36m08-27 12:44:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 17 | Loss=0.1087 | Reco=0.1065 | Grad=0.1054 | Penalty=226.1860[0m
[[36m08-27 12:44:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-27 12:44:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m08-27 12:44:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 3/14 | 11.0 sec/it | Loss 0.1870 | Reco 0.1870 | Nsdr 4.947[0m
[[36m08-27 12:45:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 6/14 | 0.12 it/sec | Loss 0.1750 | Reco 0.1750 | Nsdr 5.256[0m
[[36m08-27 12:45:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 9/14 | 0.13 it/sec | Loss 0.1752 | Reco 0.1752 | Nsdr 5.475[0m
[[36m08-27 12:45:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 12/14 | 0.14 it/sec | Loss 0.1750 | Reco 0.1750 | Nsdr 5.514[0m
[[36m08-27 12:46:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 3/14 | 10.7 sec/it | Loss 0.1839 | Reco 0.1839 | Nsdr 5.095[0m
[[36m08-27 12:46:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 6/14 | 0.12 it/sec | Loss 0.1714 | Reco 0.1714 | Nsdr 5.430[0m
[[36m08-27 12:47:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 9/14 | 0.13 it/sec | Loss 0.1715 | Reco 0.1715 | Nsdr 5.654[0m
[[36m08-27 12:47:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 12/14 | 0.14 it/sec | Loss 0.1710 | Reco 0.1710 | Nsdr 5.704[0m
[[36m08-27 12:48:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 3/14 | 10.7 sec/it | Loss 0.1857 | Reco 0.1857 | Nsdr 5.037[0m
[[36m08-27 12:48:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 6/14 | 0.12 it/sec | Loss 0.1715 | Reco 0.1715 | Nsdr 5.428[0m
[[36m08-27 12:48:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 9/14 | 0.13 it/sec | Loss 0.1714 | Reco 0.1714 | Nsdr 5.663[0m
[[36m08-27 12:49:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 12/14 | 0.14 it/sec | Loss 0.1713 | Reco 0.1713 | Nsdr 5.700[0m
[[36m08-27 12:49:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 3/14 | 10.6 sec/it | Loss 0.1944 | Reco 0.1944 | Nsdr 4.665[0m
[[36m08-27 12:50:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 6/14 | 0.12 it/sec | Loss 0.1810 | Reco 0.1810 | Nsdr 5.017[0m
[[36m08-27 12:50:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 9/14 | 0.13 it/sec | Loss 0.1831 | Reco 0.1831 | Nsdr 5.172[0m
[[36m08-27 12:50:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 12/14 | 0.14 it/sec | Loss 0.1847 | Reco 0.1847 | Nsdr 5.148[0m
[[36m08-27 12:51:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 3/14 | 10.7 sec/it | Loss 0.1993 | Reco 0.1993 | Nsdr 4.449[0m
[[36m08-27 12:51:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 6/14 | 0.12 it/sec | Loss 0.1864 | Reco 0.1864 | Nsdr 4.772[0m
[[36m08-27 12:52:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 9/14 | 0.13 it/sec | Loss 0.1897 | Reco 0.1897 | Nsdr 4.882[0m
[[36m08-27 12:52:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 12/14 | 0.14 it/sec | Loss 0.1919 | Reco 0.1919 | Nsdr 4.836[0m
[[36m08-27 12:52:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 17 | Loss=0.1719 | Reco=0.1719 | Nsdr=5.587 | Best=0.1714 | Bname=ema_batch_0 | Penalty=214.0710[0m
[[36m08-27 12:52:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-27 12:52:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m08-27 13:38:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 18 | 1164/4656 | 0.43 it/sec | Loss 0.1071 | Reco 0.1050 | Grad 0.1055 | Penalty 208.4747[0m
[[36m08-27 14:24:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 18 | 2328/4656 | 0.43 it/sec | Loss 0.1075 | Reco 0.1055 | Grad 0.1039 | Penalty 206.7789[0m
[[36m08-27 15:09:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 18 | 3492/4656 | 0.43 it/sec | Loss 0.1073 | Reco 0.1052 | Grad 0.1063 | Penalty 205.4607[0m
[[36m08-27 15:54:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 18 | Loss=0.1072 | Reco=0.1051 | Grad=0.1071 | Penalty=204.7018[0m
[[36m08-27 15:54:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-27 15:54:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m08-27 15:55:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 3/14 | 10.7 sec/it | Loss 0.1839 | Reco 0.1839 | Nsdr 5.015[0m
[[36m08-27 15:55:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 6/14 | 0.12 it/sec | Loss 0.1735 | Reco 0.1735 | Nsdr 5.295[0m
[[36m08-27 15:56:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 9/14 | 0.13 it/sec | Loss 0.1729 | Reco 0.1729 | Nsdr 5.562[0m
[[36m08-27 15:56:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 12/14 | 0.14 it/sec | Loss 0.1739 | Reco 0.1739 | Nsdr 5.560[0m
[[36m08-27 15:57:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 3/14 | 11.1 sec/it | Loss 0.1833 | Reco 0.1833 | Nsdr 5.127[0m
[[36m08-27 15:57:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 6/14 | 0.12 it/sec | Loss 0.1707 | Reco 0.1707 | Nsdr 5.466[0m
[[36m08-27 15:57:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 9/14 | 0.13 it/sec | Loss 0.1704 | Reco 0.1704 | Nsdr 5.703[0m
[[36m08-27 15:58:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 12/14 | 0.14 it/sec | Loss 0.1698 | Reco 0.1698 | Nsdr 5.760[0m
[[36m08-27 15:59:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 3/14 | 10.9 sec/it | Loss 0.1840 | Reco 0.1840 | Nsdr 5.101[0m
[[36m08-27 15:59:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 6/14 | 0.12 it/sec | Loss 0.1709 | Reco 0.1709 | Nsdr 5.461[0m
[[36m08-27 15:59:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 9/14 | 0.13 it/sec | Loss 0.1708 | Reco 0.1708 | Nsdr 5.695[0m
[[36m08-27 15:59:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 12/14 | 0.14 it/sec | Loss 0.1706 | Reco 0.1706 | Nsdr 5.737[0m
[[36m08-27 16:00:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 3/14 | 10.8 sec/it | Loss 0.1940 | Reco 0.1940 | Nsdr 4.681[0m
[[36m08-27 16:01:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 6/14 | 0.12 it/sec | Loss 0.1807 | Reco 0.1807 | Nsdr 5.034[0m
[[36m08-27 16:01:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 9/14 | 0.13 it/sec | Loss 0.1828 | Reco 0.1828 | Nsdr 5.183[0m
[[36m08-27 16:01:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 12/14 | 0.14 it/sec | Loss 0.1842 | Reco 0.1842 | Nsdr 5.168[0m
[[36m08-27 16:02:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 3/14 | 11.2 sec/it | Loss 0.1986 | Reco 0.1986 | Nsdr 4.477[0m
[[36m08-27 16:02:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 6/14 | 0.12 it/sec | Loss 0.1862 | Reco 0.1862 | Nsdr 4.784[0m
[[36m08-27 16:03:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 9/14 | 0.12 it/sec | Loss 0.1893 | Reco 0.1893 | Nsdr 4.902[0m
[[36m08-27 16:03:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 12/14 | 0.13 it/sec | Loss 0.1914 | Reco 0.1914 | Nsdr 4.862[0m
[[36m08-27 16:03:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 18 | Loss=0.1705 | Reco=0.1705 | Nsdr=5.660 | Best=0.1705 | Bname=ema_batch_0 | Penalty=204.4495[0m
[[36m08-27 16:03:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1705[0m
[[36m08-27 16:03:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-27 16:03:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m08-27 16:49:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 19 | 1164/4656 | 0.43 it/sec | Loss 0.1079 | Reco 0.1058 | Grad 0.1071 | Penalty 204.6276[0m
[[36m08-27 17:34:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 19 | 2328/4656 | 0.43 it/sec | Loss 0.1077 | Reco 0.1056 | Grad 0.1046 | Penalty 206.8276[0m
[[36m08-27 18:20:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 19 | 3492/4656 | 0.43 it/sec | Loss 0.1068 | Reco 0.1047 | Grad 0.1031 | Penalty 206.0471[0m
[[36m08-27 19:05:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 19 | Loss=0.1070 | Reco=0.1049 | Grad=0.1033 | Penalty=205.7506[0m
[[36m08-27 19:05:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-27 19:05:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m08-27 19:06:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 3/14 | 10.6 sec/it | Loss 0.1859 | Reco 0.1859 | Nsdr 4.970[0m
[[36m08-27 19:06:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 6/14 | 0.12 it/sec | Loss 0.1765 | Reco 0.1765 | Nsdr 5.180[0m
[[36m08-27 19:07:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 9/14 | 0.13 it/sec | Loss 0.1764 | Reco 0.1764 | Nsdr 5.426[0m
[[36m08-27 19:07:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 12/14 | 0.14 it/sec | Loss 0.1758 | Reco 0.1758 | Nsdr 5.475[0m
[[36m08-27 19:08:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 3/14 | 11.0 sec/it | Loss 0.1786 | Reco 0.1786 | Nsdr 5.314[0m
[[36m08-27 19:08:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 6/14 | 0.12 it/sec | Loss 0.1683 | Reco 0.1683 | Nsdr 5.562[0m
[[36m08-27 19:08:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 9/14 | 0.13 it/sec | Loss 0.1683 | Reco 0.1683 | Nsdr 5.804[0m
[[36m08-27 19:09:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 12/14 | 0.14 it/sec | Loss 0.1677 | Reco 0.1677 | Nsdr 5.866[0m
[[36m08-27 19:10:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 3/14 | 10.9 sec/it | Loss 0.1816 | Reco 0.1816 | Nsdr 5.199[0m
[[36m08-27 19:10:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 6/14 | 0.12 it/sec | Loss 0.1697 | Reco 0.1697 | Nsdr 5.517[0m
[[36m08-27 19:10:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 9/14 | 0.13 it/sec | Loss 0.1698 | Reco 0.1698 | Nsdr 5.739[0m
[[36m08-27 19:10:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 12/14 | 0.14 it/sec | Loss 0.1694 | Reco 0.1694 | Nsdr 5.790[0m
[[36m08-27 19:11:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 3/14 | 10.9 sec/it | Loss 0.1924 | Reco 0.1924 | Nsdr 4.755[0m
[[36m08-27 19:12:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 6/14 | 0.12 it/sec | Loss 0.1798 | Reco 0.1798 | Nsdr 5.082[0m
[[36m08-27 19:12:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 9/14 | 0.13 it/sec | Loss 0.1818 | Reco 0.1818 | Nsdr 5.233[0m
[[36m08-27 19:12:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 12/14 | 0.14 it/sec | Loss 0.1831 | Reco 0.1831 | Nsdr 5.224[0m
[[36m08-27 19:13:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 3/14 | 11.0 sec/it | Loss 0.1977 | Reco 0.1977 | Nsdr 4.519[0m
[[36m08-27 19:13:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 6/14 | 0.12 it/sec | Loss 0.1859 | Reco 0.1859 | Nsdr 4.805[0m
[[36m08-27 19:14:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 9/14 | 0.13 it/sec | Loss 0.1890 | Reco 0.1890 | Nsdr 4.925[0m
[[36m08-27 19:14:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 12/14 | 0.14 it/sec | Loss 0.1909 | Reco 0.1909 | Nsdr 4.892[0m
[[36m08-27 19:14:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 19 | Loss=0.1684 | Reco=0.1684 | Nsdr=5.759 | Best=0.1684 | Bname=ema_batch_0 | Penalty=210.9054[0m
[[36m08-27 19:14:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1684[0m
[[36m08-27 19:14:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-27 19:14:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m08-27 20:00:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 20 | 1164/4656 | 0.43 it/sec | Loss 0.1064 | Reco 0.1043 | Grad 0.1009 | Penalty 208.7576[0m
[[36m08-27 20:45:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 20 | 2328/4656 | 0.43 it/sec | Loss 0.1064 | Reco 0.1044 | Grad 0.1018 | Penalty 208.2861[0m
[[36m08-27 21:31:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 20 | 3492/4656 | 0.43 it/sec | Loss 0.1062 | Reco 0.1041 | Grad 0.1015 | Penalty 207.1415[0m
[[36m08-27 22:16:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 20 | Loss=0.1059 | Reco=0.1039 | Grad=0.1011 | Penalty=206.4077[0m
[[36m08-27 22:16:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-27 22:16:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m08-27 22:17:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 3/14 | 10.5 sec/it | Loss 0.1789 | Reco 0.1789 | Nsdr 5.278[0m
[[36m08-27 22:17:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 6/14 | 0.12 it/sec | Loss 0.1679 | Reco 0.1679 | Nsdr 5.553[0m
[[36m08-27 22:18:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 9/14 | 0.13 it/sec | Loss 0.1699 | Reco 0.1699 | Nsdr 5.706[0m
[[36m08-27 22:18:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 12/14 | 0.14 it/sec | Loss 0.1699 | Reco 0.1699 | Nsdr 5.757[0m
[[36m08-27 22:19:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 3/14 | 10.6 sec/it | Loss 0.1784 | Reco 0.1784 | Nsdr 5.312[0m
[[36m08-27 22:19:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 6/14 | 0.12 it/sec | Loss 0.1676 | Reco 0.1676 | Nsdr 5.597[0m
[[36m08-27 22:19:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 9/14 | 0.13 it/sec | Loss 0.1679 | Reco 0.1679 | Nsdr 5.818[0m
[[36m08-27 22:20:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 12/14 | 0.14 it/sec | Loss 0.1674 | Reco 0.1674 | Nsdr 5.876[0m
[[36m08-27 22:20:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 3/14 | 11.0 sec/it | Loss 0.1810 | Reco 0.1810 | Nsdr 5.229[0m
[[36m08-27 22:21:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 6/14 | 0.12 it/sec | Loss 0.1687 | Reco 0.1687 | Nsdr 5.558[0m
[[36m08-27 22:21:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 9/14 | 0.13 it/sec | Loss 0.1686 | Reco 0.1686 | Nsdr 5.791[0m
[[36m08-27 22:21:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 12/14 | 0.14 it/sec | Loss 0.1683 | Reco 0.1683 | Nsdr 5.843[0m
[[36m08-27 22:22:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 3/14 | 11.0 sec/it | Loss 0.1910 | Reco 0.1910 | Nsdr 4.815[0m
[[36m08-27 22:22:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 6/14 | 0.12 it/sec | Loss 0.1786 | Reco 0.1786 | Nsdr 5.135[0m
[[36m08-27 22:23:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 9/14 | 0.13 it/sec | Loss 0.1806 | Reco 0.1806 | Nsdr 5.290[0m
[[36m08-27 22:23:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 12/14 | 0.14 it/sec | Loss 0.1817 | Reco 0.1817 | Nsdr 5.285[0m
[[36m08-27 22:24:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 3/14 | 10.7 sec/it | Loss 0.1972 | Reco 0.1972 | Nsdr 4.546[0m
[[36m08-27 22:24:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 6/14 | 0.12 it/sec | Loss 0.1854 | Reco 0.1854 | Nsdr 4.829[0m
[[36m08-27 22:24:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 9/14 | 0.13 it/sec | Loss 0.1885 | Reco 0.1885 | Nsdr 4.951[0m
[[36m08-27 22:25:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 12/14 | 0.14 it/sec | Loss 0.1903 | Reco 0.1903 | Nsdr 4.919[0m
[[36m08-27 22:25:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 20 | Loss=0.1681 | Reco=0.1681 | Nsdr=5.773 | Best=0.1681 | Bname=ema_batch_0 | Penalty=206.9790[0m
[[36m08-27 22:25:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1681[0m
[[36m08-27 22:25:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m08-27 22:25:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Evaluating on the test set...[0m
[[36m08-27 22:26:03[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval | 2/10 | 13.4 sec/it[0m
[[36m08-27 22:26:31[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval | 4/10 | 13.6 sec/it[0m
[[36m08-27 22:27:03[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval | 6/10 | 14.3 sec/it[0m
[[36m08-27 22:27:35[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval | 8/10 | 14.7 sec/it[0m
[[36m08-27 22:39:22[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval (BSS) | 2/10 | 231.2 sec/it[0m
[[36m08-27 22:45:19[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval (BSS) | 4/10 | 210.1 sec/it[0m
[[36m08-27 22:52:39[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval (BSS) | 6/10 | 213.0 sec/it[0m
[[36m08-27 23:00:33[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval (BSS) | 8/10 | 218.3 sec/it[0m
[[36m08-27 23:02:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTest Summary | Epoch 20 | Sdr=4.445 | Nsdr=4.907 | Sdr_drums=6.419 | Nsdr_drums=6.329 | Sdr_bass=3.688 | Nsdr_bass=4.087 | Sdr_other=2.307 | Nsdr_other=2.973 | Sdr_vocals=5.367 | Nsdr_vocals=6.239[0m
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mParser[0m Injecting argv ['hdemucs.norm_starts=999', 'hdemucs.cac=False', 'test.split=True', 'valid_apply=True', 'model=hdemucs', 'hdemucs.dconv_lstm=4', 'ema.epoch=[0.9, 0.95]', 'ema.batch=[0.9995, 0.9999]', 'seed=42', 'hdemucs.hybrid_old=True', 'svd=base', 'svd.penalty=1e-05', 'svd.dim=100', 'svd.convtr=True', 'optim.lr=0.0005'] from sig 81de367c
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mLaunch:[0m Removing existing XP folder.
[1mExecutor:[0m Starting 1 worker processes for DDP.
[1mExecutor:[0m All workers completed successfully
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:228: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  return hydra.main(
[[36m09-07 19:47:33[0m][[34mdemucs.train[0m][[32mINFO[0m] - For logs, checkpoints and samples check /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/a68eaf9b[0m
[[36m09-07 19:47:33[0m][[34mdora.distrib[0m][[32mINFO[0m] - world_size is 1, skipping init.[0m
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
/home/paperspace/.local/lib/python3.8/site-packages/musdb/configs/mus.yaml
[[36m09-07 19:47:42[0m][[34mdemucs.train[0m][[32mINFO[0m] - train/valid set size: 18626 14[0m
[[36m09-07 19:47:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Loading from /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/22d99e8f/checkpoint.th[0m
[[36m09-07 19:47:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-07 19:47:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
/home/paperspace/.local/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
/home/paperspace/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
[[36m09-07 20:33:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 1 | 1164/4656 | 0.43 it/sec | Loss 0.1051 | Reco 0.1031 | Grad 0.1022 | Penalty 198.9982[0m
[[36m09-07 21:18:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 1 | 2328/4656 | 0.43 it/sec | Loss 0.1049 | Reco 0.1029 | Grad 0.1007 | Penalty 200.4118[0m
[[36m09-07 22:03:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 1 | 3492/4656 | 0.43 it/sec | Loss 0.1053 | Reco 0.1033 | Grad 0.1012 | Penalty 202.7491[0m
[[36m09-07 22:48:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 1 | Loss=0.1052 | Reco=0.1032 | Grad=0.1010 | Penalty=203.9082[0m
[[36m09-07 22:48:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-07 22:48:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-07 22:49:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 3/14 | 11.3 sec/it | Loss 0.1920 | Reco 0.1920 | Nsdr 4.804[0m
[[36m09-07 22:49:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 6/14 | 0.12 it/sec | Loss 0.1767 | Reco 0.1767 | Nsdr 5.233[0m
[[36m09-07 22:49:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 9/14 | 0.13 it/sec | Loss 0.1749 | Reco 0.1749 | Nsdr 5.534[0m
[[36m09-07 22:50:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 12/14 | 0.14 it/sec | Loss 0.1735 | Reco 0.1735 | Nsdr 5.612[0m
[[36m09-07 22:50:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 3/14 | 11.1 sec/it | Loss 0.1819 | Reco 0.1819 | Nsdr 5.171[0m
[[36m09-07 22:51:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 6/14 | 0.12 it/sec | Loss 0.1690 | Reco 0.1690 | Nsdr 5.527[0m
[[36m09-07 22:51:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 9/14 | 0.13 it/sec | Loss 0.1688 | Reco 0.1688 | Nsdr 5.763[0m
[[36m09-07 22:51:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 12/14 | 0.14 it/sec | Loss 0.1677 | Reco 0.1677 | Nsdr 5.858[0m
[[36m09-07 22:52:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 3/14 | 11.1 sec/it | Loss 0.1818 | Reco 0.1818 | Nsdr 5.178[0m
[[36m09-07 22:52:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 6/14 | 0.12 it/sec | Loss 0.1690 | Reco 0.1690 | Nsdr 5.526[0m
[[36m09-07 22:53:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 9/14 | 0.13 it/sec | Loss 0.1685 | Reco 0.1685 | Nsdr 5.785[0m
[[36m09-07 22:53:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 12/14 | 0.14 it/sec | Loss 0.1675 | Reco 0.1675 | Nsdr 5.870[0m
[[36m09-07 22:54:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 3/14 | 10.7 sec/it | Loss 0.1920 | Reco 0.1920 | Nsdr 4.812[0m
[[36m09-07 22:54:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 6/14 | 0.12 it/sec | Loss 0.1768 | Reco 0.1768 | Nsdr 5.236[0m
[[36m09-07 22:54:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 9/14 | 0.13 it/sec | Loss 0.1751 | Reco 0.1751 | Nsdr 5.526[0m
[[36m09-07 22:55:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 12/14 | 0.14 it/sec | Loss 0.1737 | Reco 0.1737 | Nsdr 5.604[0m
[[36m09-07 22:56:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 3/14 | 11.0 sec/it | Loss 0.1922 | Reco 0.1922 | Nsdr 4.800[0m
[[36m09-07 22:56:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 6/14 | 0.12 it/sec | Loss 0.1768 | Reco 0.1768 | Nsdr 5.229[0m
[[36m09-07 22:56:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 9/14 | 0.13 it/sec | Loss 0.1752 | Reco 0.1752 | Nsdr 5.521[0m
[[36m09-07 22:56:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 12/14 | 0.14 it/sec | Loss 0.1737 | Reco 0.1737 | Nsdr 5.603[0m
[[36m09-07 22:57:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 1 | Loss=0.1682 | Reco=0.1682 | Nsdr=5.765 | Best=0.1682 | Bname=ema_batch_1 | Penalty=209.1086[0m
[[36m09-07 22:57:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1682[0m
[[36m09-07 22:57:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-07 22:57:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-07 23:42:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 2 | 1164/4656 | 0.43 it/sec | Loss 0.1060 | Reco 0.1039 | Grad 0.1025 | Penalty 209.4350[0m
[[36m09-08 00:28:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 2 | 2328/4656 | 0.42 it/sec | Loss 0.1053 | Reco 0.1032 | Grad 0.1015 | Penalty 208.6080[0m
[[36m09-08 01:14:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 2 | 3492/4656 | 0.42 it/sec | Loss 0.1055 | Reco 0.1034 | Grad 0.1012 | Penalty 209.2138[0m
[[36m09-08 01:59:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 2 | Loss=0.1056 | Reco=0.1035 | Grad=0.1017 | Penalty=209.8279[0m
[[36m09-08 01:59:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-08 01:59:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-08 02:00:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 3/14 | 11.0 sec/it | Loss 0.1911 | Reco 0.1911 | Nsdr 4.827[0m
[[36m09-08 02:00:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 6/14 | 0.12 it/sec | Loss 0.1751 | Reco 0.1751 | Nsdr 5.283[0m
[[36m09-08 02:01:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 9/14 | 0.13 it/sec | Loss 0.1759 | Reco 0.1759 | Nsdr 5.440[0m
[[36m09-08 02:01:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 12/14 | 0.14 it/sec | Loss 0.1748 | Reco 0.1748 | Nsdr 5.516[0m
[[36m09-08 02:02:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 3/14 | 10.8 sec/it | Loss 0.1816 | Reco 0.1816 | Nsdr 5.191[0m
[[36m09-08 02:02:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 6/14 | 0.12 it/sec | Loss 0.1685 | Reco 0.1685 | Nsdr 5.553[0m
[[36m09-08 02:02:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 9/14 | 0.13 it/sec | Loss 0.1682 | Reco 0.1682 | Nsdr 5.790[0m
[[36m09-08 02:03:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 12/14 | 0.14 it/sec | Loss 0.1670 | Reco 0.1670 | Nsdr 5.882[0m
[[36m09-08 02:04:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 3/14 | 10.9 sec/it | Loss 0.1822 | Reco 0.1822 | Nsdr 5.182[0m
[[36m09-08 02:04:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 6/14 | 0.12 it/sec | Loss 0.1686 | Reco 0.1686 | Nsdr 5.558[0m
[[36m09-08 02:04:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 9/14 | 0.13 it/sec | Loss 0.1679 | Reco 0.1679 | Nsdr 5.822[0m
[[36m09-08 02:04:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 12/14 | 0.14 it/sec | Loss 0.1669 | Reco 0.1669 | Nsdr 5.906[0m
[[36m09-08 02:05:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 3/14 | 11.0 sec/it | Loss 0.1886 | Reco 0.1886 | Nsdr 4.953[0m
[[36m09-08 02:06:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 6/14 | 0.12 it/sec | Loss 0.1730 | Reco 0.1730 | Nsdr 5.404[0m
[[36m09-08 02:06:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 9/14 | 0.13 it/sec | Loss 0.1726 | Reco 0.1726 | Nsdr 5.618[0m
[[36m09-08 02:06:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 12/14 | 0.14 it/sec | Loss 0.1713 | Reco 0.1713 | Nsdr 5.701[0m
[[36m09-08 02:07:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 3/14 | 11.0 sec/it | Loss 0.1888 | Reco 0.1888 | Nsdr 4.945[0m
[[36m09-08 02:07:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 6/14 | 0.12 it/sec | Loss 0.1732 | Reco 0.1732 | Nsdr 5.397[0m
[[36m09-08 02:08:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 9/14 | 0.13 it/sec | Loss 0.1726 | Reco 0.1726 | Nsdr 5.630[0m
[[36m09-08 02:08:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 12/14 | 0.14 it/sec | Loss 0.1712 | Reco 0.1712 | Nsdr 5.712[0m
[[36m09-08 02:08:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 2 | Loss=0.1676 | Reco=0.1676 | Nsdr=5.797 | Best=0.1676 | Bname=ema_batch_1 | Penalty=216.1688[0m
[[36m09-08 02:08:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1676[0m
[[36m09-08 02:08:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-08 02:08:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-08 02:54:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 3 | 1164/4656 | 0.42 it/sec | Loss 0.1044 | Reco 0.1023 | Grad 0.1051 | Penalty 211.2520[0m
[[36m09-08 03:40:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 3 | 2328/4656 | 0.42 it/sec | Loss 0.1049 | Reco 0.1028 | Grad 0.1038 | Penalty 210.8058[0m
[[36m09-08 04:25:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 3 | 3492/4656 | 0.42 it/sec | Loss 0.1049 | Reco 0.1028 | Grad 0.1021 | Penalty 210.0287[0m
[[36m09-08 05:11:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 3 | Loss=0.1044 | Reco=0.1023 | Grad=0.1006 | Penalty=211.2338[0m
[[36m09-08 05:11:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-08 05:11:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-08 05:12:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 3/14 | 11.4 sec/it | Loss 0.1855 | Reco 0.1855 | Nsdr 5.001[0m
[[36m09-08 05:12:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 6/14 | 0.12 it/sec | Loss 0.1739 | Reco 0.1739 | Nsdr 5.264[0m
[[36m09-08 05:12:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 9/14 | 0.12 it/sec | Loss 0.1731 | Reco 0.1731 | Nsdr 5.554[0m
[[36m09-08 05:12:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 12/14 | 0.14 it/sec | Loss 0.1721 | Reco 0.1721 | Nsdr 5.634[0m
[[36m09-08 05:13:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 3/14 | 11.5 sec/it | Loss 0.1772 | Reco 0.1772 | Nsdr 5.360[0m
[[36m09-08 05:14:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 6/14 | 0.11 it/sec | Loss 0.1661 | Reco 0.1661 | Nsdr 5.648[0m
[[36m09-08 05:14:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 9/14 | 0.12 it/sec | Loss 0.1667 | Reco 0.1667 | Nsdr 5.852[0m
[[36m09-08 05:14:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 12/14 | 0.13 it/sec | Loss 0.1661 | Reco 0.1661 | Nsdr 5.917[0m
[[36m09-08 05:15:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 3/14 | 11.0 sec/it | Loss 0.1795 | Reco 0.1795 | Nsdr 5.271[0m
[[36m09-08 05:15:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 6/14 | 0.12 it/sec | Loss 0.1669 | Reco 0.1669 | Nsdr 5.622[0m
[[36m09-08 05:16:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 9/14 | 0.13 it/sec | Loss 0.1668 | Reco 0.1668 | Nsdr 5.869[0m
[[36m09-08 05:16:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 12/14 | 0.14 it/sec | Loss 0.1660 | Reco 0.1660 | Nsdr 5.940[0m
[[36m09-08 05:17:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 3/14 | 11.2 sec/it | Loss 0.1857 | Reco 0.1857 | Nsdr 5.062[0m
[[36m09-08 05:17:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 6/14 | 0.12 it/sec | Loss 0.1713 | Reco 0.1713 | Nsdr 5.454[0m
[[36m09-08 05:17:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 9/14 | 0.12 it/sec | Loss 0.1704 | Reco 0.1704 | Nsdr 5.710[0m
[[36m09-08 05:18:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 12/14 | 0.14 it/sec | Loss 0.1693 | Reco 0.1693 | Nsdr 5.792[0m
[[36m09-08 05:19:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 3/14 | 10.7 sec/it | Loss 0.1859 | Reco 0.1859 | Nsdr 5.049[0m
[[36m09-08 05:19:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 6/14 | 0.12 it/sec | Loss 0.1714 | Reco 0.1714 | Nsdr 5.450[0m
[[36m09-08 05:19:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 9/14 | 0.13 it/sec | Loss 0.1704 | Reco 0.1704 | Nsdr 5.713[0m
[[36m09-08 05:19:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 12/14 | 0.14 it/sec | Loss 0.1692 | Reco 0.1692 | Nsdr 5.797[0m
[[36m09-08 05:20:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 3 | Loss=0.1668 | Reco=0.1668 | Nsdr=5.831 | Best=0.1668 | Bname=ema_batch_1 | Penalty=213.8721[0m
[[36m09-08 05:20:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1668[0m
[[36m09-08 05:20:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-08 05:20:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-08 06:05:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 4 | 1164/4656 | 0.42 it/sec | Loss 0.1040 | Reco 0.1019 | Grad 0.1001 | Penalty 209.8275[0m
[[36m09-08 06:51:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 4 | 2328/4656 | 0.43 it/sec | Loss 0.1042 | Reco 0.1021 | Grad 0.1006 | Penalty 210.9885[0m
[[36m09-08 07:37:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 4 | 3492/4656 | 0.43 it/sec | Loss 0.1046 | Reco 0.1025 | Grad 0.1023 | Penalty 211.2619[0m
[[36m09-08 08:22:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 4 | Loss=0.1041 | Reco=0.1020 | Grad=0.1015 | Penalty=212.0091[0m
[[36m09-08 08:22:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-08 08:22:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-08 08:23:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 3/14 | 11.4 sec/it | Loss 0.1925 | Reco 0.1925 | Nsdr 4.794[0m
[[36m09-08 08:23:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 6/14 | 0.12 it/sec | Loss 0.1780 | Reco 0.1780 | Nsdr 5.227[0m
[[36m09-08 08:23:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 9/14 | 0.12 it/sec | Loss 0.1784 | Reco 0.1784 | Nsdr 5.417[0m
[[36m09-08 08:24:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 12/14 | 0.13 it/sec | Loss 0.1767 | Reco 0.1767 | Nsdr 5.516[0m
[[36m09-08 08:25:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 3/14 | 11.0 sec/it | Loss 0.1790 | Reco 0.1790 | Nsdr 5.311[0m
[[36m09-08 08:25:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 6/14 | 0.12 it/sec | Loss 0.1670 | Reco 0.1670 | Nsdr 5.637[0m
[[36m09-08 08:25:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 9/14 | 0.13 it/sec | Loss 0.1674 | Reco 0.1674 | Nsdr 5.842[0m
[[36m09-08 08:25:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 12/14 | 0.14 it/sec | Loss 0.1664 | Reco 0.1664 | Nsdr 5.927[0m
[[36m09-08 08:26:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 3/14 | 11.1 sec/it | Loss 0.1785 | Reco 0.1785 | Nsdr 5.327[0m
[[36m09-08 08:27:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 6/14 | 0.12 it/sec | Loss 0.1667 | Reco 0.1667 | Nsdr 5.644[0m
[[36m09-08 08:27:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 9/14 | 0.12 it/sec | Loss 0.1668 | Reco 0.1668 | Nsdr 5.863[0m
[[36m09-08 08:27:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 12/14 | 0.13 it/sec | Loss 0.1659 | Reco 0.1659 | Nsdr 5.946[0m
[[36m09-08 08:28:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 3/14 | 10.9 sec/it | Loss 0.1839 | Reco 0.1839 | Nsdr 5.141[0m
[[36m09-08 08:28:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 6/14 | 0.12 it/sec | Loss 0.1704 | Reco 0.1704 | Nsdr 5.520[0m
[[36m09-08 08:29:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 9/14 | 0.13 it/sec | Loss 0.1700 | Reco 0.1700 | Nsdr 5.757[0m
[[36m09-08 08:29:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 12/14 | 0.14 it/sec | Loss 0.1686 | Reco 0.1686 | Nsdr 5.850[0m
[[36m09-08 08:30:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 3/14 | 11.0 sec/it | Loss 0.1842 | Reco 0.1842 | Nsdr 5.140[0m
[[36m09-08 08:30:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 6/14 | 0.12 it/sec | Loss 0.1705 | Reco 0.1705 | Nsdr 5.521[0m
[[36m09-08 08:30:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 9/14 | 0.13 it/sec | Loss 0.1700 | Reco 0.1700 | Nsdr 5.759[0m
[[36m09-08 08:31:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 12/14 | 0.14 it/sec | Loss 0.1685 | Reco 0.1685 | Nsdr 5.853[0m
[[36m09-08 08:31:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 4 | Loss=0.1667 | Reco=0.1667 | Nsdr=5.835 | Best=0.1667 | Bname=ema_batch_1 | Penalty=215.4463[0m
[[36m09-08 08:31:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1667[0m
[[36m09-08 08:31:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-08 08:31:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-08 09:17:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 5 | 1164/4656 | 0.42 it/sec | Loss 0.1037 | Reco 0.1016 | Grad 0.0990 | Penalty 211.3569[0m
[[36m09-08 10:02:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 5 | 2328/4656 | 0.43 it/sec | Loss 0.1041 | Reco 0.1019 | Grad 0.1003 | Penalty 211.5436[0m
[[36m09-08 10:48:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 5 | 3492/4656 | 0.42 it/sec | Loss 0.1034 | Reco 0.1013 | Grad 0.1003 | Penalty 211.5917[0m
[[36m09-08 11:34:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 5 | Loss=0.1034 | Reco=0.1013 | Grad=0.0992 | Penalty=211.7451[0m
[[36m09-08 11:34:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-08 11:34:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-08 11:35:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 3/14 | 12.5 sec/it | Loss 0.1915 | Reco 0.1915 | Nsdr 4.790[0m
[[36m09-08 11:35:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 6/14 | 0.11 it/sec | Loss 0.1782 | Reco 0.1782 | Nsdr 5.154[0m
[[36m09-08 11:35:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 9/14 | 0.12 it/sec | Loss 0.1766 | Reco 0.1766 | Nsdr 5.420[0m
[[36m09-08 11:36:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 12/14 | 0.13 it/sec | Loss 0.1751 | Reco 0.1751 | Nsdr 5.522[0m
[[36m09-08 11:37:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 3/14 | 12.6 sec/it | Loss 0.1811 | Reco 0.1811 | Nsdr 5.241[0m
[[36m09-08 11:37:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 6/14 | 0.11 it/sec | Loss 0.1685 | Reco 0.1685 | Nsdr 5.592[0m
[[36m09-08 11:37:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 9/14 | 0.12 it/sec | Loss 0.1682 | Reco 0.1682 | Nsdr 5.817[0m
[[36m09-08 11:37:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 12/14 | 0.13 it/sec | Loss 0.1670 | Reco 0.1670 | Nsdr 5.907[0m
[[36m09-08 11:38:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 3/14 | 11.7 sec/it | Loss 0.1795 | Reco 0.1795 | Nsdr 5.307[0m
[[36m09-08 11:39:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 6/14 | 0.11 it/sec | Loss 0.1671 | Reco 0.1671 | Nsdr 5.640[0m
[[36m09-08 11:39:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 9/14 | 0.12 it/sec | Loss 0.1669 | Reco 0.1669 | Nsdr 5.870[0m
[[36m09-08 11:39:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 12/14 | 0.13 it/sec | Loss 0.1658 | Reco 0.1658 | Nsdr 5.958[0m
[[36m09-08 11:40:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 3/14 | 10.6 sec/it | Loss 0.1835 | Reco 0.1835 | Nsdr 5.161[0m
[[36m09-08 11:40:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 6/14 | 0.12 it/sec | Loss 0.1702 | Reco 0.1702 | Nsdr 5.531[0m
[[36m09-08 11:41:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 9/14 | 0.13 it/sec | Loss 0.1694 | Reco 0.1694 | Nsdr 5.782[0m
[[36m09-08 11:41:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 12/14 | 0.14 it/sec | Loss 0.1680 | Reco 0.1680 | Nsdr 5.874[0m
[[36m09-08 11:42:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 3/14 | 10.8 sec/it | Loss 0.1841 | Reco 0.1841 | Nsdr 5.139[0m
[[36m09-08 11:42:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 6/14 | 0.12 it/sec | Loss 0.1705 | Reco 0.1705 | Nsdr 5.517[0m
[[36m09-08 11:42:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 9/14 | 0.13 it/sec | Loss 0.1697 | Reco 0.1697 | Nsdr 5.760[0m
[[36m09-08 11:43:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 12/14 | 0.14 it/sec | Loss 0.1683 | Reco 0.1683 | Nsdr 5.859[0m
[[36m09-08 11:43:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 5 | Loss=0.1667 | Reco=0.1667 | Nsdr=5.845 | Best=0.1667 | Bname=ema_batch_1 | Penalty=217.5034[0m
[[36m09-08 11:43:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1667[0m
[[36m09-08 11:43:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-08 11:43:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-08 12:29:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 6 | 1164/4656 | 0.42 it/sec | Loss 0.1043 | Reco 0.1021 | Grad 0.0995 | Penalty 214.5288[0m
[[36m09-08 13:15:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 6 | 2328/4656 | 0.42 it/sec | Loss 0.1033 | Reco 0.1012 | Grad 0.0978 | Penalty 214.4468[0m
[[36m09-08 14:01:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 6 | 3492/4656 | 0.42 it/sec | Loss 0.1029 | Reco 0.1007 | Grad 0.0963 | Penalty 215.1631[0m
[[36m09-08 14:48:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 6 | Loss=0.1026 | Reco=0.1005 | Grad=0.0965 | Penalty=215.6919[0m
[[36m09-08 14:48:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-08 14:48:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-08 14:49:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 3/14 | 11.3 sec/it | Loss 0.1763 | Reco 0.1763 | Nsdr 5.351[0m
[[36m09-08 14:49:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 6/14 | 0.12 it/sec | Loss 0.1679 | Reco 0.1679 | Nsdr 5.551[0m
[[36m09-08 14:49:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 9/14 | 0.13 it/sec | Loss 0.1685 | Reco 0.1685 | Nsdr 5.771[0m
[[36m09-08 14:49:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 12/14 | 0.14 it/sec | Loss 0.1683 | Reco 0.1683 | Nsdr 5.818[0m
[[36m09-08 14:50:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 3/14 | 11.3 sec/it | Loss 0.1787 | Reco 0.1787 | Nsdr 5.339[0m
[[36m09-08 14:51:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 6/14 | 0.12 it/sec | Loss 0.1668 | Reco 0.1668 | Nsdr 5.664[0m
[[36m09-08 14:51:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 9/14 | 0.13 it/sec | Loss 0.1663 | Reco 0.1663 | Nsdr 5.908[0m
[[36m09-08 14:51:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 12/14 | 0.14 it/sec | Loss 0.1656 | Reco 0.1656 | Nsdr 5.977[0m
[[36m09-08 14:52:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 3/14 | 11.2 sec/it | Loss 0.1785 | Reco 0.1785 | Nsdr 5.352[0m
[[36m09-08 14:52:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 6/14 | 0.12 it/sec | Loss 0.1666 | Reco 0.1666 | Nsdr 5.675[0m
[[36m09-08 14:53:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 9/14 | 0.12 it/sec | Loss 0.1663 | Reco 0.1663 | Nsdr 5.907[0m
[[36m09-08 14:53:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 12/14 | 0.13 it/sec | Loss 0.1655 | Reco 0.1655 | Nsdr 5.982[0m
[[36m09-08 14:54:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 3/14 | 11.3 sec/it | Loss 0.1797 | Reco 0.1797 | Nsdr 5.287[0m
[[36m09-08 14:54:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 6/14 | 0.12 it/sec | Loss 0.1678 | Reco 0.1678 | Nsdr 5.619[0m
[[36m09-08 14:54:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 9/14 | 0.12 it/sec | Loss 0.1672 | Reco 0.1672 | Nsdr 5.871[0m
[[36m09-08 14:55:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 12/14 | 0.14 it/sec | Loss 0.1662 | Reco 0.1662 | Nsdr 5.950[0m
[[36m09-08 14:56:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 3/14 | 10.8 sec/it | Loss 0.1805 | Reco 0.1805 | Nsdr 5.255[0m
[[36m09-08 14:56:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 6/14 | 0.12 it/sec | Loss 0.1682 | Reco 0.1682 | Nsdr 5.597[0m
[[36m09-08 14:56:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 9/14 | 0.13 it/sec | Loss 0.1676 | Reco 0.1676 | Nsdr 5.849[0m
[[36m09-08 14:56:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 12/14 | 0.14 it/sec | Loss 0.1665 | Reco 0.1665 | Nsdr 5.934[0m
[[36m09-08 14:57:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 6 | Loss=0.1663 | Reco=0.1663 | Nsdr=5.870 | Best=0.1663 | Bname=ema_batch_1 | Penalty=218.2865[0m
[[36m09-08 14:57:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1663[0m
[[36m09-08 14:57:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-08 14:57:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-08 15:43:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 7 | 1164/4656 | 0.42 it/sec | Loss 0.1019 | Reco 0.0997 | Grad 0.1011 | Penalty 215.4076[0m
[[36m09-08 16:28:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 7 | 2328/4656 | 0.42 it/sec | Loss 0.1031 | Reco 0.1010 | Grad 0.1009 | Penalty 217.6001[0m
[[36m09-08 17:17:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 7 | 3492/4656 | 0.41 it/sec | Loss 0.1032 | Reco 0.1010 | Grad 0.1006 | Penalty 216.9778[0m
[[36m09-08 18:06:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 7 | Loss=0.1029 | Reco=0.1007 | Grad=0.0993 | Penalty=216.7086[0m
[[36m09-08 18:06:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-08 18:06:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-08 18:07:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 3/14 | 14.7 sec/it | Loss 0.1914 | Reco 0.1914 | Nsdr 4.859[0m
[[36m09-08 18:07:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 6/14 | 10.7 sec/it | Loss 0.1783 | Reco 0.1783 | Nsdr 5.173[0m
[[36m09-08 18:08:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 9/14 | 0.10 it/sec | Loss 0.1766 | Reco 0.1766 | Nsdr 5.466[0m
[[36m09-08 18:08:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 12/14 | 0.11 it/sec | Loss 0.1741 | Reco 0.1741 | Nsdr 5.607[0m
[[36m09-08 18:09:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 3/14 | 15.1 sec/it | Loss 0.1766 | Reco 0.1766 | Nsdr 5.433[0m
[[36m09-08 18:10:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 6/14 | 10.9 sec/it | Loss 0.1661 | Reco 0.1661 | Nsdr 5.700[0m
[[36m09-08 18:10:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 9/14 | 0.10 it/sec | Loss 0.1656 | Reco 0.1656 | Nsdr 5.947[0m
[[36m09-08 18:10:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 12/14 | 0.11 it/sec | Loss 0.1649 | Reco 0.1649 | Nsdr 6.010[0m
[[36m09-08 18:11:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 3/14 | 15.3 sec/it | Loss 0.1778 | Reco 0.1778 | Nsdr 5.378[0m
[[36m09-08 18:12:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 6/14 | 11.1 sec/it | Loss 0.1661 | Reco 0.1661 | Nsdr 5.694[0m
[[36m09-08 18:12:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 9/14 | 0.10 it/sec | Loss 0.1657 | Reco 0.1657 | Nsdr 5.930[0m
[[36m09-08 18:12:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 12/14 | 0.11 it/sec | Loss 0.1650 | Reco 0.1650 | Nsdr 6.003[0m
[[36m09-08 18:14:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 3/14 | 14.7 sec/it | Loss 0.1786 | Reco 0.1786 | Nsdr 5.344[0m
[[36m09-08 18:14:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 6/14 | 10.8 sec/it | Loss 0.1672 | Reco 0.1672 | Nsdr 5.650[0m
[[36m09-08 18:14:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 9/14 | 0.10 it/sec | Loss 0.1669 | Reco 0.1669 | Nsdr 5.881[0m
[[36m09-08 18:14:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 12/14 | 0.11 it/sec | Loss 0.1658 | Reco 0.1658 | Nsdr 5.972[0m
[[36m09-08 18:16:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 3/14 | 14.5 sec/it | Loss 0.1799 | Reco 0.1799 | Nsdr 5.290[0m
[[36m09-08 18:16:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 6/14 | 10.7 sec/it | Loss 0.1678 | Reco 0.1678 | Nsdr 5.624[0m
[[36m09-08 18:16:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 9/14 | 0.10 it/sec | Loss 0.1674 | Reco 0.1674 | Nsdr 5.863[0m
[[36m09-08 18:17:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 12/14 | 0.11 it/sec | Loss 0.1662 | Reco 0.1662 | Nsdr 5.956[0m
[[36m09-08 18:17:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 7 | Loss=0.1659 | Reco=0.1659 | Nsdr=5.892 | Best=0.1659 | Bname=ema_batch_1 | Penalty=219.7376[0m
[[36m09-08 18:17:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1659[0m
[[36m09-08 18:17:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-08 18:17:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-08 19:04:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 8 | 1164/4656 | 0.41 it/sec | Loss 0.1014 | Reco 0.0992 | Grad 0.0971 | Penalty 214.9481[0m
[[36m09-08 19:50:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 8 | 2328/4656 | 0.42 it/sec | Loss 0.1027 | Reco 0.1005 | Grad 0.0965 | Penalty 217.4702[0m
[[36m09-08 20:36:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 8 | 3492/4656 | 0.42 it/sec | Loss 0.1020 | Reco 0.0999 | Grad 0.0994 | Penalty 217.7242[0m
[[36m09-08 21:22:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 8 | Loss=0.1018 | Reco=0.0996 | Grad=0.0991 | Penalty=217.7773[0m
[[36m09-08 21:22:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-08 21:22:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-08 21:23:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 11.0 sec/it | Loss 0.1741 | Reco 0.1741 | Nsdr 5.467[0m
[[36m09-08 21:23:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.12 it/sec | Loss 0.1667 | Reco 0.1667 | Nsdr 5.645[0m
[[36m09-08 21:23:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.13 it/sec | Loss 0.1682 | Reco 0.1682 | Nsdr 5.797[0m
[[36m09-08 21:24:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.14 it/sec | Loss 0.1674 | Reco 0.1674 | Nsdr 5.878[0m
[[36m09-08 21:25:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 10.9 sec/it | Loss 0.1737 | Reco 0.1737 | Nsdr 5.524[0m
[[36m09-08 21:25:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.12 it/sec | Loss 0.1644 | Reco 0.1644 | Nsdr 5.760[0m
[[36m09-08 21:25:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.13 it/sec | Loss 0.1650 | Reco 0.1650 | Nsdr 5.953[0m
[[36m09-08 21:25:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.14 it/sec | Loss 0.1640 | Reco 0.1640 | Nsdr 6.042[0m
[[36m09-08 21:26:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 11.4 sec/it | Loss 0.1749 | Reco 0.1749 | Nsdr 5.493[0m
[[36m09-08 21:27:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.12 it/sec | Loss 0.1647 | Reco 0.1647 | Nsdr 5.754[0m
[[36m09-08 21:27:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.12 it/sec | Loss 0.1649 | Reco 0.1649 | Nsdr 5.968[0m
[[36m09-08 21:27:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.13 it/sec | Loss 0.1641 | Reco 0.1641 | Nsdr 6.046[0m
[[36m09-08 21:28:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 11.0 sec/it | Loss 0.1769 | Reco 0.1769 | Nsdr 5.401[0m
[[36m09-08 21:28:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.12 it/sec | Loss 0.1662 | Reco 0.1662 | Nsdr 5.690[0m
[[36m09-08 21:29:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.13 it/sec | Loss 0.1661 | Reco 0.1661 | Nsdr 5.909[0m
[[36m09-08 21:29:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.14 it/sec | Loss 0.1650 | Reco 0.1650 | Nsdr 6.003[0m
[[36m09-08 21:30:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 10.7 sec/it | Loss 0.1774 | Reco 0.1774 | Nsdr 5.392[0m
[[36m09-08 21:30:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.12 it/sec | Loss 0.1663 | Reco 0.1663 | Nsdr 5.684[0m
[[36m09-08 21:30:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.13 it/sec | Loss 0.1662 | Reco 0.1662 | Nsdr 5.919[0m
[[36m09-08 21:31:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.14 it/sec | Loss 0.1651 | Reco 0.1651 | Nsdr 6.010[0m
[[36m09-08 21:31:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 8 | Loss=0.1650 | Reco=0.1650 | Nsdr=5.933 | Best=0.1650 | Bname=ema_batch_1 | Penalty=226.7453[0m
[[36m09-08 21:31:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1650[0m
[[36m09-08 21:31:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-08 21:31:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-08 22:17:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 9 | 1164/4656 | 0.42 it/sec | Loss 0.1020 | Reco 0.0998 | Grad 0.0983 | Penalty 218.5864[0m
[[36m09-08 23:02:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 9 | 2328/4656 | 0.42 it/sec | Loss 0.1017 | Reco 0.0995 | Grad 0.0990 | Penalty 217.9452[0m
[[36m09-08 23:48:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 9 | 3492/4656 | 0.42 it/sec | Loss 0.1015 | Reco 0.0994 | Grad 0.0993 | Penalty 217.5900[0m
[[36m09-09 00:33:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 9 | Loss=0.1011 | Reco=0.0990 | Grad=0.0988 | Penalty=217.6694[0m
[[36m09-09 00:33:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-09 00:33:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-09 00:34:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 11.0 sec/it | Loss 0.1854 | Reco 0.1854 | Nsdr 5.015[0m
[[36m09-09 00:34:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.12 it/sec | Loss 0.1746 | Reco 0.1746 | Nsdr 5.307[0m
[[36m09-09 00:35:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.13 it/sec | Loss 0.1738 | Reco 0.1738 | Nsdr 5.577[0m
[[36m09-09 00:35:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.14 it/sec | Loss 0.1725 | Reco 0.1725 | Nsdr 5.665[0m
[[36m09-09 00:36:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 11.0 sec/it | Loss 0.1737 | Reco 0.1737 | Nsdr 5.544[0m
[[36m09-09 00:36:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.12 it/sec | Loss 0.1638 | Reco 0.1638 | Nsdr 5.794[0m
[[36m09-09 00:36:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.13 it/sec | Loss 0.1641 | Reco 0.1641 | Nsdr 6.013[0m
[[36m09-09 00:37:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.14 it/sec | Loss 0.1633 | Reco 0.1633 | Nsdr 6.091[0m
[[36m09-09 00:38:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 10.7 sec/it | Loss 0.1727 | Reco 0.1727 | Nsdr 5.579[0m
[[36m09-09 00:38:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.12 it/sec | Loss 0.1635 | Reco 0.1635 | Nsdr 5.806[0m
[[36m09-09 00:38:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.13 it/sec | Loss 0.1641 | Reco 0.1641 | Nsdr 6.010[0m
[[36m09-09 00:38:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.14 it/sec | Loss 0.1634 | Reco 0.1634 | Nsdr 6.083[0m
[[36m09-09 00:39:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 10.6 sec/it | Loss 0.1768 | Reco 0.1768 | Nsdr 5.413[0m
[[36m09-09 00:39:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.12 it/sec | Loss 0.1661 | Reco 0.1661 | Nsdr 5.694[0m
[[36m09-09 00:40:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.13 it/sec | Loss 0.1659 | Reco 0.1659 | Nsdr 5.926[0m
[[36m09-09 00:40:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.14 it/sec | Loss 0.1648 | Reco 0.1648 | Nsdr 6.020[0m
[[36m09-09 00:41:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 11.0 sec/it | Loss 0.1772 | Reco 0.1772 | Nsdr 5.390[0m
[[36m09-09 00:41:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.12 it/sec | Loss 0.1664 | Reco 0.1664 | Nsdr 5.680[0m
[[36m09-09 00:42:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.13 it/sec | Loss 0.1661 | Reco 0.1661 | Nsdr 5.926[0m
[[36m09-09 00:42:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.14 it/sec | Loss 0.1649 | Reco 0.1649 | Nsdr 6.019[0m
[[36m09-09 00:42:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 9 | Loss=0.1643 | Reco=0.1643 | Nsdr=5.974 | Best=0.1643 | Bname=ema_batch_0 | Penalty=229.8506[0m
[[36m09-09 00:42:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1643[0m
[[36m09-09 00:42:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-09 00:42:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-09 01:28:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 10 | 1164/4656 | 0.42 it/sec | Loss 0.1017 | Reco 0.0995 | Grad 0.0983 | Penalty 221.6200[0m
[[36m09-09 02:14:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 10 | 2328/4656 | 0.42 it/sec | Loss 0.1010 | Reco 0.0988 | Grad 0.0971 | Penalty 220.8555[0m
[[36m09-09 02:59:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 10 | 3492/4656 | 0.42 it/sec | Loss 0.1012 | Reco 0.0990 | Grad 0.0967 | Penalty 220.3730[0m
[[36m09-09 03:45:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 10 | Loss=0.1007 | Reco=0.0985 | Grad=0.0963 | Penalty=219.7994[0m
[[36m09-09 03:45:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-09 03:45:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-09 03:46:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 10.8 sec/it | Loss 0.1791 | Reco 0.1791 | Nsdr 5.280[0m
[[36m09-09 03:46:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 0.12 it/sec | Loss 0.1702 | Reco 0.1702 | Nsdr 5.490[0m
[[36m09-09 03:47:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.13 it/sec | Loss 0.1713 | Reco 0.1713 | Nsdr 5.647[0m
[[36m09-09 03:47:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.14 it/sec | Loss 0.1697 | Reco 0.1697 | Nsdr 5.767[0m
[[36m09-09 03:48:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 11.2 sec/it | Loss 0.1718 | Reco 0.1718 | Nsdr 5.642[0m
[[36m09-09 03:48:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 0.12 it/sec | Loss 0.1634 | Reco 0.1634 | Nsdr 5.821[0m
[[36m09-09 03:48:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.13 it/sec | Loss 0.1635 | Reco 0.1635 | Nsdr 6.041[0m
[[36m09-09 03:49:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.14 it/sec | Loss 0.1628 | Reco 0.1628 | Nsdr 6.112[0m
[[36m09-09 03:50:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 11.0 sec/it | Loss 0.1725 | Reco 0.1725 | Nsdr 5.610[0m
[[36m09-09 03:50:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 0.12 it/sec | Loss 0.1633 | Reco 0.1633 | Nsdr 5.828[0m
[[36m09-09 03:50:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.13 it/sec | Loss 0.1635 | Reco 0.1635 | Nsdr 6.040[0m
[[36m09-09 03:50:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.14 it/sec | Loss 0.1629 | Reco 0.1629 | Nsdr 6.114[0m
[[36m09-09 03:51:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 10.8 sec/it | Loss 0.1747 | Reco 0.1747 | Nsdr 5.491[0m
[[36m09-09 03:52:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 0.12 it/sec | Loss 0.1653 | Reco 0.1653 | Nsdr 5.728[0m
[[36m09-09 03:52:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.13 it/sec | Loss 0.1654 | Reco 0.1654 | Nsdr 5.947[0m
[[36m09-09 03:52:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.14 it/sec | Loss 0.1642 | Reco 0.1642 | Nsdr 6.046[0m
[[36m09-09 03:53:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 11.1 sec/it | Loss 0.1761 | Reco 0.1761 | Nsdr 5.430[0m
[[36m09-09 03:53:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 0.12 it/sec | Loss 0.1660 | Reco 0.1660 | Nsdr 5.700[0m
[[36m09-09 03:54:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.13 it/sec | Loss 0.1658 | Reco 0.1658 | Nsdr 5.936[0m
[[36m09-09 03:54:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.14 it/sec | Loss 0.1647 | Reco 0.1647 | Nsdr 6.030[0m
[[36m09-09 03:54:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 10 | Loss=0.1638 | Reco=0.1638 | Nsdr=5.998 | Best=0.1638 | Bname=ema_batch_1 | Penalty=225.1642[0m
[[36m09-09 03:54:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1638[0m
[[36m09-09 03:54:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-09 03:54:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-09 04:40:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 11 | 1164/4656 | 0.43 it/sec | Loss 0.1004 | Reco 0.0982 | Grad 0.0992 | Penalty 219.3988[0m
[[36m09-09 05:26:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 11 | 2328/4656 | 0.42 it/sec | Loss 0.1009 | Reco 0.0987 | Grad 0.0992 | Penalty 219.0450[0m
[[36m09-09 06:11:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 11 | 3492/4656 | 0.42 it/sec | Loss 0.1012 | Reco 0.0990 | Grad 0.0986 | Penalty 219.8670[0m
[[36m09-09 06:57:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 11 | Loss=0.1008 | Reco=0.0986 | Grad=0.0985 | Penalty=219.7802[0m
[[36m09-09 06:57:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-09 06:57:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-09 06:58:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 10.9 sec/it | Loss 0.1706 | Reco 0.1706 | Nsdr 5.622[0m
[[36m09-09 06:58:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.12 it/sec | Loss 0.1663 | Reco 0.1663 | Nsdr 5.666[0m
[[36m09-09 06:58:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.13 it/sec | Loss 0.1686 | Reco 0.1686 | Nsdr 5.804[0m
[[36m09-09 06:58:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.14 it/sec | Loss 0.1689 | Reco 0.1689 | Nsdr 5.821[0m
[[36m09-09 06:59:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 10.9 sec/it | Loss 0.1723 | Reco 0.1723 | Nsdr 5.623[0m
[[36m09-09 07:00:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.12 it/sec | Loss 0.1633 | Reco 0.1633 | Nsdr 5.828[0m
[[36m09-09 07:00:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.13 it/sec | Loss 0.1633 | Reco 0.1633 | Nsdr 6.050[0m
[[36m09-09 07:00:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.14 it/sec | Loss 0.1624 | Reco 0.1624 | Nsdr 6.134[0m
[[36m09-09 07:01:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 10.8 sec/it | Loss 0.1721 | Reco 0.1721 | Nsdr 5.627[0m
[[36m09-09 07:01:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.12 it/sec | Loss 0.1632 | Reco 0.1632 | Nsdr 5.837[0m
[[36m09-09 07:02:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.13 it/sec | Loss 0.1632 | Reco 0.1632 | Nsdr 6.057[0m
[[36m09-09 07:02:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.14 it/sec | Loss 0.1624 | Reco 0.1624 | Nsdr 6.139[0m
[[36m09-09 07:03:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 11.0 sec/it | Loss 0.1738 | Reco 0.1738 | Nsdr 5.528[0m
[[36m09-09 07:03:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.12 it/sec | Loss 0.1646 | Reco 0.1646 | Nsdr 5.758[0m
[[36m09-09 07:03:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.13 it/sec | Loss 0.1648 | Reco 0.1648 | Nsdr 5.977[0m
[[36m09-09 07:04:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.14 it/sec | Loss 0.1638 | Reco 0.1638 | Nsdr 6.066[0m
[[36m09-09 07:04:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 11.0 sec/it | Loss 0.1741 | Reco 0.1741 | Nsdr 5.514[0m
[[36m09-09 07:05:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.12 it/sec | Loss 0.1650 | Reco 0.1650 | Nsdr 5.746[0m
[[36m09-09 07:05:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.13 it/sec | Loss 0.1652 | Reco 0.1652 | Nsdr 5.952[0m
[[36m09-09 07:05:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.14 it/sec | Loss 0.1642 | Reco 0.1642 | Nsdr 6.044[0m
[[36m09-09 07:05:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 11 | Loss=0.1634 | Reco=0.1634 | Nsdr=6.021 | Best=0.1634 | Bname=ema_batch_1 | Penalty=226.0243[0m
[[36m09-09 07:05:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1634[0m
[[36m09-09 07:06:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-09 07:06:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-09 07:51:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 12 | 1164/4656 | 0.42 it/sec | Loss 0.0999 | Reco 0.0977 | Grad 0.0989 | Penalty 220.2008[0m
[[36m09-09 08:37:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 12 | 2328/4656 | 0.42 it/sec | Loss 0.1005 | Reco 0.0983 | Grad 0.0976 | Penalty 220.5691[0m
[[36m09-09 09:23:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 12 | 3492/4656 | 0.42 it/sec | Loss 0.1011 | Reco 0.0989 | Grad 0.0984 | Penalty 221.0443[0m
[[36m09-09 10:08:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 12 | Loss=0.1009 | Reco=0.0987 | Grad=0.0983 | Penalty=221.3033[0m
[[36m09-09 10:08:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-09 10:08:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-09 10:09:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 11.2 sec/it | Loss 0.1788 | Reco 0.1788 | Nsdr 5.302[0m
[[36m09-09 10:09:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.12 it/sec | Loss 0.1686 | Reco 0.1686 | Nsdr 5.557[0m
[[36m09-09 10:10:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.13 it/sec | Loss 0.1684 | Reco 0.1684 | Nsdr 5.782[0m
[[36m09-09 10:10:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.14 it/sec | Loss 0.1678 | Reco 0.1678 | Nsdr 5.845[0m
[[36m09-09 10:11:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 11.2 sec/it | Loss 0.1725 | Reco 0.1725 | Nsdr 5.621[0m
[[36m09-09 10:11:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.12 it/sec | Loss 0.1633 | Reco 0.1633 | Nsdr 5.829[0m
[[36m09-09 10:11:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.13 it/sec | Loss 0.1635 | Reco 0.1635 | Nsdr 6.042[0m
[[36m09-09 10:12:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.14 it/sec | Loss 0.1624 | Reco 0.1624 | Nsdr 6.135[0m
[[36m09-09 10:13:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 11.0 sec/it | Loss 0.1722 | Reco 0.1722 | Nsdr 5.632[0m
[[36m09-09 10:13:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.12 it/sec | Loss 0.1628 | Reco 0.1628 | Nsdr 5.856[0m
[[36m09-09 10:13:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.13 it/sec | Loss 0.1628 | Reco 0.1628 | Nsdr 6.084[0m
[[36m09-09 10:13:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.14 it/sec | Loss 0.1619 | Reco 0.1619 | Nsdr 6.170[0m
[[36m09-09 10:14:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 10.9 sec/it | Loss 0.1737 | Reco 0.1737 | Nsdr 5.544[0m
[[36m09-09 10:15:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.12 it/sec | Loss 0.1643 | Reco 0.1643 | Nsdr 5.779[0m
[[36m09-09 10:15:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.13 it/sec | Loss 0.1644 | Reco 0.1644 | Nsdr 5.998[0m
[[36m09-09 10:15:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.14 it/sec | Loss 0.1634 | Reco 0.1634 | Nsdr 6.087[0m
[[36m09-09 10:16:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 11.3 sec/it | Loss 0.1750 | Reco 0.1750 | Nsdr 5.486[0m
[[36m09-09 10:16:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.12 it/sec | Loss 0.1651 | Reco 0.1651 | Nsdr 5.742[0m
[[36m09-09 10:17:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.13 it/sec | Loss 0.1650 | Reco 0.1650 | Nsdr 5.976[0m
[[36m09-09 10:17:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.14 it/sec | Loss 0.1639 | Reco 0.1639 | Nsdr 6.066[0m
[[36m09-09 10:17:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 12 | Loss=0.1629 | Reco=0.1629 | Nsdr=6.049 | Best=0.1629 | Bname=ema_batch_1 | Penalty=226.0067[0m
[[36m09-09 10:17:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1629[0m
[[36m09-09 10:17:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-09 10:17:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-09 11:03:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 13 | 1164/4656 | 0.42 it/sec | Loss 0.0988 | Reco 0.0966 | Grad 0.0969 | Penalty 220.5411[0m
[[36m09-09 11:49:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 13 | 2328/4656 | 0.42 it/sec | Loss 0.0988 | Reco 0.0966 | Grad 0.0965 | Penalty 222.3032[0m
[[36m09-09 12:35:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 13 | 3492/4656 | 0.42 it/sec | Loss 0.0997 | Reco 0.0974 | Grad 0.0974 | Penalty 222.7774[0m
[[36m09-09 13:20:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 13 | Loss=0.0998 | Reco=0.0976 | Grad=0.0980 | Penalty=223.1750[0m
[[36m09-09 13:20:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-09 13:20:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-09 13:21:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 10.7 sec/it | Loss 0.1774 | Reco 0.1774 | Nsdr 5.370[0m
[[36m09-09 13:21:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 6/14 | 0.12 it/sec | Loss 0.1688 | Reco 0.1688 | Nsdr 5.526[0m
[[36m09-09 13:22:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 9/14 | 0.13 it/sec | Loss 0.1692 | Reco 0.1692 | Nsdr 5.721[0m
[[36m09-09 13:22:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 12/14 | 0.14 it/sec | Loss 0.1685 | Reco 0.1685 | Nsdr 5.781[0m
[[36m09-09 13:23:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 10.8 sec/it | Loss 0.1725 | Reco 0.1725 | Nsdr 5.632[0m
[[36m09-09 13:23:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 6/14 | 0.12 it/sec | Loss 0.1629 | Reco 0.1629 | Nsdr 5.861[0m
[[36m09-09 13:23:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 9/14 | 0.13 it/sec | Loss 0.1632 | Reco 0.1632 | Nsdr 6.060[0m
[[36m09-09 13:24:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 12/14 | 0.14 it/sec | Loss 0.1621 | Reco 0.1621 | Nsdr 6.148[0m
[[36m09-09 13:25:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 10.8 sec/it | Loss 0.1714 | Reco 0.1714 | Nsdr 5.672[0m
[[36m09-09 13:25:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 6/14 | 0.12 it/sec | Loss 0.1623 | Reco 0.1623 | Nsdr 5.883[0m
[[36m09-09 13:25:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 9/14 | 0.13 it/sec | Loss 0.1625 | Reco 0.1625 | Nsdr 6.105[0m
[[36m09-09 13:25:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 12/14 | 0.14 it/sec | Loss 0.1615 | Reco 0.1615 | Nsdr 6.190[0m
[[36m09-09 13:26:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 10.7 sec/it | Loss 0.1742 | Reco 0.1742 | Nsdr 5.528[0m
[[36m09-09 13:27:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 6/14 | 0.12 it/sec | Loss 0.1642 | Reco 0.1642 | Nsdr 5.783[0m
[[36m09-09 13:27:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 9/14 | 0.13 it/sec | Loss 0.1642 | Reco 0.1642 | Nsdr 6.001[0m
[[36m09-09 13:27:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 12/14 | 0.14 it/sec | Loss 0.1632 | Reco 0.1632 | Nsdr 6.089[0m
[[36m09-09 13:28:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 11.1 sec/it | Loss 0.1742 | Reco 0.1742 | Nsdr 5.530[0m
[[36m09-09 13:28:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 6/14 | 0.12 it/sec | Loss 0.1644 | Reco 0.1644 | Nsdr 5.772[0m
[[36m09-09 13:29:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 9/14 | 0.13 it/sec | Loss 0.1643 | Reco 0.1643 | Nsdr 6.004[0m
[[36m09-09 13:29:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 12/14 | 0.14 it/sec | Loss 0.1634 | Reco 0.1634 | Nsdr 6.090[0m
[[36m09-09 13:29:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 13 | Loss=0.1627 | Reco=0.1627 | Nsdr=6.062 | Best=0.1627 | Bname=ema_batch_1 | Penalty=228.8999[0m
[[36m09-09 13:29:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1627[0m
[[36m09-09 13:29:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-09 13:29:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-09 14:15:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 14 | 1164/4656 | 0.42 it/sec | Loss 0.1008 | Reco 0.0986 | Grad 0.0990 | Penalty 224.4159[0m
[[36m09-09 15:01:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 14 | 2328/4656 | 0.42 it/sec | Loss 0.1004 | Reco 0.0981 | Grad 0.0987 | Penalty 226.4750[0m
[[36m09-09 15:46:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 14 | 3492/4656 | 0.42 it/sec | Loss 0.1001 | Reco 0.0979 | Grad 0.0979 | Penalty 226.6317[0m
[[36m09-09 16:32:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 14 | Loss=0.1000 | Reco=0.0977 | Grad=0.0979 | Penalty=226.5871[0m
[[36m09-09 16:32:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-09 16:32:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-09 16:33:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 3/14 | 11.4 sec/it | Loss 0.1896 | Reco 0.1896 | Nsdr 4.925[0m
[[36m09-09 16:33:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 6/14 | 0.12 it/sec | Loss 0.1755 | Reco 0.1755 | Nsdr 5.261[0m
[[36m09-09 16:33:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 9/14 | 0.12 it/sec | Loss 0.1762 | Reco 0.1762 | Nsdr 5.437[0m
[[36m09-09 16:34:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 12/14 | 0.13 it/sec | Loss 0.1744 | Reco 0.1744 | Nsdr 5.547[0m
[[36m09-09 16:34:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 3/14 | 10.8 sec/it | Loss 0.1714 | Reco 0.1714 | Nsdr 5.673[0m
[[36m09-09 16:35:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 6/14 | 0.12 it/sec | Loss 0.1624 | Reco 0.1624 | Nsdr 5.887[0m
[[36m09-09 16:35:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 9/14 | 0.13 it/sec | Loss 0.1625 | Reco 0.1625 | Nsdr 6.113[0m
[[36m09-09 16:35:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 12/14 | 0.14 it/sec | Loss 0.1616 | Reco 0.1616 | Nsdr 6.185[0m
[[36m09-09 16:36:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 3/14 | 11.3 sec/it | Loss 0.1717 | Reco 0.1717 | Nsdr 5.669[0m
[[36m09-09 16:36:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 6/14 | 0.12 it/sec | Loss 0.1623 | Reco 0.1623 | Nsdr 5.894[0m
[[36m09-09 16:37:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 9/14 | 0.13 it/sec | Loss 0.1624 | Reco 0.1624 | Nsdr 6.106[0m
[[36m09-09 16:37:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 12/14 | 0.14 it/sec | Loss 0.1613 | Reco 0.1613 | Nsdr 6.198[0m
[[36m09-09 16:38:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 3/14 | 10.7 sec/it | Loss 0.1756 | Reco 0.1756 | Nsdr 5.487[0m
[[36m09-09 16:38:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 6/14 | 0.12 it/sec | Loss 0.1649 | Reco 0.1649 | Nsdr 5.768[0m
[[36m09-09 16:38:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 9/14 | 0.13 it/sec | Loss 0.1648 | Reco 0.1648 | Nsdr 5.986[0m
[[36m09-09 16:39:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 12/14 | 0.14 it/sec | Loss 0.1638 | Reco 0.1638 | Nsdr 6.075[0m
[[36m09-09 16:40:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 3/14 | 11.2 sec/it | Loss 0.1758 | Reco 0.1758 | Nsdr 5.468[0m
[[36m09-09 16:40:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 6/14 | 0.12 it/sec | Loss 0.1651 | Reco 0.1651 | Nsdr 5.751[0m
[[36m09-09 16:40:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 9/14 | 0.13 it/sec | Loss 0.1651 | Reco 0.1651 | Nsdr 5.968[0m
[[36m09-09 16:40:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 12/14 | 0.14 it/sec | Loss 0.1640 | Reco 0.1640 | Nsdr 6.062[0m
[[36m09-09 16:41:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 14 | Loss=0.1626 | Reco=0.1626 | Nsdr=6.068 | Best=0.1626 | Bname=ema_batch_1 | Penalty=232.7782[0m
[[36m09-09 16:41:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1626[0m
[[36m09-09 16:41:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-09 16:41:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-09 17:27:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 15 | 1164/4656 | 0.42 it/sec | Loss 0.1017 | Reco 0.0994 | Grad 0.0984 | Penalty 230.2923[0m
[[36m09-09 18:12:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 15 | 2328/4656 | 0.42 it/sec | Loss 0.1006 | Reco 0.0982 | Grad 0.0958 | Penalty 235.8216[0m
[[36m09-09 18:58:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 15 | 3492/4656 | 0.42 it/sec | Loss 0.1005 | Reco 0.0981 | Grad 0.0985 | Penalty 243.7820[0m
[[36m09-09 19:43:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 15 | Loss=0.1002 | Reco=0.0978 | Grad=0.0970 | Penalty=243.1293[0m
[[36m09-09 19:43:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-09 19:43:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-09 19:44:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 3/14 | 10.8 sec/it | Loss 0.1844 | Reco 0.1844 | Nsdr 5.139[0m
[[36m09-09 19:44:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 6/14 | 0.12 it/sec | Loss 0.1695 | Reco 0.1695 | Nsdr 5.520[0m
[[36m09-09 19:45:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 9/14 | 0.13 it/sec | Loss 0.1689 | Reco 0.1689 | Nsdr 5.769[0m
[[36m09-09 19:45:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 12/14 | 0.14 it/sec | Loss 0.1677 | Reco 0.1677 | Nsdr 5.854[0m
[[36m09-09 19:46:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 3/14 | 10.6 sec/it | Loss 0.1757 | Reco 0.1757 | Nsdr 5.518[0m
[[36m09-09 19:46:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 6/14 | 0.12 it/sec | Loss 0.1645 | Reco 0.1645 | Nsdr 5.812[0m
[[36m09-09 19:46:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 9/14 | 0.13 it/sec | Loss 0.1645 | Reco 0.1645 | Nsdr 6.015[0m
[[36m09-09 19:47:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 12/14 | 0.14 it/sec | Loss 0.1634 | Reco 0.1634 | Nsdr 6.098[0m
[[36m09-09 19:48:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 3/14 | 10.7 sec/it | Loss 0.1724 | Reco 0.1724 | Nsdr 5.656[0m
[[36m09-09 19:48:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 6/14 | 0.12 it/sec | Loss 0.1626 | Reco 0.1626 | Nsdr 5.898[0m
[[36m09-09 19:48:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 9/14 | 0.13 it/sec | Loss 0.1627 | Reco 0.1627 | Nsdr 6.101[0m
[[36m09-09 19:48:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 12/14 | 0.14 it/sec | Loss 0.1616 | Reco 0.1616 | Nsdr 6.188[0m
[[36m09-09 19:49:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 3/14 | 11.2 sec/it | Loss 0.1756 | Reco 0.1756 | Nsdr 5.483[0m
[[36m09-09 19:50:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 6/14 | 0.12 it/sec | Loss 0.1648 | Reco 0.1648 | Nsdr 5.772[0m
[[36m09-09 19:50:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 9/14 | 0.13 it/sec | Loss 0.1647 | Reco 0.1647 | Nsdr 5.989[0m
[[36m09-09 19:50:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 12/14 | 0.14 it/sec | Loss 0.1635 | Reco 0.1635 | Nsdr 6.088[0m
[[36m09-09 19:51:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 3/14 | 10.9 sec/it | Loss 0.1758 | Reco 0.1758 | Nsdr 5.475[0m
[[36m09-09 19:51:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 6/14 | 0.12 it/sec | Loss 0.1651 | Reco 0.1651 | Nsdr 5.754[0m
[[36m09-09 19:52:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 9/14 | 0.13 it/sec | Loss 0.1648 | Reco 0.1648 | Nsdr 5.992[0m
[[36m09-09 19:52:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 12/14 | 0.14 it/sec | Loss 0.1637 | Reco 0.1637 | Nsdr 6.083[0m
[[36m09-09 19:52:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 15 | Loss=0.1628 | Reco=0.1628 | Nsdr=6.061 | Best=0.1626 | Bname=ema_batch_1 | Penalty=236.2042[0m
[[36m09-09 19:52:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-09 19:52:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-09 20:38:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 16 | 1164/4656 | 0.43 it/sec | Loss 0.0996 | Reco 0.0973 | Grad 0.0969 | Penalty 231.2039[0m
[[36m09-09 21:24:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 16 | 2328/4656 | 0.42 it/sec | Loss 0.0995 | Reco 0.0972 | Grad 0.0973 | Penalty 231.2926[0m
[[36m09-09 22:09:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 16 | 3492/4656 | 0.42 it/sec | Loss 0.0988 | Reco 0.0965 | Grad 0.0964 | Penalty 231.3141[0m
[[36m09-09 22:55:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 16 | Loss=0.0991 | Reco=0.0968 | Grad=0.0967 | Penalty=231.3734[0m
[[36m09-09 22:55:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-09 22:55:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-09 22:56:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 3/14 | 11.0 sec/it | Loss 0.1846 | Reco 0.1846 | Nsdr 5.178[0m
[[36m09-09 22:56:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 6/14 | 0.12 it/sec | Loss 0.1726 | Reco 0.1726 | Nsdr 5.473[0m
[[36m09-09 22:56:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 9/14 | 0.13 it/sec | Loss 0.1720 | Reco 0.1720 | Nsdr 5.702[0m
[[36m09-09 22:56:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 12/14 | 0.14 it/sec | Loss 0.1710 | Reco 0.1710 | Nsdr 5.777[0m
[[36m09-09 22:57:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 3/14 | 10.8 sec/it | Loss 0.1718 | Reco 0.1718 | Nsdr 5.657[0m
[[36m09-09 22:58:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 6/14 | 0.12 it/sec | Loss 0.1630 | Reco 0.1630 | Nsdr 5.863[0m
[[36m09-09 22:58:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 9/14 | 0.13 it/sec | Loss 0.1633 | Reco 0.1633 | Nsdr 6.073[0m
[[36m09-09 22:58:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 12/14 | 0.14 it/sec | Loss 0.1626 | Reco 0.1626 | Nsdr 6.142[0m
[[36m09-09 22:59:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 3/14 | 11.3 sec/it | Loss 0.1718 | Reco 0.1718 | Nsdr 5.675[0m
[[36m09-09 22:59:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 6/14 | 0.12 it/sec | Loss 0.1625 | Reco 0.1625 | Nsdr 5.901[0m
[[36m09-09 23:00:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 9/14 | 0.13 it/sec | Loss 0.1627 | Reco 0.1627 | Nsdr 6.111[0m
[[36m09-09 23:00:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 12/14 | 0.14 it/sec | Loss 0.1617 | Reco 0.1617 | Nsdr 6.191[0m
[[36m09-09 23:01:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 3/14 | 10.9 sec/it | Loss 0.1755 | Reco 0.1755 | Nsdr 5.506[0m
[[36m09-09 23:01:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 6/14 | 0.12 it/sec | Loss 0.1647 | Reco 0.1647 | Nsdr 5.788[0m
[[36m09-09 23:01:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 9/14 | 0.13 it/sec | Loss 0.1645 | Reco 0.1645 | Nsdr 6.015[0m
[[36m09-09 23:02:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 12/14 | 0.14 it/sec | Loss 0.1635 | Reco 0.1635 | Nsdr 6.099[0m
[[36m09-09 23:02:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 3/14 | 10.7 sec/it | Loss 0.1757 | Reco 0.1757 | Nsdr 5.495[0m
[[36m09-09 23:03:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 6/14 | 0.12 it/sec | Loss 0.1649 | Reco 0.1649 | Nsdr 5.774[0m
[[36m09-09 23:03:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 9/14 | 0.13 it/sec | Loss 0.1647 | Reco 0.1647 | Nsdr 6.006[0m
[[36m09-09 23:03:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 12/14 | 0.14 it/sec | Loss 0.1636 | Reco 0.1636 | Nsdr 6.092[0m
[[36m09-09 23:03:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 16 | Loss=0.1629 | Reco=0.1629 | Nsdr=6.065 | Best=0.1626 | Bname=ema_batch_1 | Penalty=234.0588[0m
[[36m09-09 23:04:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-09 23:04:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-09 23:49:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 17 | 1164/4656 | 0.43 it/sec | Loss 0.0996 | Reco 0.0973 | Grad 0.0950 | Penalty 230.6029[0m
[[36m09-10 00:35:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 17 | 2328/4656 | 0.43 it/sec | Loss 0.0992 | Reco 0.0968 | Grad 0.0937 | Penalty 230.9707[0m
[[36m09-10 01:20:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 17 | 3492/4656 | 0.43 it/sec | Loss 0.0989 | Reco 0.0966 | Grad 0.0942 | Penalty 230.3304[0m
[[36m09-10 02:06:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 17 | Loss=0.0988 | Reco=0.0965 | Grad=0.0942 | Penalty=230.1090[0m
[[36m09-10 02:06:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-10 02:06:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-10 02:07:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 3/14 | 10.9 sec/it | Loss 0.1793 | Reco 0.1793 | Nsdr 5.390[0m
[[36m09-10 02:07:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 6/14 | 0.12 it/sec | Loss 0.1693 | Reco 0.1693 | Nsdr 5.612[0m
[[36m09-10 02:07:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 9/14 | 0.13 it/sec | Loss 0.1689 | Reco 0.1689 | Nsdr 5.857[0m
[[36m09-10 02:08:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 12/14 | 0.14 it/sec | Loss 0.1673 | Reco 0.1673 | Nsdr 5.966[0m
[[36m09-10 02:09:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 3/14 | 11.3 sec/it | Loss 0.1726 | Reco 0.1726 | Nsdr 5.642[0m
[[36m09-10 02:09:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 6/14 | 0.12 it/sec | Loss 0.1633 | Reco 0.1633 | Nsdr 5.861[0m
[[36m09-10 02:09:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 9/14 | 0.13 it/sec | Loss 0.1630 | Reco 0.1630 | Nsdr 6.096[0m
[[36m09-10 02:09:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 12/14 | 0.14 it/sec | Loss 0.1620 | Reco 0.1620 | Nsdr 6.176[0m
[[36m09-10 02:10:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 3/14 | 11.0 sec/it | Loss 0.1718 | Reco 0.1718 | Nsdr 5.682[0m
[[36m09-10 02:11:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 6/14 | 0.12 it/sec | Loss 0.1622 | Reco 0.1622 | Nsdr 5.911[0m
[[36m09-10 02:11:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 9/14 | 0.13 it/sec | Loss 0.1624 | Reco 0.1624 | Nsdr 6.117[0m
[[36m09-10 02:11:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 12/14 | 0.14 it/sec | Loss 0.1615 | Reco 0.1615 | Nsdr 6.197[0m
[[36m09-10 02:12:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 3/14 | 11.0 sec/it | Loss 0.1746 | Reco 0.1746 | Nsdr 5.544[0m
[[36m09-10 02:12:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 6/14 | 0.12 it/sec | Loss 0.1641 | Reco 0.1641 | Nsdr 5.814[0m
[[36m09-10 02:13:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 9/14 | 0.13 it/sec | Loss 0.1640 | Reco 0.1640 | Nsdr 6.033[0m
[[36m09-10 02:13:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 12/14 | 0.14 it/sec | Loss 0.1630 | Reco 0.1630 | Nsdr 6.126[0m
[[36m09-10 02:14:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 3/14 | 10.8 sec/it | Loss 0.1752 | Reco 0.1752 | Nsdr 5.517[0m
[[36m09-10 02:14:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 6/14 | 0.12 it/sec | Loss 0.1648 | Reco 0.1648 | Nsdr 5.787[0m
[[36m09-10 02:14:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 9/14 | 0.13 it/sec | Loss 0.1646 | Reco 0.1646 | Nsdr 6.009[0m
[[36m09-10 02:15:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 12/14 | 0.14 it/sec | Loss 0.1635 | Reco 0.1635 | Nsdr 6.101[0m
[[36m09-10 02:15:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 17 | Loss=0.1627 | Reco=0.1627 | Nsdr=6.068 | Best=0.1626 | Bname=ema_batch_1 | Penalty=234.3671[0m
[[36m09-10 02:15:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-10 02:15:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-10 03:01:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 18 | 1164/4656 | 0.42 it/sec | Loss 0.0983 | Reco 0.0960 | Grad 0.0936 | Penalty 232.8275[0m
[[36m09-10 03:46:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 18 | 2328/4656 | 0.42 it/sec | Loss 0.0989 | Reco 0.0966 | Grad 0.0934 | Penalty 231.2746[0m
[[36m09-10 04:32:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 18 | 3492/4656 | 0.42 it/sec | Loss 0.0989 | Reco 0.0966 | Grad 0.0935 | Penalty 230.2050[0m
[[36m09-10 05:18:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 18 | Loss=0.0988 | Reco=0.0965 | Grad=0.0938 | Penalty=230.3223[0m
[[36m09-10 05:18:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-10 05:18:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-10 05:19:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 3/14 | 11.1 sec/it | Loss 0.1797 | Reco 0.1797 | Nsdr 5.337[0m
[[36m09-10 05:19:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 6/14 | 0.12 it/sec | Loss 0.1692 | Reco 0.1692 | Nsdr 5.589[0m
[[36m09-10 05:19:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 9/14 | 0.13 it/sec | Loss 0.1682 | Reco 0.1682 | Nsdr 5.850[0m
[[36m09-10 05:19:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 12/14 | 0.14 it/sec | Loss 0.1667 | Reco 0.1667 | Nsdr 5.953[0m
[[36m09-10 05:20:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 3/14 | 10.7 sec/it | Loss 0.1745 | Reco 0.1745 | Nsdr 5.574[0m
[[36m09-10 05:21:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 6/14 | 0.12 it/sec | Loss 0.1646 | Reco 0.1646 | Nsdr 5.818[0m
[[36m09-10 05:21:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 9/14 | 0.13 it/sec | Loss 0.1636 | Reco 0.1636 | Nsdr 6.077[0m
[[36m09-10 05:21:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 12/14 | 0.14 it/sec | Loss 0.1623 | Reco 0.1623 | Nsdr 6.169[0m
[[36m09-10 05:22:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 3/14 | 11.3 sec/it | Loss 0.1713 | Reco 0.1713 | Nsdr 5.705[0m
[[36m09-10 05:22:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 6/14 | 0.12 it/sec | Loss 0.1625 | Reco 0.1625 | Nsdr 5.905[0m
[[36m09-10 05:23:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 9/14 | 0.12 it/sec | Loss 0.1622 | Reco 0.1622 | Nsdr 6.141[0m
[[36m09-10 05:23:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 12/14 | 0.13 it/sec | Loss 0.1612 | Reco 0.1612 | Nsdr 6.222[0m
[[36m09-10 05:24:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 3/14 | 11.0 sec/it | Loss 0.1746 | Reco 0.1746 | Nsdr 5.555[0m
[[36m09-10 05:24:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 6/14 | 0.12 it/sec | Loss 0.1641 | Reco 0.1641 | Nsdr 5.825[0m
[[36m09-10 05:24:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 9/14 | 0.13 it/sec | Loss 0.1639 | Reco 0.1639 | Nsdr 6.047[0m
[[36m09-10 05:25:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 12/14 | 0.14 it/sec | Loss 0.1628 | Reco 0.1628 | Nsdr 6.142[0m
[[36m09-10 05:26:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 3/14 | 10.7 sec/it | Loss 0.1753 | Reco 0.1753 | Nsdr 5.521[0m
[[36m09-10 05:26:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 6/14 | 0.12 it/sec | Loss 0.1647 | Reco 0.1647 | Nsdr 5.791[0m
[[36m09-10 05:26:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 9/14 | 0.13 it/sec | Loss 0.1645 | Reco 0.1645 | Nsdr 6.017[0m
[[36m09-10 05:26:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 12/14 | 0.14 it/sec | Loss 0.1633 | Reco 0.1633 | Nsdr 6.113[0m
[[36m09-10 05:27:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 18 | Loss=0.1624 | Reco=0.1624 | Nsdr=6.095 | Best=0.1624 | Bname=ema_batch_1 | Penalty=236.6320[0m
[[36m09-10 05:27:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1624[0m
[[36m09-10 05:27:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-10 05:27:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-10 06:12:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 19 | 1164/4656 | 0.42 it/sec | Loss 0.0993 | Reco 0.0970 | Grad 0.0975 | Penalty 232.0356[0m
[[36m09-10 06:58:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 19 | 2328/4656 | 0.43 it/sec | Loss 0.0991 | Reco 0.0968 | Grad 0.0945 | Penalty 233.1772[0m
[[36m09-10 07:44:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 19 | 3492/4656 | 0.43 it/sec | Loss 0.0986 | Reco 0.0963 | Grad 0.0956 | Penalty 234.1887[0m
[[36m09-10 08:29:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 19 | Loss=0.0988 | Reco=0.0965 | Grad=0.0952 | Penalty=233.7349[0m
[[36m09-10 08:29:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-10 08:29:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-10 08:30:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 3/14 | 10.8 sec/it | Loss 0.1729 | Reco 0.1729 | Nsdr 5.595[0m
[[36m09-10 08:30:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 6/14 | 0.12 it/sec | Loss 0.1681 | Reco 0.1681 | Nsdr 5.644[0m
[[36m09-10 08:30:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 9/14 | 0.13 it/sec | Loss 0.1691 | Reco 0.1691 | Nsdr 5.850[0m
[[36m09-10 08:31:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 12/14 | 0.14 it/sec | Loss 0.1688 | Reco 0.1688 | Nsdr 5.898[0m
[[36m09-10 08:32:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 3/14 | 11.2 sec/it | Loss 0.1702 | Reco 0.1702 | Nsdr 5.759[0m
[[36m09-10 08:32:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 6/14 | 0.12 it/sec | Loss 0.1617 | Reco 0.1617 | Nsdr 5.941[0m
[[36m09-10 08:32:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 9/14 | 0.12 it/sec | Loss 0.1618 | Reco 0.1618 | Nsdr 6.170[0m
[[36m09-10 08:32:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 12/14 | 0.13 it/sec | Loss 0.1606 | Reco 0.1606 | Nsdr 6.259[0m
[[36m09-10 08:33:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 3/14 | 10.9 sec/it | Loss 0.1708 | Reco 0.1708 | Nsdr 5.734[0m
[[36m09-10 08:34:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 6/14 | 0.12 it/sec | Loss 0.1620 | Reco 0.1620 | Nsdr 5.932[0m
[[36m09-10 08:34:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 9/14 | 0.13 it/sec | Loss 0.1618 | Reco 0.1618 | Nsdr 6.164[0m
[[36m09-10 08:34:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 12/14 | 0.14 it/sec | Loss 0.1607 | Reco 0.1607 | Nsdr 6.251[0m
[[36m09-10 08:35:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 3/14 | 10.8 sec/it | Loss 0.1731 | Reco 0.1731 | Nsdr 5.623[0m
[[36m09-10 08:35:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 6/14 | 0.12 it/sec | Loss 0.1635 | Reco 0.1635 | Nsdr 5.854[0m
[[36m09-10 08:36:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 9/14 | 0.13 it/sec | Loss 0.1634 | Reco 0.1634 | Nsdr 6.082[0m
[[36m09-10 08:36:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 12/14 | 0.14 it/sec | Loss 0.1623 | Reco 0.1623 | Nsdr 6.171[0m
[[36m09-10 08:37:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 3/14 | 10.9 sec/it | Loss 0.1738 | Reco 0.1738 | Nsdr 5.585[0m
[[36m09-10 08:37:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 6/14 | 0.12 it/sec | Loss 0.1642 | Reco 0.1642 | Nsdr 5.822[0m
[[36m09-10 08:37:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 9/14 | 0.13 it/sec | Loss 0.1641 | Reco 0.1641 | Nsdr 6.046[0m
[[36m09-10 08:38:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 12/14 | 0.14 it/sec | Loss 0.1630 | Reco 0.1630 | Nsdr 6.135[0m
[[36m09-10 08:38:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 19 | Loss=0.1619 | Reco=0.1619 | Nsdr=6.122 | Best=0.1619 | Bname=ema_batch_0 | Penalty=236.7761[0m
[[36m09-10 08:38:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1619[0m
[[36m09-10 08:38:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-10 08:38:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-10 09:24:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 20 | 1164/4656 | 0.42 it/sec | Loss 0.1283 | Reco 0.1206 | Grad 0.1965 | Penalty 765.8889[0m
[[36m09-10 10:10:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 20 | 2328/4656 | 0.42 it/sec | Loss 0.1175 | Reco 0.1112 | Grad 0.1516 | Penalty 627.2093[0m
[[36m09-10 10:57:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 20 | 3492/4656 | 0.42 it/sec | Loss 0.1124 | Reco 0.1069 | Grad 0.1336 | Penalty 546.6371[0m
[[36m09-10 11:43:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 20 | Loss=0.1094 | Reco=0.1045 | Grad=0.1255 | Penalty=493.5563[0m
[[36m09-10 11:43:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-10 11:43:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-10 11:43:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 3/14 | 10.9 sec/it | Loss 0.1724 | Reco 0.1724 | Nsdr 5.529[0m
[[36m09-10 11:44:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 6/14 | 0.12 it/sec | Loss 0.1638 | Reco 0.1638 | Nsdr 5.756[0m
[[36m09-10 11:44:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 9/14 | 0.13 it/sec | Loss 0.1664 | Reco 0.1664 | Nsdr 5.884[0m
[[36m09-10 11:44:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 12/14 | 0.14 it/sec | Loss 0.1659 | Reco 0.1659 | Nsdr 5.944[0m
[[36m09-10 11:45:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 3/14 | 11.2 sec/it | Loss 0.1793 | Reco 0.1793 | Nsdr 5.351[0m
[[36m09-10 11:45:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 6/14 | 0.12 it/sec | Loss 0.1678 | Reco 0.1678 | Nsdr 5.625[0m
[[36m09-10 11:46:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 9/14 | 0.13 it/sec | Loss 0.1676 | Reco 0.1676 | Nsdr 5.866[0m
[[36m09-10 11:46:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 12/14 | 0.14 it/sec | Loss 0.1665 | Reco 0.1665 | Nsdr 5.941[0m
[[36m09-10 11:47:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 3/14 | 11.0 sec/it | Loss 0.1898 | Reco 0.1898 | Nsdr 4.940[0m
[[36m09-10 11:47:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 6/14 | 0.12 it/sec | Loss 0.1756 | Reco 0.1756 | Nsdr 5.269[0m
[[36m09-10 11:48:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 9/14 | 0.13 it/sec | Loss 0.1754 | Reco 0.1754 | Nsdr 5.499[0m
[[36m09-10 11:48:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 12/14 | 0.14 it/sec | Loss 0.1750 | Reco 0.1750 | Nsdr 5.543[0m
[[36m09-10 11:49:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 3/14 | 10.9 sec/it | Loss 0.1761 | Reco 0.1761 | Nsdr 5.498[0m
[[36m09-10 11:49:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 6/14 | 0.12 it/sec | Loss 0.1652 | Reco 0.1652 | Nsdr 5.762[0m
[[36m09-10 11:49:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 9/14 | 0.13 it/sec | Loss 0.1646 | Reco 0.1646 | Nsdr 6.012[0m
[[36m09-10 11:50:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 12/14 | 0.14 it/sec | Loss 0.1636 | Reco 0.1636 | Nsdr 6.096[0m
[[36m09-10 11:50:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 3/14 | 10.7 sec/it | Loss 0.1755 | Reco 0.1755 | Nsdr 5.513[0m
[[36m09-10 11:51:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 6/14 | 0.12 it/sec | Loss 0.1647 | Reco 0.1647 | Nsdr 5.786[0m
[[36m09-10 11:51:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 9/14 | 0.13 it/sec | Loss 0.1642 | Reco 0.1642 | Nsdr 6.035[0m
[[36m09-10 11:51:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 12/14 | 0.14 it/sec | Loss 0.1630 | Reco 0.1630 | Nsdr 6.131[0m
[[36m09-10 11:51:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 20 | Loss=0.1642 | Reco=0.1642 | Nsdr=6.010 | Best=0.1619 | Bname=ema_epoch_1 | Penalty=320.5002[0m
[[36m09-10 11:51:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-10 11:51:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Evaluating on the test set...[0m
[[36m09-10 11:52:33[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval | 2/10 | 12.8 sec/it[0m
[[36m09-10 11:53:01[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval | 4/10 | 13.1 sec/it[0m
[[36m09-10 11:53:32[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval | 6/10 | 13.8 sec/it[0m
[[36m09-10 11:54:02[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval | 8/10 | 14.2 sec/it[0m
[[36m09-10 12:05:37[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval (BSS) | 2/10 | 227.5 sec/it[0m
[[36m09-10 12:11:44[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval (BSS) | 4/10 | 209.7 sec/it[0m
[[36m09-10 12:19:13[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval (BSS) | 6/10 | 213.9 sec/it[0m
[[36m09-10 12:27:11[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval (BSS) | 8/10 | 219.5 sec/it[0m
[[36m09-10 12:29:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTest Summary | Epoch 20 | Sdr=4.617 | Nsdr=5.081 | Sdr_drums=6.515 | Nsdr_drums=6.499 | Sdr_bass=3.877 | Nsdr_bass=4.260 | Sdr_other=2.372 | Nsdr_other=3.010 | Sdr_vocals=5.705 | Nsdr_vocals=6.553[0m
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mParser[0m Injecting argv ['hdemucs.norm_starts=999', 'hdemucs.cac=False', 'test.split=True', 'valid_apply=True', 'model=hdemucs', 'hdemucs.dconv_lstm=4', 'ema.epoch=[0.9, 0.95]', 'ema.batch=[0.9995, 0.9999]', 'seed=42', 'hdemucs.hybrid_old=True', 'svd=base', 'svd.penalty=1e-05', 'svd.dim=100', 'svd.convtr=True', 'optim.lr=0.0005', 'batch_size=4', 'dset.segment=8', 'hdemucs.channels=24', 'test.workers=', 'epochs=20'] from sig 22d99e8f
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mExecutor:[0m Starting 1 worker processes for DDP.
[1mExecutor:[0m All workers completed successfully
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:228: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  return hydra.main(
[[36m09-10 16:18:02[0m][[34mdemucs.train[0m][[32mINFO[0m] - For logs, checkpoints and samples check /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/538354e6[0m
[[36m09-10 16:18:02[0m][[34mdora.distrib[0m][[32mINFO[0m] - world_size is 1, skipping init.[0m
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
/home/paperspace/.local/lib/python3.8/site-packages/musdb/configs/mus.yaml
[[36m09-10 16:18:11[0m][[34mdemucs.train[0m][[32mINFO[0m] - train/valid set size: 18626 14[0m
[[36m09-10 16:18:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Loading from /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/a68eaf9b/checkpoint.th[0m
[[36m09-10 16:18:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-10 16:18:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
/home/paperspace/.local/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
/home/paperspace/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
[[36m09-10 17:04:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 1 | 1164/4656 | 0.42 it/sec | Loss 0.0976 | Reco 0.0954 | Grad 0.0919 | Penalty 224.8514[0m
[[36m09-10 17:50:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 1 | 2328/4656 | 0.42 it/sec | Loss 0.0975 | Reco 0.0953 | Grad 0.0922 | Penalty 226.2894[0m
[[36m09-10 18:36:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 1 | 3492/4656 | 0.42 it/sec | Loss 0.0980 | Reco 0.0958 | Grad 0.0929 | Penalty 227.4343[0m
[[36m09-10 19:23:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 1 | Loss=0.0980 | Reco=0.0957 | Grad=0.0925 | Penalty=228.2751[0m
[[36m09-10 19:23:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-10 19:23:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-10 19:23:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 3/14 | 12.5 sec/it | Loss 0.1776 | Reco 0.1776 | Nsdr 5.424[0m
[[36m09-10 19:24:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 6/14 | 0.11 it/sec | Loss 0.1689 | Reco 0.1689 | Nsdr 5.608[0m
[[36m09-10 19:24:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 9/14 | 0.12 it/sec | Loss 0.1698 | Reco 0.1698 | Nsdr 5.770[0m
[[36m09-10 19:24:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 12/14 | 0.13 it/sec | Loss 0.1684 | Reco 0.1684 | Nsdr 5.857[0m
[[36m09-10 19:25:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 3/14 | 13.0 sec/it | Loss 0.1729 | Reco 0.1729 | Nsdr 5.652[0m
[[36m09-10 19:26:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 6/14 | 0.10 it/sec | Loss 0.1632 | Reco 0.1632 | Nsdr 5.876[0m
[[36m09-10 19:26:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 9/14 | 0.11 it/sec | Loss 0.1634 | Reco 0.1634 | Nsdr 6.084[0m
[[36m09-10 19:26:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 12/14 | 0.12 it/sec | Loss 0.1620 | Reco 0.1620 | Nsdr 6.185[0m
[[36m09-10 19:27:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 3/14 | 11.9 sec/it | Loss 0.1727 | Reco 0.1727 | Nsdr 5.653[0m
[[36m09-10 19:27:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 6/14 | 0.11 it/sec | Loss 0.1628 | Reco 0.1628 | Nsdr 5.889[0m
[[36m09-10 19:28:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 9/14 | 0.12 it/sec | Loss 0.1630 | Reco 0.1630 | Nsdr 6.102[0m
[[36m09-10 19:28:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 12/14 | 0.13 it/sec | Loss 0.1616 | Reco 0.1616 | Nsdr 6.202[0m
[[36m09-10 19:29:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 3/14 | 11.9 sec/it | Loss 0.1769 | Reco 0.1769 | Nsdr 5.458[0m
[[36m09-10 19:29:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 6/14 | 0.11 it/sec | Loss 0.1682 | Reco 0.1682 | Nsdr 5.637[0m
[[36m09-10 19:30:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 9/14 | 0.12 it/sec | Loss 0.1693 | Reco 0.1693 | Nsdr 5.796[0m
[[36m09-10 19:30:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 12/14 | 0.13 it/sec | Loss 0.1679 | Reco 0.1679 | Nsdr 5.877[0m
[[36m09-10 19:31:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 3/14 | 11.9 sec/it | Loss 0.1767 | Reco 0.1767 | Nsdr 5.463[0m
[[36m09-10 19:31:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 6/14 | 0.11 it/sec | Loss 0.1682 | Reco 0.1682 | Nsdr 5.637[0m
[[36m09-10 19:31:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 9/14 | 0.12 it/sec | Loss 0.1693 | Reco 0.1693 | Nsdr 5.789[0m
[[36m09-10 19:32:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 12/14 | 0.13 it/sec | Loss 0.1680 | Reco 0.1680 | Nsdr 5.869[0m
[[36m09-10 19:32:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 1 | Loss=0.1628 | Reco=0.1628 | Nsdr=6.070 | Best=0.1628 | Bname=ema_batch_1 | Penalty=235.9101[0m
[[36m09-10 19:32:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1628[0m
[[36m09-10 19:32:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-10 19:32:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-10 20:18:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 2 | 1164/4656 | 0.42 it/sec | Loss 0.0993 | Reco 0.0969 | Grad 0.0966 | Penalty 234.3612[0m
[[36m09-10 21:04:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 2 | 2328/4656 | 0.42 it/sec | Loss 0.0984 | Reco 0.0960 | Grad 0.0940 | Penalty 233.6044[0m
[[36m09-10 21:49:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 2 | 3492/4656 | 0.42 it/sec | Loss 0.0986 | Reco 0.0962 | Grad 0.0934 | Penalty 235.0617[0m
[[36m09-10 22:36:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 2 | Loss=0.0986 | Reco=0.0962 | Grad=0.0930 | Penalty=235.5921[0m
[[36m09-10 22:36:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-10 22:36:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-10 22:37:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 3/14 | 11.9 sec/it | Loss 0.1806 | Reco 0.1806 | Nsdr 5.356[0m
[[36m09-10 22:37:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 6/14 | 0.11 it/sec | Loss 0.1682 | Reco 0.1682 | Nsdr 5.664[0m
[[36m09-10 22:37:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 9/14 | 0.12 it/sec | Loss 0.1687 | Reco 0.1687 | Nsdr 5.835[0m
[[36m09-10 22:37:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 12/14 | 0.13 it/sec | Loss 0.1680 | Reco 0.1680 | Nsdr 5.885[0m
[[36m09-10 22:38:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 3/14 | 11.6 sec/it | Loss 0.1687 | Reco 0.1687 | Nsdr 5.829[0m
[[36m09-10 22:39:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 6/14 | 0.11 it/sec | Loss 0.1602 | Reco 0.1602 | Nsdr 6.006[0m
[[36m09-10 22:39:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 9/14 | 0.12 it/sec | Loss 0.1607 | Reco 0.1607 | Nsdr 6.206[0m
[[36m09-10 22:39:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 12/14 | 0.13 it/sec | Loss 0.1598 | Reco 0.1598 | Nsdr 6.277[0m
[[36m09-10 22:40:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 3/14 | 11.5 sec/it | Loss 0.1701 | Reco 0.1701 | Nsdr 5.767[0m
[[36m09-10 22:40:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 6/14 | 0.12 it/sec | Loss 0.1608 | Reco 0.1608 | Nsdr 5.974[0m
[[36m09-10 22:41:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 9/14 | 0.12 it/sec | Loss 0.1612 | Reco 0.1612 | Nsdr 6.178[0m
[[36m09-10 22:41:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 12/14 | 0.13 it/sec | Loss 0.1601 | Reco 0.1601 | Nsdr 6.265[0m
[[36m09-10 22:42:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 3/14 | 11.5 sec/it | Loss 0.1755 | Reco 0.1755 | Nsdr 5.562[0m
[[36m09-10 22:42:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 6/14 | 0.12 it/sec | Loss 0.1652 | Reco 0.1652 | Nsdr 5.803[0m
[[36m09-10 22:43:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 9/14 | 0.12 it/sec | Loss 0.1658 | Reco 0.1658 | Nsdr 5.973[0m
[[36m09-10 22:43:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 12/14 | 0.13 it/sec | Loss 0.1646 | Reco 0.1646 | Nsdr 6.048[0m
[[36m09-10 22:44:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 3/14 | 11.2 sec/it | Loss 0.1757 | Reco 0.1757 | Nsdr 5.554[0m
[[36m09-10 22:44:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 6/14 | 0.12 it/sec | Loss 0.1653 | Reco 0.1653 | Nsdr 5.800[0m
[[36m09-10 22:44:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 9/14 | 0.13 it/sec | Loss 0.1658 | Reco 0.1658 | Nsdr 5.973[0m
[[36m09-10 22:45:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 12/14 | 0.14 it/sec | Loss 0.1648 | Reco 0.1648 | Nsdr 6.040[0m
[[36m09-10 22:45:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 2 | Loss=0.1613 | Reco=0.1613 | Nsdr=6.130 | Best=0.1613 | Bname=ema_batch_0 | Penalty=239.2919[0m
[[36m09-10 22:45:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1613[0m
[[36m09-10 22:45:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-10 22:45:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-10 23:32:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 3 | 1164/4656 | 0.41 it/sec | Loss 0.0973 | Reco 0.0949 | Grad 0.0949 | Penalty 233.4713[0m
[[36m09-11 00:18:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 3 | 2328/4656 | 0.42 it/sec | Loss 0.0980 | Reco 0.0956 | Grad 0.0946 | Penalty 234.0039[0m
[[36m09-11 01:04:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 3 | 3492/4656 | 0.42 it/sec | Loss 0.0981 | Reco 0.0958 | Grad 0.0938 | Penalty 234.0390[0m
[[36m09-11 01:50:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 3 | Loss=0.0977 | Reco=0.0954 | Grad=0.0928 | Penalty=234.2222[0m
[[36m09-11 01:50:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-11 01:50:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-11 01:51:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 3/14 | 11.4 sec/it | Loss 0.1787 | Reco 0.1787 | Nsdr 5.342[0m
[[36m09-11 01:51:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 6/14 | 0.12 it/sec | Loss 0.1694 | Reco 0.1694 | Nsdr 5.577[0m
[[36m09-11 01:51:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 9/14 | 0.12 it/sec | Loss 0.1693 | Reco 0.1693 | Nsdr 5.812[0m
[[36m09-11 01:52:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 12/14 | 0.13 it/sec | Loss 0.1677 | Reco 0.1677 | Nsdr 5.914[0m
[[36m09-11 01:53:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 3/14 | 11.3 sec/it | Loss 0.1693 | Reco 0.1693 | Nsdr 5.785[0m
[[36m09-11 01:53:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 6/14 | 0.12 it/sec | Loss 0.1602 | Reco 0.1602 | Nsdr 5.989[0m
[[36m09-11 01:53:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 9/14 | 0.12 it/sec | Loss 0.1612 | Reco 0.1612 | Nsdr 6.163[0m
[[36m09-11 01:53:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 12/14 | 0.13 it/sec | Loss 0.1605 | Reco 0.1605 | Nsdr 6.230[0m
[[36m09-11 01:54:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 3/14 | 12.5 sec/it | Loss 0.1696 | Reco 0.1696 | Nsdr 5.778[0m
[[36m09-11 01:55:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 6/14 | 0.11 it/sec | Loss 0.1603 | Reco 0.1603 | Nsdr 5.993[0m
[[36m09-11 01:55:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 9/14 | 0.12 it/sec | Loss 0.1608 | Reco 0.1608 | Nsdr 6.194[0m
[[36m09-11 01:55:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 12/14 | 0.13 it/sec | Loss 0.1599 | Reco 0.1599 | Nsdr 6.275[0m
[[36m09-11 01:56:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 3/14 | 11.6 sec/it | Loss 0.1739 | Reco 0.1739 | Nsdr 5.631[0m
[[36m09-11 01:56:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 6/14 | 0.11 it/sec | Loss 0.1642 | Reco 0.1642 | Nsdr 5.859[0m
[[36m09-11 01:57:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 9/14 | 0.12 it/sec | Loss 0.1645 | Reco 0.1645 | Nsdr 6.052[0m
[[36m09-11 01:57:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 12/14 | 0.13 it/sec | Loss 0.1633 | Reco 0.1633 | Nsdr 6.126[0m
[[36m09-11 01:58:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 3/14 | 11.3 sec/it | Loss 0.1737 | Reco 0.1737 | Nsdr 5.630[0m
[[36m09-11 01:58:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 6/14 | 0.12 it/sec | Loss 0.1641 | Reco 0.1641 | Nsdr 5.856[0m
[[36m09-11 01:59:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 9/14 | 0.12 it/sec | Loss 0.1644 | Reco 0.1644 | Nsdr 6.052[0m
[[36m09-11 01:59:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 12/14 | 0.13 it/sec | Loss 0.1632 | Reco 0.1632 | Nsdr 6.132[0m
[[36m09-11 01:59:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 3 | Loss=0.1613 | Reco=0.1613 | Nsdr=6.134 | Best=0.1613 | Bname=ema_batch_1 | Penalty=238.4808[0m
[[36m09-11 01:59:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1613[0m
[[36m09-11 01:59:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-11 01:59:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-11 02:45:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 4 | 1164/4656 | 0.42 it/sec | Loss 0.0973 | Reco 0.0950 | Grad 0.0900 | Penalty 232.1319[0m
[[36m09-11 03:31:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 4 | 2328/4656 | 0.42 it/sec | Loss 0.0974 | Reco 0.0951 | Grad 0.0901 | Penalty 231.4427[0m
[[36m09-11 04:18:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 4 | 3492/4656 | 0.42 it/sec | Loss 0.0978 | Reco 0.0955 | Grad 0.0909 | Penalty 231.6475[0m
[[36m09-11 05:04:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 4 | Loss=0.0973 | Reco=0.0950 | Grad=0.0912 | Penalty=232.4990[0m
[[36m09-11 05:04:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-11 05:04:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-11 05:05:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 3/14 | 12.1 sec/it | Loss 0.1836 | Reco 0.1836 | Nsdr 5.240[0m
[[36m09-11 05:05:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 6/14 | 0.11 it/sec | Loss 0.1706 | Reco 0.1706 | Nsdr 5.583[0m
[[36m09-11 05:06:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 9/14 | 0.12 it/sec | Loss 0.1713 | Reco 0.1713 | Nsdr 5.739[0m
[[36m09-11 05:06:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 12/14 | 0.13 it/sec | Loss 0.1690 | Reco 0.1690 | Nsdr 5.868[0m
[[36m09-11 05:07:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 3/14 | 11.8 sec/it | Loss 0.1732 | Reco 0.1732 | Nsdr 5.649[0m
[[36m09-11 05:07:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 6/14 | 0.11 it/sec | Loss 0.1625 | Reco 0.1625 | Nsdr 5.914[0m
[[36m09-11 05:07:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 9/14 | 0.12 it/sec | Loss 0.1626 | Reco 0.1626 | Nsdr 6.108[0m
[[36m09-11 05:08:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 12/14 | 0.13 it/sec | Loss 0.1614 | Reco 0.1614 | Nsdr 6.201[0m
[[36m09-11 05:09:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 3/14 | 11.3 sec/it | Loss 0.1705 | Reco 0.1705 | Nsdr 5.749[0m
[[36m09-11 05:09:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 6/14 | 0.12 it/sec | Loss 0.1608 | Reco 0.1608 | Nsdr 5.980[0m
[[36m09-11 05:09:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 9/14 | 0.12 it/sec | Loss 0.1610 | Reco 0.1610 | Nsdr 6.189[0m
[[36m09-11 05:10:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 12/14 | 0.13 it/sec | Loss 0.1600 | Reco 0.1600 | Nsdr 6.274[0m
[[36m09-11 05:10:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 3/14 | 11.4 sec/it | Loss 0.1735 | Reco 0.1735 | Nsdr 5.644[0m
[[36m09-11 05:11:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 6/14 | 0.12 it/sec | Loss 0.1637 | Reco 0.1637 | Nsdr 5.886[0m
[[36m09-11 05:11:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 9/14 | 0.12 it/sec | Loss 0.1641 | Reco 0.1641 | Nsdr 6.079[0m
[[36m09-11 05:11:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 12/14 | 0.13 it/sec | Loss 0.1626 | Reco 0.1626 | Nsdr 6.171[0m
[[36m09-11 05:12:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 3/14 | 11.5 sec/it | Loss 0.1732 | Reco 0.1732 | Nsdr 5.654[0m
[[36m09-11 05:12:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 6/14 | 0.12 it/sec | Loss 0.1636 | Reco 0.1636 | Nsdr 5.886[0m
[[36m09-11 05:13:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 9/14 | 0.12 it/sec | Loss 0.1640 | Reco 0.1640 | Nsdr 6.078[0m
[[36m09-11 05:13:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 12/14 | 0.13 it/sec | Loss 0.1626 | Reco 0.1626 | Nsdr 6.172[0m
[[36m09-11 05:13:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 4 | Loss=0.1614 | Reco=0.1614 | Nsdr=6.129 | Best=0.1613 | Bname=ema_batch_1 | Penalty=239.0826[0m
[[36m09-11 05:13:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-11 05:13:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-11 06:00:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 5 | 1164/4656 | 0.42 it/sec | Loss 0.0974 | Reco 0.0950 | Grad 0.0919 | Penalty 233.1127[0m
[[36m09-11 06:46:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 5 | 2328/4656 | 0.42 it/sec | Loss 0.0977 | Reco 0.0954 | Grad 0.0932 | Penalty 232.8416[0m
[[36m09-11 07:31:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 5 | 3492/4656 | 0.42 it/sec | Loss 0.0971 | Reco 0.0947 | Grad 0.0928 | Penalty 233.6097[0m
[[36m09-11 08:17:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 5 | Loss=0.0972 | Reco=0.0948 | Grad=0.0924 | Penalty=233.9507[0m
[[36m09-11 08:17:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-11 08:17:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-11 08:17:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 3/14 | 11.1 sec/it | Loss 0.1791 | Reco 0.1791 | Nsdr 5.362[0m
[[36m09-11 08:18:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 6/14 | 0.12 it/sec | Loss 0.1683 | Reco 0.1683 | Nsdr 5.615[0m
[[36m09-11 08:18:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 9/14 | 0.13 it/sec | Loss 0.1677 | Reco 0.1677 | Nsdr 5.847[0m
[[36m09-11 08:18:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 12/14 | 0.14 it/sec | Loss 0.1664 | Reco 0.1664 | Nsdr 5.935[0m
[[36m09-11 08:19:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 3/14 | 11.0 sec/it | Loss 0.1705 | Reco 0.1705 | Nsdr 5.751[0m
[[36m09-11 08:19:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 6/14 | 0.12 it/sec | Loss 0.1610 | Reco 0.1610 | Nsdr 5.973[0m
[[36m09-11 08:20:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 9/14 | 0.13 it/sec | Loss 0.1612 | Reco 0.1612 | Nsdr 6.176[0m
[[36m09-11 08:20:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 12/14 | 0.14 it/sec | Loss 0.1603 | Reco 0.1603 | Nsdr 6.249[0m
[[36m09-11 08:21:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 3/14 | 11.1 sec/it | Loss 0.1692 | Reco 0.1692 | Nsdr 5.799[0m
[[36m09-11 08:21:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 6/14 | 0.12 it/sec | Loss 0.1604 | Reco 0.1604 | Nsdr 6.003[0m
[[36m09-11 08:21:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 9/14 | 0.13 it/sec | Loss 0.1607 | Reco 0.1607 | Nsdr 6.203[0m
[[36m09-11 08:22:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 12/14 | 0.14 it/sec | Loss 0.1598 | Reco 0.1598 | Nsdr 6.284[0m
[[36m09-11 08:22:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 3/14 | 10.9 sec/it | Loss 0.1718 | Reco 0.1718 | Nsdr 5.706[0m
[[36m09-11 08:23:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 6/14 | 0.12 it/sec | Loss 0.1626 | Reco 0.1626 | Nsdr 5.918[0m
[[36m09-11 08:23:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 9/14 | 0.13 it/sec | Loss 0.1630 | Reco 0.1630 | Nsdr 6.111[0m
[[36m09-11 08:23:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 12/14 | 0.14 it/sec | Loss 0.1617 | Reco 0.1617 | Nsdr 6.201[0m
[[36m09-11 08:24:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 3/14 | 10.9 sec/it | Loss 0.1720 | Reco 0.1720 | Nsdr 5.696[0m
[[36m09-11 08:24:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 6/14 | 0.12 it/sec | Loss 0.1628 | Reco 0.1628 | Nsdr 5.912[0m
[[36m09-11 08:25:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 9/14 | 0.13 it/sec | Loss 0.1631 | Reco 0.1631 | Nsdr 6.113[0m
[[36m09-11 08:25:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 12/14 | 0.14 it/sec | Loss 0.1618 | Reco 0.1618 | Nsdr 6.198[0m
[[36m09-11 08:25:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 5 | Loss=0.1612 | Reco=0.1612 | Nsdr=6.144 | Best=0.1612 | Bname=ema_batch_1 | Penalty=240.0603[0m
[[36m09-11 08:25:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1612[0m
[[36m09-11 08:25:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-11 08:25:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-11 09:11:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 6 | 1164/4656 | 0.43 it/sec | Loss 0.0978 | Reco 0.0954 | Grad 0.0908 | Penalty 236.8109[0m
[[36m09-11 09:56:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 6 | 2328/4656 | 0.43 it/sec | Loss 0.0971 | Reco 0.0947 | Grad 0.0912 | Penalty 235.7951[0m
[[36m09-11 10:42:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 6 | 3492/4656 | 0.43 it/sec | Loss 0.0969 | Reco 0.0945 | Grad 0.0909 | Penalty 235.8188[0m
[[36m09-11 11:28:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 6 | Loss=0.0967 | Reco=0.0943 | Grad=0.0908 | Penalty=235.9014[0m
[[36m09-11 11:28:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-11 11:28:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-11 11:28:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 3/14 | 11.1 sec/it | Loss 0.1726 | Reco 0.1726 | Nsdr 5.660[0m
[[36m09-11 11:29:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 6/14 | 0.12 it/sec | Loss 0.1638 | Reco 0.1638 | Nsdr 5.822[0m
[[36m09-11 11:29:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 9/14 | 0.13 it/sec | Loss 0.1638 | Reco 0.1638 | Nsdr 6.048[0m
[[36m09-11 11:29:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 12/14 | 0.14 it/sec | Loss 0.1634 | Reco 0.1634 | Nsdr 6.091[0m
[[36m09-11 11:30:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 3/14 | 11.1 sec/it | Loss 0.1705 | Reco 0.1705 | Nsdr 5.735[0m
[[36m09-11 11:30:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 6/14 | 0.12 it/sec | Loss 0.1608 | Reco 0.1608 | Nsdr 5.984[0m
[[36m09-11 11:31:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 9/14 | 0.13 it/sec | Loss 0.1610 | Reco 0.1610 | Nsdr 6.184[0m
[[36m09-11 11:31:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 12/14 | 0.14 it/sec | Loss 0.1601 | Reco 0.1601 | Nsdr 6.260[0m
[[36m09-11 11:32:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 3/14 | 11.4 sec/it | Loss 0.1694 | Reco 0.1694 | Nsdr 5.799[0m
[[36m09-11 11:32:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 6/14 | 0.12 it/sec | Loss 0.1602 | Reco 0.1602 | Nsdr 6.020[0m
[[36m09-11 11:32:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 9/14 | 0.12 it/sec | Loss 0.1604 | Reco 0.1604 | Nsdr 6.229[0m
[[36m09-11 11:33:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 12/14 | 0.13 it/sec | Loss 0.1595 | Reco 0.1595 | Nsdr 6.301[0m
[[36m09-11 11:34:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 3/14 | 10.8 sec/it | Loss 0.1697 | Reco 0.1697 | Nsdr 5.797[0m
[[36m09-11 11:34:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 6/14 | 0.12 it/sec | Loss 0.1610 | Reco 0.1610 | Nsdr 5.984[0m
[[36m09-11 11:34:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 9/14 | 0.13 it/sec | Loss 0.1612 | Reco 0.1612 | Nsdr 6.194[0m
[[36m09-11 11:34:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 12/14 | 0.14 it/sec | Loss 0.1603 | Reco 0.1603 | Nsdr 6.267[0m
[[36m09-11 11:35:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 3/14 | 10.9 sec/it | Loss 0.1694 | Reco 0.1694 | Nsdr 5.808[0m
[[36m09-11 11:36:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 6/14 | 0.12 it/sec | Loss 0.1610 | Reco 0.1610 | Nsdr 5.988[0m
[[36m09-11 11:36:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 9/14 | 0.13 it/sec | Loss 0.1613 | Reco 0.1613 | Nsdr 6.193[0m
[[36m09-11 11:36:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 12/14 | 0.14 it/sec | Loss 0.1604 | Reco 0.1604 | Nsdr 6.265[0m
[[36m09-11 11:36:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 6 | Loss=0.1610 | Reco=0.1610 | Nsdr=6.159 | Best=0.1610 | Bname=ema_batch_1 | Penalty=241.6552[0m
[[36m09-11 11:36:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1610[0m
[[36m09-11 11:36:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-11 11:36:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-11 12:22:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 7 | 1164/4656 | 0.42 it/sec | Loss 0.0956 | Reco 0.0932 | Grad 0.0943 | Penalty 237.7833[0m
[[36m09-11 13:08:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 7 | 2328/4656 | 0.42 it/sec | Loss 0.0971 | Reco 0.0947 | Grad 0.0948 | Penalty 238.5511[0m
[[36m09-11 13:54:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 7 | 3492/4656 | 0.42 it/sec | Loss 0.0973 | Reco 0.0949 | Grad 0.0944 | Penalty 238.9342[0m
[[36m09-11 14:40:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 7 | Loss=0.0970 | Reco=0.0946 | Grad=0.0932 | Penalty=238.8025[0m
[[36m09-11 14:40:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-11 14:40:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-11 14:41:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 3/14 | 11.6 sec/it | Loss 0.1787 | Reco 0.1787 | Nsdr 5.407[0m
[[36m09-11 14:41:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 6/14 | 0.11 it/sec | Loss 0.1679 | Reco 0.1679 | Nsdr 5.656[0m
[[36m09-11 14:42:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 9/14 | 0.12 it/sec | Loss 0.1672 | Reco 0.1672 | Nsdr 5.905[0m
[[36m09-11 14:42:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 12/14 | 0.13 it/sec | Loss 0.1657 | Reco 0.1657 | Nsdr 6.007[0m
[[36m09-11 14:43:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 3/14 | 11.5 sec/it | Loss 0.1680 | Reco 0.1680 | Nsdr 5.874[0m
[[36m09-11 14:43:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 6/14 | 0.12 it/sec | Loss 0.1600 | Reco 0.1600 | Nsdr 6.039[0m
[[36m09-11 14:44:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 9/14 | 0.12 it/sec | Loss 0.1604 | Reco 0.1604 | Nsdr 6.232[0m
[[36m09-11 14:44:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 12/14 | 0.13 it/sec | Loss 0.1596 | Reco 0.1596 | Nsdr 6.295[0m
[[36m09-11 14:45:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 3/14 | 10.9 sec/it | Loss 0.1678 | Reco 0.1678 | Nsdr 5.868[0m
[[36m09-11 14:45:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 6/14 | 0.12 it/sec | Loss 0.1592 | Reco 0.1592 | Nsdr 6.062[0m
[[36m09-11 14:45:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 9/14 | 0.13 it/sec | Loss 0.1597 | Reco 0.1597 | Nsdr 6.254[0m
[[36m09-11 14:46:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 12/14 | 0.14 it/sec | Loss 0.1590 | Reco 0.1590 | Nsdr 6.321[0m
[[36m09-11 14:46:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 3/14 | 11.1 sec/it | Loss 0.1696 | Reco 0.1696 | Nsdr 5.810[0m
[[36m09-11 14:47:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 6/14 | 0.12 it/sec | Loss 0.1609 | Reco 0.1609 | Nsdr 5.996[0m
[[36m09-11 14:47:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 9/14 | 0.13 it/sec | Loss 0.1611 | Reco 0.1611 | Nsdr 6.205[0m
[[36m09-11 14:47:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 12/14 | 0.14 it/sec | Loss 0.1600 | Reco 0.1600 | Nsdr 6.283[0m
[[36m09-11 14:48:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 3/14 | 10.8 sec/it | Loss 0.1696 | Reco 0.1696 | Nsdr 5.811[0m
[[36m09-11 14:48:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 6/14 | 0.12 it/sec | Loss 0.1608 | Reco 0.1608 | Nsdr 6.002[0m
[[36m09-11 14:49:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 9/14 | 0.13 it/sec | Loss 0.1611 | Reco 0.1611 | Nsdr 6.205[0m
[[36m09-11 14:49:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 12/14 | 0.14 it/sec | Loss 0.1601 | Reco 0.1601 | Nsdr 6.280[0m
[[36m09-11 14:49:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 7 | Loss=0.1604 | Reco=0.1604 | Nsdr=6.177 | Best=0.1604 | Bname=ema_batch_1 | Penalty=242.8168[0m
[[36m09-11 14:49:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1604[0m
[[36m09-11 14:49:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-11 14:49:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-11 15:35:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 8 | 1164/4656 | 0.42 it/sec | Loss 0.0960 | Reco 0.0937 | Grad 0.0951 | Penalty 238.3396[0m
[[36m09-11 16:21:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 8 | 2328/4656 | 0.42 it/sec | Loss 0.0971 | Reco 0.0948 | Grad 0.0930 | Penalty 238.2273[0m
[[36m09-11 17:08:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 8 | 3492/4656 | 0.42 it/sec | Loss 0.0966 | Reco 0.0942 | Grad 0.0935 | Penalty 239.5691[0m
[[36m09-11 17:55:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 8 | Loss=0.0966 | Reco=0.0942 | Grad=0.0946 | Penalty=239.6425[0m
[[36m09-11 17:55:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-11 17:55:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-11 17:56:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 11.1 sec/it | Loss 0.1681 | Reco 0.1681 | Nsdr 5.796[0m
[[36m09-11 17:56:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.12 it/sec | Loss 0.1613 | Reco 0.1613 | Nsdr 5.942[0m
[[36m09-11 17:56:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.13 it/sec | Loss 0.1639 | Reco 0.1639 | Nsdr 6.019[0m
[[36m09-11 17:57:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.14 it/sec | Loss 0.1636 | Reco 0.1636 | Nsdr 6.060[0m
[[36m09-11 17:57:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 11.0 sec/it | Loss 0.1683 | Reco 0.1683 | Nsdr 5.844[0m
[[36m09-11 17:58:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.12 it/sec | Loss 0.1597 | Reco 0.1597 | Nsdr 6.033[0m
[[36m09-11 17:58:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.13 it/sec | Loss 0.1608 | Reco 0.1608 | Nsdr 6.178[0m
[[36m09-11 17:58:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.14 it/sec | Loss 0.1599 | Reco 0.1599 | Nsdr 6.258[0m
[[36m09-11 17:59:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 10.9 sec/it | Loss 0.1677 | Reco 0.1677 | Nsdr 5.881[0m
[[36m09-11 17:59:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.12 it/sec | Loss 0.1593 | Reco 0.1593 | Nsdr 6.070[0m
[[36m09-11 18:00:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.13 it/sec | Loss 0.1599 | Reco 0.1599 | Nsdr 6.249[0m
[[36m09-11 18:00:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.14 it/sec | Loss 0.1590 | Reco 0.1590 | Nsdr 6.324[0m
[[36m09-11 18:01:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 10.9 sec/it | Loss 0.1679 | Reco 0.1679 | Nsdr 5.875[0m
[[36m09-11 18:01:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.12 it/sec | Loss 0.1596 | Reco 0.1596 | Nsdr 6.051[0m
[[36m09-11 18:01:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.13 it/sec | Loss 0.1603 | Reco 0.1603 | Nsdr 6.227[0m
[[36m09-11 18:02:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.14 it/sec | Loss 0.1596 | Reco 0.1596 | Nsdr 6.292[0m
[[36m09-11 18:03:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 10.7 sec/it | Loss 0.1684 | Reco 0.1684 | Nsdr 5.853[0m
[[36m09-11 18:03:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.12 it/sec | Loss 0.1600 | Reco 0.1600 | Nsdr 6.036[0m
[[36m09-11 18:03:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.13 it/sec | Loss 0.1607 | Reco 0.1607 | Nsdr 6.215[0m
[[36m09-11 18:03:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.14 it/sec | Loss 0.1598 | Reco 0.1598 | Nsdr 6.284[0m
[[36m09-11 18:04:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 8 | Loss=0.1603 | Reco=0.1603 | Nsdr=6.188 | Best=0.1603 | Bname=ema_batch_1 | Penalty=245.5708[0m
[[36m09-11 18:04:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1603[0m
[[36m09-11 18:04:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-11 18:04:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-11 18:50:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 9 | 1164/4656 | 0.42 it/sec | Loss 0.0968 | Reco 0.0944 | Grad 0.0942 | Penalty 239.2515[0m
[[36m09-11 19:36:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 9 | 2328/4656 | 0.42 it/sec | Loss 0.0963 | Reco 0.0939 | Grad 0.0911 | Penalty 237.7482[0m
[[36m09-11 20:22:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 9 | 3492/4656 | 0.42 it/sec | Loss 0.0961 | Reco 0.0937 | Grad 0.0910 | Penalty 239.0498[0m
[[36m09-11 21:08:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 9 | Loss=0.0958 | Reco=0.0934 | Grad=0.0912 | Penalty=238.8204[0m
[[36m09-11 21:08:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-11 21:08:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-11 21:09:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 11.4 sec/it | Loss 0.1839 | Reco 0.1839 | Nsdr 5.189[0m
[[36m09-11 21:09:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.12 it/sec | Loss 0.1723 | Reco 0.1723 | Nsdr 5.487[0m
[[36m09-11 21:10:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.12 it/sec | Loss 0.1714 | Reco 0.1714 | Nsdr 5.714[0m
[[36m09-11 21:10:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.13 it/sec | Loss 0.1693 | Reco 0.1693 | Nsdr 5.832[0m
[[36m09-11 21:11:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 12.2 sec/it | Loss 0.1683 | Reco 0.1683 | Nsdr 5.834[0m
[[36m09-11 21:11:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.11 it/sec | Loss 0.1599 | Reco 0.1599 | Nsdr 6.021[0m
[[36m09-11 21:12:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.12 it/sec | Loss 0.1606 | Reco 0.1606 | Nsdr 6.191[0m
[[36m09-11 21:12:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.13 it/sec | Loss 0.1595 | Reco 0.1595 | Nsdr 6.279[0m
[[36m09-11 21:13:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 11.6 sec/it | Loss 0.1679 | Reco 0.1679 | Nsdr 5.860[0m
[[36m09-11 21:13:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.11 it/sec | Loss 0.1592 | Reco 0.1592 | Nsdr 6.061[0m
[[36m09-11 21:13:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.12 it/sec | Loss 0.1598 | Reco 0.1598 | Nsdr 6.243[0m
[[36m09-11 21:14:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.13 it/sec | Loss 0.1588 | Reco 0.1588 | Nsdr 6.324[0m
[[36m09-11 21:15:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 11.7 sec/it | Loss 0.1688 | Reco 0.1688 | Nsdr 5.833[0m
[[36m09-11 21:15:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.11 it/sec | Loss 0.1599 | Reco 0.1599 | Nsdr 6.036[0m
[[36m09-11 21:15:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.12 it/sec | Loss 0.1604 | Reco 0.1604 | Nsdr 6.220[0m
[[36m09-11 21:15:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.13 it/sec | Loss 0.1595 | Reco 0.1595 | Nsdr 6.292[0m
[[36m09-11 21:16:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 11.5 sec/it | Loss 0.1690 | Reco 0.1690 | Nsdr 5.830[0m
[[36m09-11 21:17:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.12 it/sec | Loss 0.1602 | Reco 0.1602 | Nsdr 6.027[0m
[[36m09-11 21:17:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.12 it/sec | Loss 0.1606 | Reco 0.1606 | Nsdr 6.217[0m
[[36m09-11 21:17:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.13 it/sec | Loss 0.1597 | Reco 0.1597 | Nsdr 6.289[0m
[[36m09-11 21:17:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 9 | Loss=0.1601 | Reco=0.1601 | Nsdr=6.193 | Best=0.1601 | Bname=ema_batch_1 | Penalty=243.7046[0m
[[36m09-11 21:17:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1601[0m
[[36m09-11 21:18:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-11 21:18:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-11 22:06:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 10 | 1164/4656 | 0.40 it/sec | Loss 0.0964 | Reco 0.0940 | Grad 0.0909 | Penalty 237.6833[0m
[[36m09-11 22:53:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 10 | 2328/4656 | 0.41 it/sec | Loss 0.0958 | Reco 0.0934 | Grad 0.0901 | Penalty 237.5920[0m
[[36m09-11 23:40:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 10 | 3492/4656 | 0.41 it/sec | Loss 0.0959 | Reco 0.0936 | Grad 0.0907 | Penalty 237.8739[0m
[[36m09-12 00:31:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 10 | Loss=0.0955 | Reco=0.0931 | Grad=0.0904 | Penalty=238.0518[0m
[[36m09-12 00:31:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-12 00:31:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-12 00:32:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 14.8 sec/it | Loss 0.1780 | Reco 0.1780 | Nsdr 5.427[0m
[[36m09-12 00:32:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 10.8 sec/it | Loss 0.1684 | Reco 0.1684 | Nsdr 5.646[0m
[[36m09-12 00:33:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.10 it/sec | Loss 0.1701 | Reco 0.1701 | Nsdr 5.754[0m
[[36m09-12 00:33:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.11 it/sec | Loss 0.1681 | Reco 0.1681 | Nsdr 5.877[0m
[[36m09-12 00:34:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 14.1 sec/it | Loss 0.1686 | Reco 0.1686 | Nsdr 5.855[0m
[[36m09-12 00:34:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 10.3 sec/it | Loss 0.1607 | Reco 0.1607 | Nsdr 6.016[0m
[[36m09-12 00:35:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.11 it/sec | Loss 0.1608 | Reco 0.1608 | Nsdr 6.209[0m
[[36m09-12 00:35:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.12 it/sec | Loss 0.1596 | Reco 0.1596 | Nsdr 6.299[0m
[[36m09-12 00:36:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 15.0 sec/it | Loss 0.1671 | Reco 0.1671 | Nsdr 5.906[0m
[[36m09-12 00:36:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 10.8 sec/it | Loss 0.1589 | Reco 0.1589 | Nsdr 6.087[0m
[[36m09-12 00:37:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.10 it/sec | Loss 0.1594 | Reco 0.1594 | Nsdr 6.266[0m
[[36m09-12 00:37:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.11 it/sec | Loss 0.1585 | Reco 0.1585 | Nsdr 6.346[0m
[[36m09-12 00:38:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 14.5 sec/it | Loss 0.1690 | Reco 0.1690 | Nsdr 5.830[0m
[[36m09-12 00:39:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 10.6 sec/it | Loss 0.1604 | Reco 0.1604 | Nsdr 6.024[0m
[[36m09-12 00:39:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.10 it/sec | Loss 0.1607 | Reco 0.1607 | Nsdr 6.212[0m
[[36m09-12 00:39:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.11 it/sec | Loss 0.1597 | Reco 0.1597 | Nsdr 6.289[0m
[[36m09-12 00:40:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 14.2 sec/it | Loss 0.1695 | Reco 0.1695 | Nsdr 5.807[0m
[[36m09-12 00:41:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 10.3 sec/it | Loss 0.1606 | Reco 0.1606 | Nsdr 6.010[0m
[[36m09-12 00:41:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.11 it/sec | Loss 0.1610 | Reco 0.1610 | Nsdr 6.197[0m
[[36m09-12 00:41:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.12 it/sec | Loss 0.1599 | Reco 0.1599 | Nsdr 6.281[0m
[[36m09-12 00:41:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 10 | Loss=0.1597 | Reco=0.1597 | Nsdr=6.216 | Best=0.1597 | Bname=ema_batch_1 | Penalty=244.8525[0m
[[36m09-12 00:41:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1597[0m
[[36m09-12 00:42:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-12 00:42:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-12 01:31:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 11 | 1164/4656 | 0.39 it/sec | Loss 0.0956 | Reco 0.0932 | Grad 0.0922 | Penalty 237.8448[0m
[[36m09-12 02:21:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 11 | 2328/4656 | 0.39 it/sec | Loss 0.0959 | Reco 0.0935 | Grad 0.0915 | Penalty 237.5604[0m
[[36m09-12 03:11:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 11 | 3492/4656 | 0.39 it/sec | Loss 0.0964 | Reco 0.0940 | Grad 0.0931 | Penalty 240.6371[0m
[[36m09-12 04:01:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 11 | Loss=0.0962 | Reco=0.0938 | Grad=0.0931 | Penalty=241.4326[0m
[[36m09-12 04:01:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-12 04:01:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-12 04:02:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 12.9 sec/it | Loss 0.1663 | Reco 0.1663 | Nsdr 5.860[0m
[[36m09-12 04:02:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.10 it/sec | Loss 0.1646 | Reco 0.1646 | Nsdr 5.814[0m
[[36m09-12 04:03:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.11 it/sec | Loss 0.1659 | Reco 0.1659 | Nsdr 5.969[0m
[[36m09-12 04:03:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.12 it/sec | Loss 0.1657 | Reco 0.1657 | Nsdr 6.004[0m
[[36m09-12 04:04:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 13.4 sec/it | Loss 0.1682 | Reco 0.1682 | Nsdr 5.864[0m
[[36m09-12 04:04:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.10 it/sec | Loss 0.1601 | Reco 0.1601 | Nsdr 6.024[0m
[[36m09-12 04:05:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.11 it/sec | Loss 0.1600 | Reco 0.1600 | Nsdr 6.245[0m
[[36m09-12 04:05:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.12 it/sec | Loss 0.1589 | Reco 0.1589 | Nsdr 6.330[0m
[[36m09-12 04:06:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 12.0 sec/it | Loss 0.1677 | Reco 0.1677 | Nsdr 5.896[0m
[[36m09-12 04:06:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.11 it/sec | Loss 0.1596 | Reco 0.1596 | Nsdr 6.067[0m
[[36m09-12 04:06:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.12 it/sec | Loss 0.1596 | Reco 0.1596 | Nsdr 6.280[0m
[[36m09-12 04:07:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.13 it/sec | Loss 0.1585 | Reco 0.1585 | Nsdr 6.366[0m
[[36m09-12 04:08:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 12.1 sec/it | Loss 0.1672 | Reco 0.1672 | Nsdr 5.901[0m
[[36m09-12 04:08:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.11 it/sec | Loss 0.1595 | Reco 0.1595 | Nsdr 6.060[0m
[[36m09-12 04:08:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.12 it/sec | Loss 0.1598 | Reco 0.1598 | Nsdr 6.262[0m
[[36m09-12 04:08:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.13 it/sec | Loss 0.1589 | Reco 0.1589 | Nsdr 6.334[0m
[[36m09-12 04:09:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 11.9 sec/it | Loss 0.1682 | Reco 0.1682 | Nsdr 5.866[0m
[[36m09-12 04:10:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.11 it/sec | Loss 0.1599 | Reco 0.1599 | Nsdr 6.047[0m
[[36m09-12 04:10:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.12 it/sec | Loss 0.1600 | Reco 0.1600 | Nsdr 6.252[0m
[[36m09-12 04:10:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.13 it/sec | Loss 0.1591 | Reco 0.1591 | Nsdr 6.324[0m
[[36m09-12 04:10:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 11 | Loss=0.1597 | Reco=0.1597 | Nsdr=6.235 | Best=0.1597 | Bname=ema_batch_1 | Penalty=247.2812[0m
[[36m09-12 04:10:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1597[0m
[[36m09-12 04:11:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-12 04:11:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-12 05:01:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 12 | 1164/4656 | 0.39 it/sec | Loss 0.0953 | Reco 0.0928 | Grad 0.0917 | Penalty 242.7881[0m
[[36m09-12 05:51:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 12 | 2328/4656 | 0.39 it/sec | Loss 0.0958 | Reco 0.0933 | Grad 0.0900 | Penalty 243.0581[0m
[[36m09-12 06:41:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 12 | 3492/4656 | 0.39 it/sec | Loss 0.0962 | Reco 0.0938 | Grad 0.0904 | Penalty 242.3824[0m
[[36m09-12 07:29:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 12 | Loss=0.0961 | Reco=0.0937 | Grad=0.0906 | Penalty=242.2743[0m
[[36m09-12 07:29:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-12 07:29:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-12 07:30:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 12.0 sec/it | Loss 0.1786 | Reco 0.1786 | Nsdr 5.392[0m
[[36m09-12 07:30:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.11 it/sec | Loss 0.1666 | Reco 0.1666 | Nsdr 5.712[0m
[[36m09-12 07:30:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.12 it/sec | Loss 0.1672 | Reco 0.1672 | Nsdr 5.878[0m
[[36m09-12 07:31:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.13 it/sec | Loss 0.1662 | Reco 0.1662 | Nsdr 5.952[0m
[[36m09-12 07:32:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 12.2 sec/it | Loss 0.1684 | Reco 0.1684 | Nsdr 5.873[0m
[[36m09-12 07:32:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.11 it/sec | Loss 0.1595 | Reco 0.1595 | Nsdr 6.058[0m
[[36m09-12 07:32:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.12 it/sec | Loss 0.1596 | Reco 0.1596 | Nsdr 6.269[0m
[[36m09-12 07:33:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.13 it/sec | Loss 0.1584 | Reco 0.1584 | Nsdr 6.368[0m
[[36m09-12 07:34:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 12.6 sec/it | Loss 0.1674 | Reco 0.1674 | Nsdr 5.910[0m
[[36m09-12 07:34:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.11 it/sec | Loss 0.1592 | Reco 0.1592 | Nsdr 6.079[0m
[[36m09-12 07:34:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.12 it/sec | Loss 0.1591 | Reco 0.1591 | Nsdr 6.305[0m
[[36m09-12 07:34:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.13 it/sec | Loss 0.1580 | Reco 0.1580 | Nsdr 6.395[0m
[[36m09-12 07:35:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 12.1 sec/it | Loss 0.1673 | Reco 0.1673 | Nsdr 5.904[0m
[[36m09-12 07:36:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.11 it/sec | Loss 0.1592 | Reco 0.1592 | Nsdr 6.075[0m
[[36m09-12 07:36:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.12 it/sec | Loss 0.1595 | Reco 0.1595 | Nsdr 6.273[0m
[[36m09-12 07:36:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.13 it/sec | Loss 0.1587 | Reco 0.1587 | Nsdr 6.341[0m
[[36m09-12 07:37:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 12.1 sec/it | Loss 0.1673 | Reco 0.1673 | Nsdr 5.904[0m
[[36m09-12 07:38:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.11 it/sec | Loss 0.1595 | Reco 0.1595 | Nsdr 6.065[0m
[[36m09-12 07:38:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.12 it/sec | Loss 0.1597 | Reco 0.1597 | Nsdr 6.269[0m
[[36m09-12 07:38:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.13 it/sec | Loss 0.1589 | Reco 0.1589 | Nsdr 6.336[0m
[[36m09-12 07:38:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 12 | Loss=0.1592 | Reco=0.1592 | Nsdr=6.265 | Best=0.1592 | Bname=ema_batch_1 | Penalty=247.8131[0m
[[36m09-12 07:38:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1592[0m
[[36m09-12 07:38:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-12 07:38:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-12 08:27:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 13 | 1164/4656 | 0.40 it/sec | Loss 73.7359 | Reco 73.7014 | Grad 12687.6877 | Penalty 3455.6477[0m
[[36m09-12 09:17:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 13 | 2328/4656 | 0.40 it/sec | Loss 37.0355 | Reco 36.9912 | Grad 6362.3569 | Penalty 4429.8729[0m
[[36m09-12 10:07:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 13 | 3492/4656 | 0.39 it/sec | Loss 24.7962 | Reco 24.7497 | Grad 4246.4831 | Penalty 4655.0999[0m
[[36m09-12 10:57:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 13 | Loss=21.7224 | Reco=21.6750 | Grad=3303.7188 | Penalty=4739.2856[0m
[[36m09-12 10:57:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-12 10:57:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-12 10:58:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 14.0 sec/it | Loss 0.2875 | Reco 0.2875 | Nsdr 1.154[0m
[[36m09-12 10:58:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 6/14 | 10.2 sec/it | Loss 0.2732 | Reco 0.2732 | Nsdr 1.273[0m
[[36m09-12 10:59:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 9/14 | 0.11 it/sec | Loss 0.2812 | Reco 0.2812 | Nsdr 1.305[0m
[[36m09-12 10:59:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 12/14 | 0.12 it/sec | Loss 0.2836 | Reco 0.2836 | Nsdr 1.279[0m
[[36m09-12 11:00:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 14.5 sec/it | Loss 0.2960 | Reco 0.2960 | Nsdr 0.910[0m
[[36m09-12 11:00:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 6/14 | 10.5 sec/it | Loss 0.2884 | Reco 0.2884 | Nsdr 0.886[0m
[[36m09-12 11:01:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 9/14 | 0.11 it/sec | Loss 0.2972 | Reco 0.2972 | Nsdr 0.914[0m
[[36m09-12 11:01:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 12/14 | 0.12 it/sec | Loss 0.2993 | Reco 0.2993 | Nsdr 0.915[0m
[[36m09-12 11:02:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 14.0 sec/it | Loss 0.2673 | Reco 0.2673 | Nsdr 2.011[0m
[[36m09-12 11:02:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 6/14 | 10.4 sec/it | Loss 0.2586 | Reco 0.2586 | Nsdr 2.012[0m
[[36m09-12 11:03:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 9/14 | 0.11 it/sec | Loss 0.2625 | Reco 0.2625 | Nsdr 2.173[0m
[[36m09-12 11:03:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 12/14 | 0.12 it/sec | Loss 0.2619 | Reco 0.2619 | Nsdr 2.224[0m
[[36m09-12 11:04:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 14.4 sec/it | Loss 0.1963 | Reco 0.1963 | Nsdr 4.691[0m
[[36m09-12 11:04:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 6/14 | 10.5 sec/it | Loss 0.1876 | Reco 0.1876 | Nsdr 4.833[0m
[[36m09-12 11:05:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 9/14 | 0.11 it/sec | Loss 0.1895 | Reco 0.1895 | Nsdr 4.965[0m
[[36m09-12 11:05:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 12/14 | 0.12 it/sec | Loss 0.1893 | Reco 0.1893 | Nsdr 5.007[0m
[[36m09-12 11:06:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 14.2 sec/it | Loss 0.1850 | Reco 0.1850 | Nsdr 5.125[0m
[[36m09-12 11:06:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 6/14 | 10.4 sec/it | Loss 0.1763 | Reco 0.1763 | Nsdr 5.302[0m
[[36m09-12 11:07:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 9/14 | 0.11 it/sec | Loss 0.1781 | Reco 0.1781 | Nsdr 5.426[0m
[[36m09-12 11:07:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 12/14 | 0.12 it/sec | Loss 0.1779 | Reco 0.1779 | Nsdr 5.472[0m
[[36m09-12 11:07:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 13 | Loss=0.1786 | Reco=0.1786 | Nsdr=5.384 | Best=0.1592 | Bname=ema_epoch_1 | Penalty=5015.7695[0m
[[36m09-12 11:07:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-12 11:07:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-12 11:58:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 14 | 1164/4656 | 0.39 it/sec | Loss 0.2534 | Reco 0.2043 | Grad 0.3675 | Penalty 4907.9432[0m
[[36m09-12 12:48:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 14 | 2328/4656 | 0.39 it/sec | Loss 0.2510 | Reco 0.2029 | Grad 2.6710 | Penalty 4809.3054[0m
[[36m09-12 13:37:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 14 | 3492/4656 | 0.39 it/sec | Loss 0.2480 | Reco 0.2008 | Grad 1.8856 | Penalty 4720.0155[0m
[[36m09-12 14:25:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 14 | Loss=0.2453 | Reco=0.1990 | Grad=1.5446 | Penalty=4637.9736[0m
[[36m09-12 14:25:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-12 14:25:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-12 14:26:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 3/14 | 12.3 sec/it | Loss 0.2738 | Reco 0.2738 | Nsdr 1.708[0m
[[36m09-12 14:26:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 6/14 | 0.11 it/sec | Loss 0.2633 | Reco 0.2633 | Nsdr 1.791[0m
[[36m09-12 14:26:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 9/14 | 0.12 it/sec | Loss 0.2688 | Reco 0.2688 | Nsdr 1.879[0m
[[36m09-12 14:26:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 12/14 | 0.13 it/sec | Loss 0.2704 | Reco 0.2704 | Nsdr 1.851[0m
[[36m09-12 14:27:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 3/14 | 12.3 sec/it | Loss 0.2802 | Reco 0.2802 | Nsdr 1.384[0m
[[36m09-12 14:28:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 6/14 | 0.11 it/sec | Loss 0.2655 | Reco 0.2655 | Nsdr 1.539[0m
[[36m09-12 14:28:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 9/14 | 0.12 it/sec | Loss 0.2725 | Reco 0.2725 | Nsdr 1.596[0m
[[36m09-12 14:28:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 12/14 | 0.13 it/sec | Loss 0.2750 | Reco 0.2750 | Nsdr 1.562[0m
[[36m09-12 14:29:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 3/14 | 12.1 sec/it | Loss 0.2977 | Reco 0.2977 | Nsdr 0.960[0m
[[36m09-12 14:30:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 6/14 | 0.11 it/sec | Loss 0.2946 | Reco 0.2946 | Nsdr 0.836[0m
[[36m09-12 14:30:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 9/14 | 0.12 it/sec | Loss 0.3022 | Reco 0.3022 | Nsdr 0.906[0m
[[36m09-12 14:30:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 12/14 | 0.13 it/sec | Loss 0.3024 | Reco 0.3024 | Nsdr 0.935[0m
[[36m09-12 14:31:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 3/14 | 12.2 sec/it | Loss 0.2412 | Reco 0.2412 | Nsdr 3.027[0m
[[36m09-12 14:31:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 6/14 | 0.11 it/sec | Loss 0.2344 | Reco 0.2344 | Nsdr 2.993[0m
[[36m09-12 14:32:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 9/14 | 0.12 it/sec | Loss 0.2363 | Reco 0.2363 | Nsdr 3.171[0m
[[36m09-12 14:32:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 12/14 | 0.13 it/sec | Loss 0.2363 | Reco 0.2363 | Nsdr 3.201[0m
[[36m09-12 14:33:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 3/14 | 12.1 sec/it | Loss 0.2209 | Reco 0.2209 | Nsdr 3.788[0m
[[36m09-12 14:33:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 6/14 | 0.11 it/sec | Loss 0.2126 | Reco 0.2126 | Nsdr 3.857[0m
[[36m09-12 14:34:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 9/14 | 0.12 it/sec | Loss 0.2142 | Reco 0.2142 | Nsdr 4.015[0m
[[36m09-12 14:34:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 12/14 | 0.13 it/sec | Loss 0.2141 | Reco 0.2141 | Nsdr 4.052[0m
[[36m09-12 14:34:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 14 | Loss=0.2146 | Reco=0.2146 | Nsdr=3.987 | Best=0.1592 | Bname=ema_epoch_1 | Penalty=4322.6235[0m
[[36m09-12 14:34:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-12 14:34:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-12 15:23:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 15 | 1164/4656 | 0.39 it/sec | Loss 0.2363 | Reco 0.1937 | Grad 0.4596 | Penalty 4258.0733[0m
[[36m09-12 16:12:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 15 | 2328/4656 | 0.40 it/sec | Loss 0.2340 | Reco 0.1920 | Grad 0.3723 | Penalty 4197.8522[0m
[[36m09-12 17:00:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 15 | 3492/4656 | 0.40 it/sec | Loss 0.2322 | Reco 0.1908 | Grad 0.3447 | Penalty 4141.3523[0m
[[36m09-12 17:48:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 15 | Loss=0.2311 | Reco=0.1902 | Grad=0.3318 | Penalty=4088.2188[0m
[[36m09-12 17:48:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-12 17:48:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-12 17:49:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 3/14 | 12.5 sec/it | Loss 0.2719 | Reco 0.2719 | Nsdr 1.747[0m
[[36m09-12 17:49:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 6/14 | 0.11 it/sec | Loss 0.2565 | Reco 0.2565 | Nsdr 1.969[0m
[[36m09-12 17:49:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 9/14 | 0.12 it/sec | Loss 0.2622 | Reco 0.2622 | Nsdr 2.049[0m
[[36m09-12 17:50:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 12/14 | 0.13 it/sec | Loss 0.2645 | Reco 0.2645 | Nsdr 2.002[0m
[[36m09-12 17:51:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 3/14 | 12.5 sec/it | Loss 0.2721 | Reco 0.2721 | Nsdr 1.731[0m
[[36m09-12 17:51:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 6/14 | 0.11 it/sec | Loss 0.2572 | Reco 0.2572 | Nsdr 1.942[0m
[[36m09-12 17:51:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 9/14 | 0.12 it/sec | Loss 0.2631 | Reco 0.2631 | Nsdr 2.011[0m
[[36m09-12 17:52:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 12/14 | 0.13 it/sec | Loss 0.2654 | Reco 0.2654 | Nsdr 1.968[0m
[[36m09-12 17:53:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 3/14 | 12.3 sec/it | Loss 0.2985 | Reco 0.2985 | Nsdr 0.920[0m
[[36m09-12 17:53:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 6/14 | 0.11 it/sec | Loss 0.2929 | Reco 0.2929 | Nsdr 0.851[0m
[[36m09-12 17:53:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 9/14 | 0.12 it/sec | Loss 0.3016 | Reco 0.3016 | Nsdr 0.880[0m
[[36m09-12 17:53:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 12/14 | 0.13 it/sec | Loss 0.3028 | Reco 0.3028 | Nsdr 0.896[0m
[[36m09-12 17:54:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 3/14 | 12.3 sec/it | Loss 0.2668 | Reco 0.2668 | Nsdr 2.034[0m
[[36m09-12 17:55:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 6/14 | 0.11 it/sec | Loss 0.2611 | Reco 0.2611 | Nsdr 1.942[0m
[[36m09-12 17:55:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 9/14 | 0.12 it/sec | Loss 0.2657 | Reco 0.2657 | Nsdr 2.083[0m
[[36m09-12 17:55:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 12/14 | 0.13 it/sec | Loss 0.2656 | Reco 0.2656 | Nsdr 2.113[0m
[[36m09-12 17:56:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 3/14 | 12.2 sec/it | Loss 0.2479 | Reco 0.2479 | Nsdr 2.773[0m
[[36m09-12 17:56:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 6/14 | 0.11 it/sec | Loss 0.2413 | Reco 0.2413 | Nsdr 2.722[0m
[[36m09-12 17:57:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 9/14 | 0.12 it/sec | Loss 0.2436 | Reco 0.2436 | Nsdr 2.900[0m
[[36m09-12 17:57:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 12/14 | 0.13 it/sec | Loss 0.2436 | Reco 0.2436 | Nsdr 2.929[0m
[[36m09-12 17:57:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 15 | Loss=0.2440 | Reco=0.2440 | Nsdr=2.882 | Best=0.1592 | Bname=ema_epoch_1 | Penalty=3881.7766[0m
[[36m09-12 17:57:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-12 17:57:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-12 18:46:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 16 | 1164/4656 | 0.40 it/sec | Loss 0.2265 | Reco 0.1881 | Grad 0.3013 | Penalty 3837.1783[0m
[[36m09-12 19:33:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 16 | 2328/4656 | 0.40 it/sec | Loss 0.2256 | Reco 0.1877 | Grad 0.3303 | Penalty 3796.4922[0m
[[36m09-12 20:22:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 16 | 3492/4656 | 0.40 it/sec | Loss 0.2246 | Reco 0.1870 | Grad 0.4147 | Penalty 3759.5219[0m
[[36m09-12 21:10:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 16 | Loss=0.2242 | Reco=0.1869 | Grad=0.3888 | Penalty=3723.8168[0m
[[36m09-12 21:10:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-12 21:10:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-12 21:11:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 3/14 | 11.8 sec/it | Loss 0.2673 | Reco 0.2673 | Nsdr 1.890[0m
[[36m09-12 21:11:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 6/14 | 0.11 it/sec | Loss 0.2531 | Reco 0.2531 | Nsdr 2.087[0m
[[36m09-12 21:11:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 9/14 | 0.12 it/sec | Loss 0.2592 | Reco 0.2592 | Nsdr 2.158[0m
[[36m09-12 21:12:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 12/14 | 0.13 it/sec | Loss 0.2616 | Reco 0.2616 | Nsdr 2.112[0m
[[36m09-12 21:13:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 3/14 | 11.9 sec/it | Loss 0.2686 | Reco 0.2686 | Nsdr 1.849[0m
[[36m09-12 21:13:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 6/14 | 0.11 it/sec | Loss 0.2539 | Reco 0.2539 | Nsdr 2.067[0m
[[36m09-12 21:13:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 9/14 | 0.12 it/sec | Loss 0.2597 | Reco 0.2597 | Nsdr 2.135[0m
[[36m09-12 21:13:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 12/14 | 0.13 it/sec | Loss 0.2619 | Reco 0.2619 | Nsdr 2.095[0m
[[36m09-12 21:14:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 3/14 | 12.0 sec/it | Loss 0.2901 | Reco 0.2901 | Nsdr 1.185[0m
[[36m09-12 21:15:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 6/14 | 0.11 it/sec | Loss 0.2833 | Reco 0.2833 | Nsdr 1.148[0m
[[36m09-12 21:15:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 9/14 | 0.12 it/sec | Loss 0.2916 | Reco 0.2916 | Nsdr 1.177[0m
[[36m09-12 21:15:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 12/14 | 0.13 it/sec | Loss 0.2928 | Reco 0.2928 | Nsdr 1.185[0m
[[36m09-12 21:16:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 3/14 | 11.6 sec/it | Loss 0.2798 | Reco 0.2798 | Nsdr 1.578[0m
[[36m09-12 21:16:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 6/14 | 0.11 it/sec | Loss 0.2753 | Reco 0.2753 | Nsdr 1.465[0m
[[36m09-12 21:17:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 9/14 | 0.12 it/sec | Loss 0.2810 | Reco 0.2810 | Nsdr 1.572[0m
[[36m09-12 21:17:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 12/14 | 0.13 it/sec | Loss 0.2813 | Reco 0.2813 | Nsdr 1.585[0m
[[36m09-12 21:18:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 3/14 | 11.7 sec/it | Loss 0.2650 | Reco 0.2650 | Nsdr 2.111[0m
[[36m09-12 21:18:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 6/14 | 0.11 it/sec | Loss 0.2593 | Reco 0.2593 | Nsdr 2.022[0m
[[36m09-12 21:19:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 9/14 | 0.12 it/sec | Loss 0.2635 | Reco 0.2635 | Nsdr 2.168[0m
[[36m09-12 21:19:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 12/14 | 0.13 it/sec | Loss 0.2634 | Reco 0.2634 | Nsdr 2.198[0m
[[36m09-12 21:19:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 16 | Loss=0.2608 | Reco=0.2608 | Nsdr=2.087 | Best=0.1592 | Bname=main | Penalty=3582.9067[0m
[[36m09-12 21:19:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-12 21:19:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-12 22:08:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 17 | 1164/4656 | 0.40 it/sec | Loss 0.2440 | Reco 0.2085 | Grad 2.8410 | Penalty 3551.4904[0m
[[36m09-12 22:57:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 17 | 2328/4656 | 0.40 it/sec | Loss 0.2319 | Reco 0.1967 | Grad 1.5778 | Penalty 3518.9552[0m
[[36m09-12 23:48:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 17 | 3492/4656 | 0.39 it/sec | Loss 0.2271 | Reco 0.1922 | Grad 1.1536 | Penalty 3486.1923[0m
[[36m09-13 00:37:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 17 | Loss=0.2243 | Reco=0.1898 | Grad=0.9409 | Penalty=3453.8124[0m
[[36m09-13 00:37:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-13 00:37:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-13 00:38:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 3/14 | 14.3 sec/it | Loss 0.2697 | Reco 0.2697 | Nsdr 1.864[0m
[[36m09-13 00:38:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 6/14 | 10.3 sec/it | Loss 0.2535 | Reco 0.2535 | Nsdr 2.116[0m
[[36m09-13 00:39:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 9/14 | 0.11 it/sec | Loss 0.2577 | Reco 0.2577 | Nsdr 2.227[0m
[[36m09-13 00:39:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 12/14 | 0.12 it/sec | Loss 0.2598 | Reco 0.2598 | Nsdr 2.190[0m
[[36m09-13 00:40:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 3/14 | 11.7 sec/it | Loss 0.2666 | Reco 0.2666 | Nsdr 1.928[0m
[[36m09-13 00:40:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 6/14 | 0.11 it/sec | Loss 0.2520 | Reco 0.2520 | Nsdr 2.144[0m
[[36m09-13 00:40:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 9/14 | 0.12 it/sec | Loss 0.2571 | Reco 0.2571 | Nsdr 2.228[0m
[[36m09-13 00:41:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 12/14 | 0.13 it/sec | Loss 0.2594 | Reco 0.2594 | Nsdr 2.190[0m
[[36m09-13 00:42:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 3/14 | 11.8 sec/it | Loss 0.2811 | Reco 0.2811 | Nsdr 1.475[0m
[[36m09-13 00:42:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 6/14 | 0.11 it/sec | Loss 0.2721 | Reco 0.2721 | Nsdr 1.500[0m
[[36m09-13 00:42:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 9/14 | 0.12 it/sec | Loss 0.2797 | Reco 0.2797 | Nsdr 1.538[0m
[[36m09-13 00:43:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 12/14 | 0.13 it/sec | Loss 0.2810 | Reco 0.2810 | Nsdr 1.535[0m
[[36m09-13 00:43:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 3/14 | 11.9 sec/it | Loss 0.2892 | Reco 0.2892 | Nsdr 1.279[0m
[[36m09-13 00:44:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 6/14 | 0.11 it/sec | Loss 0.2862 | Reco 0.2862 | Nsdr 1.143[0m
[[36m09-13 00:44:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 9/14 | 0.12 it/sec | Loss 0.2925 | Reco 0.2925 | Nsdr 1.233[0m
[[36m09-13 00:44:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 12/14 | 0.13 it/sec | Loss 0.2926 | Reco 0.2926 | Nsdr 1.253[0m
[[36m09-13 00:45:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 3/14 | 11.6 sec/it | Loss 0.2753 | Reco 0.2753 | Nsdr 1.739[0m
[[36m09-13 00:46:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 6/14 | 0.11 it/sec | Loss 0.2703 | Reco 0.2703 | Nsdr 1.634[0m
[[36m09-13 00:46:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 9/14 | 0.12 it/sec | Loss 0.2757 | Reco 0.2757 | Nsdr 1.753[0m
[[36m09-13 00:46:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 12/14 | 0.13 it/sec | Loss 0.2758 | Reco 0.2758 | Nsdr 1.769[0m
[[36m09-13 00:46:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 17 | Loss=0.2587 | Reco=0.2587 | Nsdr=2.157 | Best=0.1592 | Bname=ema_batch_0 | Penalty=3325.1650[0m
[[36m09-13 00:46:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-13 00:46:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-13 01:35:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 18 | 1164/4656 | 0.40 it/sec | Loss 0.2146 | Reco 0.1817 | Grad 0.3443 | Penalty 3293.5626[0m
[[36m09-13 02:23:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 18 | 2328/4656 | 0.40 it/sec | Loss 0.2147 | Reco 0.1821 | Grad 0.3265 | Penalty 3262.4761[0m
[[36m09-13 03:13:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 18 | 3492/4656 | 0.40 it/sec | Loss 0.2515 | Reco 0.2172 | Grad 21.5848 | Penalty 3423.3944[0m
[[36m09-13 04:04:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 18 | Loss=0.2538 | Reco=0.2192 | Grad=16.2084 | Penalty=3461.5649[0m
[[36m09-13 04:04:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-13 04:04:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-13 04:05:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 3/14 | 15.1 sec/it | Loss 0.2995 | Reco 0.2995 | Nsdr 0.340[0m
[[36m09-13 04:05:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 6/14 | 10.9 sec/it | Loss 0.2929 | Reco 0.2929 | Nsdr 0.484[0m
[[36m09-13 04:05:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 9/14 | 0.10 it/sec | Loss 0.3026 | Reco 0.3026 | Nsdr 0.323[0m
[[36m09-13 04:06:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 12/14 | 0.11 it/sec | Loss 0.3062 | Reco 0.3062 | Nsdr 0.322[0m
[[36m09-13 04:07:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 3/14 | 14.1 sec/it | Loss 6.2534 | Reco 6.2534 | Nsdr -18.410[0m
[[36m09-13 04:07:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 6/14 | 10.3 sec/it | Loss 6.1877 | Reco 6.1877 | Nsdr -18.488[0m
[[36m09-13 04:07:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 9/14 | 0.11 it/sec | Loss 6.1639 | Reco 6.1639 | Nsdr -18.320[0m
[[36m09-13 04:08:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 12/14 | 0.12 it/sec | Loss 6.0458 | Reco 6.0458 | Nsdr -18.251[0m
[[36m09-13 04:09:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 3/14 | 13.9 sec/it | Loss 0.2923 | Reco 0.2923 | Nsdr 0.908[0m
[[36m09-13 04:09:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 6/14 | 10.2 sec/it | Loss 0.2756 | Reco 0.2756 | Nsdr 1.153[0m
[[36m09-13 04:09:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 9/14 | 0.11 it/sec | Loss 0.2844 | Reco 0.2844 | Nsdr 1.170[0m
[[36m09-13 04:10:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 12/14 | 0.12 it/sec | Loss 0.2889 | Reco 0.2889 | Nsdr 1.101[0m
[[36m09-13 04:11:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 3/14 | 14.4 sec/it | Loss 0.2916 | Reco 0.2916 | Nsdr 1.065[0m
[[36m09-13 04:11:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 6/14 | 10.5 sec/it | Loss 0.2893 | Reco 0.2893 | Nsdr 0.929[0m
[[36m09-13 04:11:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 9/14 | 0.10 it/sec | Loss 0.2975 | Reco 0.2975 | Nsdr 0.978[0m
[[36m09-13 04:12:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 12/14 | 0.11 it/sec | Loss 0.2983 | Reco 0.2983 | Nsdr 1.000[0m
[[36m09-13 04:13:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 3/14 | 14.8 sec/it | Loss 0.2809 | Reco 0.2809 | Nsdr 1.458[0m
[[36m09-13 04:13:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 6/14 | 10.7 sec/it | Loss 0.2774 | Reco 0.2774 | Nsdr 1.335[0m
[[36m09-13 04:14:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 9/14 | 0.10 it/sec | Loss 0.2838 | Reco 0.2838 | Nsdr 1.425[0m
[[36m09-13 04:14:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 12/14 | 0.11 it/sec | Loss 0.2848 | Reco 0.2848 | Nsdr 1.428[0m
[[36m09-13 04:14:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 18 | Loss=0.2856 | Reco=0.2856 | Nsdr=1.393 | Best=0.1592 | Bname=ema_epoch_1 | Penalty=3495.1428[0m
[[36m09-13 04:14:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-13 04:14:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-13 05:05:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 19 | 1164/4656 | 0.38 it/sec | Loss 0.2594 | Reco 0.2250 | Grad 0.0619 | Penalty 3432.6960[0m
[[36m09-13 05:52:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 19 | 2328/4656 | 0.40 it/sec | Loss 0.2577 | Reco 0.2240 | Grad 0.0625 | Penalty 3379.2483[0m
[[36m09-13 06:39:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 19 | 3492/4656 | 0.40 it/sec | Loss 0.2568 | Reco 0.2235 | Grad 0.0634 | Penalty 3331.1961[0m
[[36m09-13 07:26:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 19 | Loss=0.2566 | Reco=0.2237 | Grad=0.0643 | Penalty=3287.4950[0m
[[36m09-13 07:26:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-13 07:26:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-13 07:27:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 3/14 | 11.9 sec/it | Loss 0.2985 | Reco 0.2985 | Nsdr 0.751[0m
[[36m09-13 07:27:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 6/14 | 0.11 it/sec | Loss 0.2905 | Reco 0.2905 | Nsdr 0.764[0m
[[36m09-13 07:27:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 9/14 | 0.12 it/sec | Loss 0.2999 | Reco 0.2999 | Nsdr 0.783[0m
[[36m09-13 07:28:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 12/14 | 0.13 it/sec | Loss 0.3040 | Reco 0.3040 | Nsdr 0.747[0m
[[36m09-13 07:29:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 3/14 | 12.5 sec/it | Loss 0.2974 | Reco 0.2974 | Nsdr 0.758[0m
[[36m09-13 07:29:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 6/14 | 0.11 it/sec | Loss 0.2908 | Reco 0.2908 | Nsdr 0.747[0m
[[36m09-13 07:29:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 9/14 | 0.12 it/sec | Loss 0.3006 | Reco 0.3006 | Nsdr 0.763[0m
[[36m09-13 07:29:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 12/14 | 0.13 it/sec | Loss 0.3044 | Reco 0.3044 | Nsdr 0.737[0m
[[36m09-13 07:30:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 3/14 | 11.6 sec/it | Loss 0.3288 | Reco 0.3288 | Nsdr -0.010[0m
[[36m09-13 07:31:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 6/14 | 0.11 it/sec | Loss 0.3266 | Reco 0.3266 | Nsdr -0.268[0m
[[36m09-13 07:31:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 9/14 | 0.12 it/sec | Loss 0.3365 | Reco 0.3365 | Nsdr -0.227[0m
[[36m09-13 07:31:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 12/14 | 0.13 it/sec | Loss 0.3392 | Reco 0.3392 | Nsdr -0.212[0m
[[36m09-13 07:32:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 3/14 | 11.5 sec/it | Loss 0.2940 | Reco 0.2940 | Nsdr 0.904[0m
[[36m09-13 07:32:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 6/14 | 0.12 it/sec | Loss 0.2903 | Reco 0.2903 | Nsdr 0.811[0m
[[36m09-13 07:33:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 9/14 | 0.12 it/sec | Loss 0.2995 | Reco 0.2995 | Nsdr 0.834[0m
[[36m09-13 07:33:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 12/14 | 0.13 it/sec | Loss 0.3015 | Reco 0.3015 | Nsdr 0.848[0m
[[36m09-13 07:34:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 3/14 | 11.8 sec/it | Loss 0.2866 | Reco 0.2866 | Nsdr 1.185[0m
[[36m09-13 07:34:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 6/14 | 0.11 it/sec | Loss 0.2843 | Reco 0.2843 | Nsdr 1.045[0m
[[36m09-13 07:34:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 9/14 | 0.12 it/sec | Loss 0.2923 | Reco 0.2923 | Nsdr 1.099[0m
[[36m09-13 07:35:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 12/14 | 0.13 it/sec | Loss 0.2940 | Reco 0.2940 | Nsdr 1.101[0m
[[36m09-13 07:35:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 19 | Loss=0.2951 | Reco=0.2951 | Nsdr=1.067 | Best=0.1592 | Bname=ema_epoch_1 | Penalty=3120.0105[0m
[[36m09-13 07:35:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-13 07:35:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-13 08:23:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 20 | 1164/4656 | 0.41 it/sec | Loss 0.2541 | Reco 0.2232 | Grad 0.0672 | Penalty 3086.5472[0m
[[36m09-13 09:10:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 20 | 2328/4656 | 0.41 it/sec | Loss 0.2541 | Reco 0.2235 | Grad 0.0711 | Penalty 3054.6351[0m
[[36m09-13 09:58:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 20 | 3492/4656 | 0.41 it/sec | Loss 0.2532 | Reco 0.2230 | Grad 0.0702 | Penalty 3023.7807[0m
[[36m09-13 10:46:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 20 | Loss=0.2526 | Reco=0.2227 | Grad=0.0705 | Penalty=2993.6661[0m
[[36m09-13 10:46:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-13 10:46:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-13 10:47:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 3/14 | 12.3 sec/it | Loss 0.2976 | Reco 0.2976 | Nsdr 0.775[0m
[[36m09-13 10:47:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 6/14 | 0.11 it/sec | Loss 0.2896 | Reco 0.2896 | Nsdr 0.788[0m
[[36m09-13 10:48:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 9/14 | 0.12 it/sec | Loss 0.2993 | Reco 0.2993 | Nsdr 0.802[0m
[[36m09-13 10:48:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 12/14 | 0.13 it/sec | Loss 0.3034 | Reco 0.3034 | Nsdr 0.764[0m
[[36m09-13 10:49:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 3/14 | 12.3 sec/it | Loss 0.2975 | Reco 0.2975 | Nsdr 0.785[0m
[[36m09-13 10:49:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 6/14 | 0.11 it/sec | Loss 0.2897 | Reco 0.2897 | Nsdr 0.793[0m
[[36m09-13 10:50:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 9/14 | 0.12 it/sec | Loss 0.2994 | Reco 0.2994 | Nsdr 0.806[0m
[[36m09-13 10:50:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 12/14 | 0.13 it/sec | Loss 0.3034 | Reco 0.3034 | Nsdr 0.770[0m
[[36m09-13 10:51:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 3/14 | 12.4 sec/it | Loss 0.3860 | Reco 0.3860 | Nsdr -3.092[0m
[[36m09-13 10:51:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 6/14 | 0.11 it/sec | Loss 0.3710 | Reco 0.3710 | Nsdr -2.915[0m
[[36m09-13 10:52:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 9/14 | 0.12 it/sec | Loss 0.3815 | Reco 0.3815 | Nsdr -2.939[0m
[[36m09-13 10:52:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 12/14 | 0.13 it/sec | Loss 0.3953 | Reco 0.3953 | Nsdr -3.289[0m
[[36m09-13 10:53:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 3/14 | 12.7 sec/it | Loss 0.2963 | Reco 0.2963 | Nsdr 0.795[0m
[[36m09-13 10:53:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 6/14 | 0.11 it/sec | Loss 0.2907 | Reco 0.2907 | Nsdr 0.750[0m
[[36m09-13 10:53:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 9/14 | 0.12 it/sec | Loss 0.3005 | Reco 0.3005 | Nsdr 0.761[0m
[[36m09-13 10:54:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 12/14 | 0.13 it/sec | Loss 0.3033 | Reco 0.3033 | Nsdr 0.763[0m
[[36m09-13 10:55:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 3/14 | 12.2 sec/it | Loss 0.2918 | Reco 0.2918 | Nsdr 0.972[0m
[[36m09-13 10:55:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 6/14 | 0.11 it/sec | Loss 0.2896 | Reco 0.2896 | Nsdr 0.839[0m
[[36m09-13 10:55:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 9/14 | 0.12 it/sec | Loss 0.2987 | Reco 0.2987 | Nsdr 0.869[0m
[[36m09-13 10:56:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 12/14 | 0.13 it/sec | Loss 0.3007 | Reco 0.3007 | Nsdr 0.877[0m
[[36m09-13 10:56:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 20 | Loss=0.3018 | Reco=0.3018 | Nsdr=0.850 | Best=0.1592 | Bname=ema_epoch_1 | Penalty=2874.7092[0m
[[36m09-13 10:56:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-13 10:56:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Evaluating on the test set...[0m
[[36m09-13 10:56:55[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval | 2/10 | 14.2 sec/it[0m
[[36m09-13 10:57:25[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval | 4/10 | 14.5 sec/it[0m
[[36m09-13 10:58:00[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval | 6/10 | 15.3 sec/it[0m
[[36m09-13 10:58:34[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval | 8/10 | 15.7 sec/it[0m
[[36m09-13 11:13:14[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval (BSS) | 2/10 | 288.4 sec/it[0m
[[36m09-13 11:20:52[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval (BSS) | 4/10 | 264.6 sec/it[0m
[[36m09-13 11:29:50[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval (BSS) | 6/10 | 265.9 sec/it[0m
[[36m09-13 11:39:30[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval (BSS) | 8/10 | 271.3 sec/it[0m
[[36m09-13 11:41:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTest Summary | Epoch 20 | Sdr=4.731 | Nsdr=5.182 | Sdr_drums=6.631 | Nsdr_drums=6.545 | Sdr_bass=3.877 | Nsdr_bass=4.323 | Sdr_other=2.541 | Nsdr_other=3.161 | Sdr_vocals=5.875 | Nsdr_vocals=6.700[0m
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mParser[0m Injecting argv ['hdemucs.norm_starts=999', 'hdemucs.cac=False', 'test.split=True', 'valid_apply=True', 'model=hdemucs', 'hdemucs.dconv_lstm=4', 'ema.epoch=[0.9, 0.95]', 'ema.batch=[0.9995, 0.9999]', 'seed=42', 'hdemucs.hybrid_old=True', 'svd=base', 'svd.penalty=1e-05', 'svd.dim=100', 'svd.convtr=True', 'optim.lr=0.0005', 'batch_size=4', 'dset.segment=8', 'hdemucs.channels=24', 'test.workers=', 'continue_from=22d99e8f', 'epochs=20'] from sig a68eaf9b
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mExecutor:[0m Starting 1 worker processes for DDP.
[1mExecutor:[0m All workers completed successfully
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:228: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  return hydra.main(
[[36m09-20 14:16:25[0m][[34mdemucs.train[0m][[32mINFO[0m] - For logs, checkpoints and samples check /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/7cffc5b6[0m
[[36m09-20 14:16:25[0m][[34mdora.distrib[0m][[32mINFO[0m] - world_size is 1, skipping init.[0m
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
/home/paperspace/.local/lib/python3.8/site-packages/musdb/configs/mus.yaml
[[36m09-20 14:16:33[0m][[34mdemucs.train[0m][[32mINFO[0m] - train/valid set size: 18626 14[0m
[[36m09-20 14:16:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Loading from /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/538354000000.0/checkpoint.th[0m
/home/paperspace/.local/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
/home/paperspace/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Error executing job with overrides: ['hdemucs.norm_starts=999', 'hdemucs.cac=False', 'test.split=True', 'valid_apply=True', 'model=hdemucs', 'hdemucs.dconv_lstm=4', 'ema.epoch=[0.9, 0.95]', 'ema.batch=[0.9995, 0.9999]', 'seed=42', 'hdemucs.hybrid_old=True', 'svd=base', 'svd.penalty=1e-05', 'svd.dim=100', 'svd.convtr=True', 'optim.lr=0.0005', 'batch_size=4', 'dset.segment=8', 'hdemucs.channels=24', 'test.workers=', 'continue_from=a68eaf9b', 'epochs=20', 'continue_from=538354e6', 'epochs=20', 'optim.lr=1.5e-4']
Traceback (most recent call last):
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/train.py", line 148, in main
    solver = get_solver(args)
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/train.py", line 110, in get_solver
    return Solver(loaders, model, optimizer, args)
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/solver.py", line 75, in __init__
    self._reset()
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/solver.py", line 125, in _reset
    package = torch.load(cf, 'cpu')
  File "/home/paperspace/.local/lib/python3.8/site-packages/torch/serialization.py", line 594, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/paperspace/.local/lib/python3.8/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/paperspace/.local/lib/python3.8/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/538354000000.0/checkpoint.th'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mParser[0m Injecting argv ['hdemucs.norm_starts=999', 'hdemucs.cac=False', 'test.split=True', 'valid_apply=True', 'model=hdemucs', 'hdemucs.dconv_lstm=4', 'ema.epoch=[0.9, 0.95]', 'ema.batch=[0.9995, 0.9999]', 'seed=42', 'hdemucs.hybrid_old=True', 'svd=base', 'svd.penalty=1e-05', 'svd.dim=100', 'svd.convtr=True', 'optim.lr=0.0005', 'batch_size=4', 'dset.segment=8', 'hdemucs.channels=24', 'test.workers=', 'continue_from=a68eaf9b', 'epochs=20'] from sig 538354e6
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mExecutor:[0m Starting 1 worker processes for DDP.
[1mExecutor:[0m Worker 0 died, killing all workers
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:228: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  return hydra.main(
[[36m09-20 14:26:11[0m][[34mdemucs.train[0m][[32mINFO[0m] - For logs, checkpoints and samples check /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/5e8ce54e[0m
[[36m09-20 14:26:12[0m][[34mdora.distrib[0m][[32mINFO[0m] - world_size is 1, skipping init.[0m
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
/home/paperspace/.local/lib/python3.8/site-packages/musdb/configs/mus.yaml
[[36m09-20 14:26:15[0m][[34mdemucs.train[0m][[32mINFO[0m] - train/valid set size: 18626 14[0m
[[36m09-20 14:26:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Loading from /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/538354000000.0/checkpoint.th[0m
/home/paperspace/.local/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
/home/paperspace/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Error executing job with overrides: ['hdemucs.norm_starts=999', 'hdemucs.cac=False', 'test.split=True', 'valid_apply=True', 'model=hdemucs', 'hdemucs.dconv_lstm=4', 'ema.epoch=[0.9, 0.95]', 'ema.batch=[0.9995, 0.9999]', 'seed=42', 'hdemucs.hybrid_old=True', 'svd=base', 'svd.penalty=1e-05', 'svd.dim=100', 'svd.convtr=True', 'optim.lr=0.0005', 'batch_size=4', 'dset.segment=8', 'hdemucs.channels=24', 'test.workers=', 'continue_from=a68eaf9b', 'epochs=20', 'continue_from=538354e6', 'epochs=20', 'optim.lr=0.00025']
Traceback (most recent call last):
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/train.py", line 148, in main
    solver = get_solver(args)
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/train.py", line 110, in get_solver
    return Solver(loaders, model, optimizer, args)
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/solver.py", line 75, in __init__
    self._reset()
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/solver.py", line 125, in _reset
    package = torch.load(cf, 'cpu')
  File "/home/paperspace/.local/lib/python3.8/site-packages/torch/serialization.py", line 594, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/paperspace/.local/lib/python3.8/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/paperspace/.local/lib/python3.8/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/538354000000.0/checkpoint.th'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mParser[0m Injecting argv ['hdemucs.norm_starts=999', 'hdemucs.cac=False', 'test.split=True', 'valid_apply=True', 'model=hdemucs', 'hdemucs.dconv_lstm=4', 'ema.epoch=[0.9, 0.95]', 'ema.batch=[0.9995, 0.9999]', 'seed=42', 'hdemucs.hybrid_old=True', 'svd=base', 'svd.penalty=1e-05', 'svd.dim=100', 'svd.convtr=True', 'optim.lr=0.0005', 'batch_size=4', 'dset.segment=8', 'hdemucs.channels=24', 'test.workers=', 'continue_from=a68eaf9b', 'epochs=20'] from sig 538354e6
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mExecutor:[0m Starting 1 worker processes for DDP.
[1mExecutor:[0m Worker 0 died, killing all workers
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:228: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  return hydra.main(
[[36m09-20 14:31:43[0m][[34mdemucs.train[0m][[32mINFO[0m] - For logs, checkpoints and samples check /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/5e8ce54e[0m
[[36m09-20 14:31:43[0m][[34mdora.distrib[0m][[32mINFO[0m] - world_size is 1, skipping init.[0m
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
/home/paperspace/.local/lib/python3.8/site-packages/musdb/configs/mus.yaml
[[36m09-20 14:31:47[0m][[34mdemucs.train[0m][[32mINFO[0m] - train/valid set size: 18626 14[0m
[[36m09-20 14:31:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Loading from /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/538354000000.0/checkpoint.th[0m
/home/paperspace/.local/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
/home/paperspace/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Error executing job with overrides: ['hdemucs.norm_starts=999', 'hdemucs.cac=False', 'test.split=True', 'valid_apply=True', 'model=hdemucs', 'hdemucs.dconv_lstm=4', 'ema.epoch=[0.9, 0.95]', 'ema.batch=[0.9995, 0.9999]', 'seed=42', 'hdemucs.hybrid_old=True', 'svd=base', 'svd.penalty=1e-05', 'svd.dim=100', 'svd.convtr=True', 'optim.lr=0.0005', 'batch_size=4', 'dset.segment=8', 'hdemucs.channels=24', 'test.workers=', 'continue_from=a68eaf9b', 'epochs=20', 'continue_from=538354e6', 'epochs=20', 'optim.lr=0.00025']
Traceback (most recent call last):
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/train.py", line 148, in main
    solver = get_solver(args)
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/train.py", line 110, in get_solver
    return Solver(loaders, model, optimizer, args)
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/solver.py", line 75, in __init__
    self._reset()
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/solver.py", line 125, in _reset
    package = torch.load(cf, 'cpu')
  File "/home/paperspace/.local/lib/python3.8/site-packages/torch/serialization.py", line 594, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/paperspace/.local/lib/python3.8/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/paperspace/.local/lib/python3.8/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/538354000000.0/checkpoint.th'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mParser[0m Injecting argv ['hdemucs.norm_starts=999', 'hdemucs.cac=False', 'test.split=True', 'valid_apply=True', 'model=hdemucs', 'hdemucs.dconv_lstm=4', 'ema.epoch=[0.9, 0.95]', 'ema.batch=[0.9995, 0.9999]', 'seed=42', 'hdemucs.hybrid_old=True', 'svd=base', 'svd.penalty=1e-05', 'svd.dim=100', 'svd.convtr=True', 'optim.lr=0.0005', 'batch_size=4', 'dset.segment=8', 'hdemucs.channels=24', 'test.workers=', 'continue_from=a68eaf9b', 'epochs=20'] from sig 538354e6
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mExecutor:[0m Starting 1 worker processes for DDP.
[1mExecutor:[0m Worker 0 died, killing all workers
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:228: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  return hydra.main(
[[36m09-20 14:32:25[0m][[34mdemucs.train[0m][[32mINFO[0m] - For logs, checkpoints and samples check /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/5e8ce54e[0m
[[36m09-20 14:32:25[0m][[34mdora.distrib[0m][[32mINFO[0m] - world_size is 1, skipping init.[0m
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
/home/paperspace/.local/lib/python3.8/site-packages/musdb/configs/mus.yaml
[[36m09-20 14:32:29[0m][[34mdemucs.train[0m][[32mINFO[0m] - train/valid set size: 18626 14[0m
[[36m09-20 14:32:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Loading from /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/538354000000.0/checkpoint.th[0m
/home/paperspace/.local/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
/home/paperspace/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Error executing job with overrides: ['hdemucs.norm_starts=999', 'hdemucs.cac=False', 'test.split=True', 'valid_apply=True', 'model=hdemucs', 'hdemucs.dconv_lstm=4', 'ema.epoch=[0.9, 0.95]', 'ema.batch=[0.9995, 0.9999]', 'seed=42', 'hdemucs.hybrid_old=True', 'svd=base', 'svd.penalty=1e-05', 'svd.dim=100', 'svd.convtr=True', 'optim.lr=0.0005', 'batch_size=4', 'dset.segment=8', 'hdemucs.channels=24', 'test.workers=', 'continue_from=a68eaf9b', 'epochs=20', 'continue_from=538354e6', 'epochs=20', 'optim.lr=0.00025']
Traceback (most recent call last):
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/train.py", line 148, in main
    solver = get_solver(args)
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/train.py", line 110, in get_solver
    return Solver(loaders, model, optimizer, args)
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/solver.py", line 75, in __init__
    self._reset()
  File "/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/demucs/solver.py", line 125, in _reset
    package = torch.load(cf, 'cpu')
  File "/home/paperspace/.local/lib/python3.8/site-packages/torch/serialization.py", line 594, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/paperspace/.local/lib/python3.8/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/paperspace/.local/lib/python3.8/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/538354000000.0/checkpoint.th'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mParser[0m Injecting argv ['hdemucs.norm_starts=999', 'hdemucs.cac=False', 'test.split=True', 'valid_apply=True', 'model=hdemucs', 'hdemucs.dconv_lstm=4', 'ema.epoch=[0.9, 0.95]', 'ema.batch=[0.9995, 0.9999]', 'seed=42', 'hdemucs.hybrid_old=True', 'svd=base', 'svd.penalty=1e-05', 'svd.dim=100', 'svd.convtr=True', 'optim.lr=0.0005', 'batch_size=4', 'dset.segment=8', 'hdemucs.channels=24', 'test.workers=', 'continue_from=a68eaf9b', 'epochs=20'] from sig 538354e6
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mExecutor:[0m Starting 1 worker processes for DDP.
[1mExecutor:[0m Worker 0 died, killing all workers
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:228: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  return hydra.main(
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:228: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  return hydra.main(
[[36m09-20 15:55:33[0m][[34mdemucs.train[0m][[32mINFO[0m] - For logs, checkpoints and samples check /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/538354e6[0m
[[36m09-20 15:55:33[0m][[34mdora.distrib[0m][[32mINFO[0m] - world_size is 1, skipping init.[0m
[[36m09-20 15:55:33[0m][[34mdemucs.train[0m][[32mINFO[0m] - For logs, checkpoints and samples check /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/538354e6[0m
[[36m09-20 15:55:33[0m][[34mdora.distrib[0m][[32mINFO[0m] - world_size is 1, skipping init.[0m
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
/home/paperspace/.local/lib/python3.8/site-packages/musdb/configs/mus.yaml
[[36m09-20 15:55:38[0m][[34mdemucs.train[0m][[32mINFO[0m] - train/valid set size: 18626 14[0m
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
/home/paperspace/.local/lib/python3.8/site-packages/musdb/configs/mus.yaml
[[36m09-20 15:55:38[0m][[34mdemucs.train[0m][[32mINFO[0m] - train/valid set size: 18626 14[0m
[[36m09-20 15:55:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Loading checkpoint model: /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/538354e6/checkpoint.th[0m
[[36m09-20 15:55:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Loading checkpoint model: /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/538354e6/checkpoint.th[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Replaying metrics from previous run[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 1 | Loss=0.0980 | Reco=0.0957 | Grad=0.0925 | Penalty=228.2751[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 1 | Loss=0.1628 | Reco=0.1628 | Nsdr=6.070 | Best=0.1628 | Bname=ema_batch_1 | Penalty=235.9101[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 2 | Loss=0.0986 | Reco=0.0962 | Grad=0.0930 | Penalty=235.5921[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 2 | Loss=0.1613 | Reco=0.1613 | Nsdr=6.130 | Best=0.1613 | Bname=ema_batch_0 | Penalty=239.2919[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 3 | Loss=0.0977 | Reco=0.0954 | Grad=0.0928 | Penalty=234.2222[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 3 | Loss=0.1613 | Reco=0.1613 | Nsdr=6.134 | Best=0.1613 | Bname=ema_batch_1 | Penalty=238.4808[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 4 | Loss=0.0973 | Reco=0.0950 | Grad=0.0912 | Penalty=232.4990[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 4 | Loss=0.1614 | Reco=0.1614 | Nsdr=6.129 | Best=0.1613 | Bname=ema_batch_1 | Penalty=239.0826[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 5 | Loss=0.0972 | Reco=0.0948 | Grad=0.0924 | Penalty=233.9507[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 5 | Loss=0.1612 | Reco=0.1612 | Nsdr=6.144 | Best=0.1612 | Bname=ema_batch_1 | Penalty=240.0603[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 6 | Loss=0.0967 | Reco=0.0943 | Grad=0.0908 | Penalty=235.9014[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 6 | Loss=0.1610 | Reco=0.1610 | Nsdr=6.159 | Best=0.1610 | Bname=ema_batch_1 | Penalty=241.6552[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 7 | Loss=0.0970 | Reco=0.0946 | Grad=0.0932 | Penalty=238.8025[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 7 | Loss=0.1604 | Reco=0.1604 | Nsdr=6.177 | Best=0.1604 | Bname=ema_batch_1 | Penalty=242.8168[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 8 | Loss=0.0966 | Reco=0.0942 | Grad=0.0946 | Penalty=239.6425[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 8 | Loss=0.1603 | Reco=0.1603 | Nsdr=6.188 | Best=0.1603 | Bname=ema_batch_1 | Penalty=245.5708[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 9 | Loss=0.0958 | Reco=0.0934 | Grad=0.0912 | Penalty=238.8204[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 9 | Loss=0.1601 | Reco=0.1601 | Nsdr=6.193 | Best=0.1601 | Bname=ema_batch_1 | Penalty=243.7046[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 10 | Loss=0.0955 | Reco=0.0931 | Grad=0.0904 | Penalty=238.0518[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 10 | Loss=0.1597 | Reco=0.1597 | Nsdr=6.216 | Best=0.1597 | Bname=ema_batch_1 | Penalty=244.8525[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 11 | Loss=0.0962 | Reco=0.0938 | Grad=0.0931 | Penalty=241.4326[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 11 | Loss=0.1597 | Reco=0.1597 | Nsdr=6.235 | Best=0.1597 | Bname=ema_batch_1 | Penalty=247.2812[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 12 | Loss=0.0961 | Reco=0.0937 | Grad=0.0906 | Penalty=242.2743[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 12 | Loss=0.1592 | Reco=0.1592 | Nsdr=6.265 | Best=0.1592 | Bname=ema_batch_1 | Penalty=247.8131[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 13 | Loss=21.7224 | Reco=21.6750 | Grad=3303.7188 | Penalty=4739.2856[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 13 | Loss=0.1786 | Reco=0.1786 | Nsdr=5.384 | Best=0.1592 | Bname=ema_epoch_1 | Penalty=5015.7695[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 14 | Loss=0.2453 | Reco=0.1990 | Grad=1.5446 | Penalty=4637.9736[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 14 | Loss=0.2146 | Reco=0.2146 | Nsdr=3.987 | Best=0.1592 | Bname=ema_epoch_1 | Penalty=4322.6235[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 15 | Loss=0.2311 | Reco=0.1902 | Grad=0.3318 | Penalty=4088.2188[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 15 | Loss=0.2440 | Reco=0.2440 | Nsdr=2.882 | Best=0.1592 | Bname=ema_epoch_1 | Penalty=3881.7766[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 16 | Loss=0.2242 | Reco=0.1869 | Grad=0.3888 | Penalty=3723.8168[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 16 | Loss=0.2608 | Reco=0.2608 | Nsdr=2.087 | Best=0.1592 | Bname=main | Penalty=3582.9067[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 17 | Loss=0.2243 | Reco=0.1898 | Grad=0.9409 | Penalty=3453.8124[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 17 | Loss=0.2587 | Reco=0.2587 | Nsdr=2.157 | Best=0.1592 | Bname=ema_batch_0 | Penalty=3325.1650[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 18 | Loss=0.2538 | Reco=0.2192 | Grad=16.2084 | Penalty=3461.5649[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 18 | Loss=0.2856 | Reco=0.2856 | Nsdr=1.393 | Best=0.1592 | Bname=ema_epoch_1 | Penalty=3495.1428[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 19 | Loss=0.2566 | Reco=0.2237 | Grad=0.0643 | Penalty=3287.4950[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 19 | Loss=0.2951 | Reco=0.2951 | Nsdr=1.067 | Best=0.1592 | Bname=ema_epoch_1 | Penalty=3120.0105[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 20 | Loss=0.2526 | Reco=0.2227 | Grad=0.0705 | Penalty=2993.6661[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 20 | Loss=0.3018 | Reco=0.3018 | Nsdr=0.850 | Best=0.1592 | Bname=ema_epoch_1 | Penalty=2874.7092[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTest Summary | Epoch 20 | Sdr=4.731 | Nsdr=5.182 | Sdr_drums=6.631 | Nsdr_drums=6.545 | Sdr_bass=3.877 | Nsdr_bass=4.323 | Sdr_other=2.541 | Nsdr_other=3.161 | Sdr_vocals=5.875 | Nsdr_vocals=6.700[0m
/home/paperspace/.local/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
/home/paperspace/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Replaying metrics from previous run[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 1 | Loss=0.0980 | Reco=0.0957 | Grad=0.0925 | Penalty=228.2751[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 1 | Loss=0.1628 | Reco=0.1628 | Nsdr=6.070 | Best=0.1628 | Bname=ema_batch_1 | Penalty=235.9101[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 2 | Loss=0.0986 | Reco=0.0962 | Grad=0.0930 | Penalty=235.5921[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 2 | Loss=0.1613 | Reco=0.1613 | Nsdr=6.130 | Best=0.1613 | Bname=ema_batch_0 | Penalty=239.2919[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 3 | Loss=0.0977 | Reco=0.0954 | Grad=0.0928 | Penalty=234.2222[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 3 | Loss=0.1613 | Reco=0.1613 | Nsdr=6.134 | Best=0.1613 | Bname=ema_batch_1 | Penalty=238.4808[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 4 | Loss=0.0973 | Reco=0.0950 | Grad=0.0912 | Penalty=232.4990[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 4 | Loss=0.1614 | Reco=0.1614 | Nsdr=6.129 | Best=0.1613 | Bname=ema_batch_1 | Penalty=239.0826[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 5 | Loss=0.0972 | Reco=0.0948 | Grad=0.0924 | Penalty=233.9507[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 5 | Loss=0.1612 | Reco=0.1612 | Nsdr=6.144 | Best=0.1612 | Bname=ema_batch_1 | Penalty=240.0603[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 6 | Loss=0.0967 | Reco=0.0943 | Grad=0.0908 | Penalty=235.9014[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 6 | Loss=0.1610 | Reco=0.1610 | Nsdr=6.159 | Best=0.1610 | Bname=ema_batch_1 | Penalty=241.6552[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 7 | Loss=0.0970 | Reco=0.0946 | Grad=0.0932 | Penalty=238.8025[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 7 | Loss=0.1604 | Reco=0.1604 | Nsdr=6.177 | Best=0.1604 | Bname=ema_batch_1 | Penalty=242.8168[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 8 | Loss=0.0966 | Reco=0.0942 | Grad=0.0946 | Penalty=239.6425[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 8 | Loss=0.1603 | Reco=0.1603 | Nsdr=6.188 | Best=0.1603 | Bname=ema_batch_1 | Penalty=245.5708[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 9 | Loss=0.0958 | Reco=0.0934 | Grad=0.0912 | Penalty=238.8204[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 9 | Loss=0.1601 | Reco=0.1601 | Nsdr=6.193 | Best=0.1601 | Bname=ema_batch_1 | Penalty=243.7046[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 10 | Loss=0.0955 | Reco=0.0931 | Grad=0.0904 | Penalty=238.0518[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 10 | Loss=0.1597 | Reco=0.1597 | Nsdr=6.216 | Best=0.1597 | Bname=ema_batch_1 | Penalty=244.8525[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 11 | Loss=0.0962 | Reco=0.0938 | Grad=0.0931 | Penalty=241.4326[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 11 | Loss=0.1597 | Reco=0.1597 | Nsdr=6.235 | Best=0.1597 | Bname=ema_batch_1 | Penalty=247.2812[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 12 | Loss=0.0961 | Reco=0.0937 | Grad=0.0906 | Penalty=242.2743[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 12 | Loss=0.1592 | Reco=0.1592 | Nsdr=6.265 | Best=0.1592 | Bname=ema_batch_1 | Penalty=247.8131[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 13 | Loss=21.7224 | Reco=21.6750 | Grad=3303.7188 | Penalty=4739.2856[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 13 | Loss=0.1786 | Reco=0.1786 | Nsdr=5.384 | Best=0.1592 | Bname=ema_epoch_1 | Penalty=5015.7695[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 14 | Loss=0.2453 | Reco=0.1990 | Grad=1.5446 | Penalty=4637.9736[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 14 | Loss=0.2146 | Reco=0.2146 | Nsdr=3.987 | Best=0.1592 | Bname=ema_epoch_1 | Penalty=4322.6235[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 15 | Loss=0.2311 | Reco=0.1902 | Grad=0.3318 | Penalty=4088.2188[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 15 | Loss=0.2440 | Reco=0.2440 | Nsdr=2.882 | Best=0.1592 | Bname=ema_epoch_1 | Penalty=3881.7766[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 16 | Loss=0.2242 | Reco=0.1869 | Grad=0.3888 | Penalty=3723.8168[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 16 | Loss=0.2608 | Reco=0.2608 | Nsdr=2.087 | Best=0.1592 | Bname=main | Penalty=3582.9067[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 17 | Loss=0.2243 | Reco=0.1898 | Grad=0.9409 | Penalty=3453.8124[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 17 | Loss=0.2587 | Reco=0.2587 | Nsdr=2.157 | Best=0.1592 | Bname=ema_batch_0 | Penalty=3325.1650[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 18 | Loss=0.2538 | Reco=0.2192 | Grad=16.2084 | Penalty=3461.5649[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 18 | Loss=0.2856 | Reco=0.2856 | Nsdr=1.393 | Best=0.1592 | Bname=ema_epoch_1 | Penalty=3495.1428[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 19 | Loss=0.2566 | Reco=0.2237 | Grad=0.0643 | Penalty=3287.4950[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 19 | Loss=0.2951 | Reco=0.2951 | Nsdr=1.067 | Best=0.1592 | Bname=ema_epoch_1 | Penalty=3120.0105[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 20 | Loss=0.2526 | Reco=0.2227 | Grad=0.0705 | Penalty=2993.6661[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 20 | Loss=0.3018 | Reco=0.3018 | Nsdr=0.850 | Best=0.1592 | Bname=ema_epoch_1 | Penalty=2874.7092[0m
[[36m09-20 15:55:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTest Summary | Epoch 20 | Sdr=4.731 | Nsdr=5.182 | Sdr_drums=6.631 | Nsdr_drums=6.545 | Sdr_bass=3.877 | Nsdr_bass=4.323 | Sdr_other=2.541 | Nsdr_other=3.161 | Sdr_vocals=5.875 | Nsdr_vocals=6.700[0m
/home/paperspace/.local/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
/home/paperspace/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mParser[0m Injecting argv ['hdemucs.norm_starts=999', 'hdemucs.cac=False', 'test.split=True', 'valid_apply=True', 'model=hdemucs', 'hdemucs.dconv_lstm=4', 'ema.epoch=[0.9, 0.95]', 'ema.batch=[0.9995, 0.9999]', 'seed=42', 'hdemucs.hybrid_old=True', 'svd=base', 'svd.penalty=1e-05', 'svd.dim=100', 'svd.convtr=True', 'optim.lr=0.0005', 'batch_size=4', 'dset.segment=8', 'hdemucs.channels=24', 'test.workers=', 'continue_from=22d99e8f', 'epochs=20'] from sig a68eaf9b
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mExecutor:[0m Starting 1 worker processes for DDP.
[1mExecutor:[0m All workers completed successfully
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mParser[0m Injecting argv ['hdemucs.norm_starts=999', 'hdemucs.cac=False', 'test.split=True', 'valid_apply=True', 'model=hdemucs', 'hdemucs.dconv_lstm=4', 'ema.epoch=[0.9, 0.95]', 'ema.batch=[0.9995, 0.9999]', 'seed=42', 'hdemucs.hybrid_old=True', 'svd=base', 'svd.penalty=1e-05', 'svd.dim=100', 'svd.convtr=True', 'optim.lr=0.0005', 'batch_size=4', 'dset.segment=8', 'hdemucs.channels=24', 'test.workers=', 'continue_from=22d99e8f', 'epochs=20'] from sig a68eaf9b
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mExecutor:[0m Starting 1 worker processes for DDP.
[1mExecutor:[0m All workers completed successfully
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:228: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  return hydra.main(
[[36m09-23 08:32:19[0m][[34mdemucs.train[0m][[32mINFO[0m] - For logs, checkpoints and samples check /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/e2755e29[0m
[[36m09-23 08:32:19[0m][[34mdora.distrib[0m][[32mINFO[0m] - world_size is 1, skipping init.[0m
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
/home/paperspace/.local/lib/python3.8/site-packages/musdb/configs/mus.yaml
[[36m09-23 08:32:30[0m][[34mdemucs.train[0m][[32mINFO[0m] - train/valid set size: 18626 14[0m
Hi
[[36m09-23 08:32:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Loading from /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/538354e6/checkpoint.th[0m
[[36m09-23 08:32:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-23 08:32:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
/home/paperspace/.local/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
/home/paperspace/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:228: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  return hydra.main(
[[36m09-23 08:41:52[0m][[34mdemucs.train[0m][[32mINFO[0m] - For logs, checkpoints and samples check /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/5e8ce54e[0m
[[36m09-23 08:41:52[0m][[34mdora.distrib[0m][[32mINFO[0m] - world_size is 1, skipping init.[0m
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
/home/paperspace/.local/lib/python3.8/site-packages/musdb/configs/mus.yaml
[[36m09-23 08:42:00[0m][[34mdemucs.train[0m][[32mINFO[0m] - train/valid set size: 18626 14[0m
Hi
[[36m09-23 08:42:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Loading checkpoint model: /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/5e8ce54e/checkpoint.th[0m
[[36m09-23 08:42:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Replaying metrics from previous run[0m
[[36m09-23 08:42:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 1 | Loss=0.0917 | Reco=0.0895 | Grad=0.1529 | Penalty=214.4221[0m
[[36m09-23 08:42:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 1 | Loss=0.1605 | Reco=0.1605 | Nsdr=6.197 | Best=0.1605 | Bname=ema_batch_1 | Penalty=217.0066[0m
[[36m09-23 08:42:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 2 | Loss=0.0920 | Reco=0.0899 | Grad=0.0774 | Penalty=210.3680[0m
[[36m09-23 08:42:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 2 | Loss=0.1588 | Reco=0.1588 | Nsdr=6.273 | Best=0.1588 | Bname=ema_batch_0 | Penalty=213.0423[0m
[[36m09-23 08:42:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 3 | Loss=0.0913 | Reco=0.0892 | Grad=0.0774 | Penalty=206.6418[0m
[[36m09-23 08:42:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 3 | Loss=0.1594 | Reco=0.1594 | Nsdr=6.252 | Best=0.1588 | Bname=ema_batch_1 | Penalty=209.3791[0m
[[36m09-23 08:42:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-23 08:42:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
/home/paperspace/.local/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
/home/paperspace/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
[[36m09-23 09:28:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 4 | 1164/4656 | 0.42 it/sec | Loss 0.0922 | Reco 0.0902 | Grad 0.0809 | Penalty 204.9937[0m
[[36m09-23 10:14:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 4 | 2328/4656 | 0.42 it/sec | Loss 0.0918 | Reco 0.0898 | Grad 0.0808 | Penalty 205.1677[0m
[[36m09-23 10:59:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 4 | 3492/4656 | 0.42 it/sec | Loss 0.0920 | Reco 0.0899 | Grad 0.0815 | Penalty 204.9935[0m
[[36m09-23 11:45:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 4 | Loss=0.0918 | Reco=0.0898 | Grad=0.0812 | Penalty=204.9784[0m
[[36m09-23 11:45:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-23 11:45:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-23 11:46:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 3/14 | 11.5 sec/it | Loss 0.1753 | Reco 0.1753 | Nsdr 5.558[0m
[[36m09-23 11:46:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 6/14 | 0.12 it/sec | Loss 0.1642 | Reco 0.1642 | Nsdr 5.809[0m
[[36m09-23 11:46:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 9/14 | 0.12 it/sec | Loss 0.1646 | Reco 0.1646 | Nsdr 5.981[0m
[[36m09-23 11:46:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 12/14 | 0.13 it/sec | Loss 0.1630 | Reco 0.1630 | Nsdr 6.089[0m
[[36m09-23 11:47:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 3/14 | 11.2 sec/it | Loss 0.1671 | Reco 0.1671 | Nsdr 5.929[0m
[[36m09-23 11:47:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 6/14 | 0.12 it/sec | Loss 0.1593 | Reco 0.1593 | Nsdr 6.093[0m
[[36m09-23 11:48:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 9/14 | 0.13 it/sec | Loss 0.1595 | Reco 0.1595 | Nsdr 6.290[0m
[[36m09-23 11:48:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 12/14 | 0.14 it/sec | Loss 0.1580 | Reco 0.1580 | Nsdr 6.392[0m
[[36m09-23 11:49:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 3/14 | 10.7 sec/it | Loss 0.1667 | Reco 0.1667 | Nsdr 5.957[0m
[[36m09-23 11:49:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 6/14 | 0.12 it/sec | Loss 0.1586 | Reco 0.1586 | Nsdr 6.134[0m
[[36m09-23 11:50:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 9/14 | 0.13 it/sec | Loss 0.1588 | Reco 0.1588 | Nsdr 6.328[0m
[[36m09-23 11:50:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 12/14 | 0.14 it/sec | Loss 0.1576 | Reco 0.1576 | Nsdr 6.420[0m
[[36m09-23 11:51:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 3/14 | 10.6 sec/it | Loss 0.1698 | Reco 0.1698 | Nsdr 5.836[0m
[[36m09-23 11:51:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 6/14 | 0.12 it/sec | Loss 0.1603 | Reco 0.1603 | Nsdr 6.056[0m
[[36m09-23 11:51:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 9/14 | 0.13 it/sec | Loss 0.1603 | Reco 0.1603 | Nsdr 6.249[0m
[[36m09-23 11:52:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 12/14 | 0.14 it/sec | Loss 0.1590 | Reco 0.1590 | Nsdr 6.331[0m
[[36m09-23 11:52:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 3/14 | 10.9 sec/it | Loss 0.1699 | Reco 0.1699 | Nsdr 5.834[0m
[[36m09-23 11:53:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 6/14 | 0.12 it/sec | Loss 0.1604 | Reco 0.1604 | Nsdr 6.044[0m
[[36m09-23 11:53:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 9/14 | 0.13 it/sec | Loss 0.1604 | Reco 0.1604 | Nsdr 6.236[0m
[[36m09-23 11:53:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 12/14 | 0.14 it/sec | Loss 0.1592 | Reco 0.1592 | Nsdr 6.319[0m
[[36m09-23 11:53:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 4 | Loss=0.1588 | Reco=0.1588 | Nsdr=6.283 | Best=0.1588 | Bname=ema_batch_1 | Penalty=209.4439[0m
[[36m09-23 11:54:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-23 11:54:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-23 12:40:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 5 | 1164/4656 | 0.42 it/sec | Loss 0.0915 | Reco 0.0895 | Grad 0.0818 | Penalty 204.5611[0m
[[36m09-23 13:26:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 5 | 2328/4656 | 0.42 it/sec | Loss 0.0914 | Reco 0.0893 | Grad 0.0819 | Penalty 205.0145[0m
[[36m09-23 14:12:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 5 | 3492/4656 | 0.42 it/sec | Loss 0.0914 | Reco 0.0894 | Grad 0.0813 | Penalty 204.5762[0m
[[36m09-23 14:59:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 5 | Loss=0.0915 | Reco=0.0895 | Grad=0.0815 | Penalty=204.2562[0m
[[36m09-23 14:59:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-23 14:59:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-23 15:00:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 3/14 | 11.4 sec/it | Loss 0.1730 | Reco 0.1730 | Nsdr 5.695[0m
[[36m09-23 15:00:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 6/14 | 0.12 it/sec | Loss 0.1636 | Reco 0.1636 | Nsdr 5.898[0m
[[36m09-23 15:00:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 9/14 | 0.12 it/sec | Loss 0.1636 | Reco 0.1636 | Nsdr 6.080[0m
[[36m09-23 15:01:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 12/14 | 0.13 it/sec | Loss 0.1618 | Reco 0.1618 | Nsdr 6.189[0m
[[36m09-23 15:02:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 3/14 | 11.8 sec/it | Loss 0.1672 | Reco 0.1672 | Nsdr 5.943[0m
[[36m09-23 15:02:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 6/14 | 0.11 it/sec | Loss 0.1589 | Reco 0.1589 | Nsdr 6.113[0m
[[36m09-23 15:02:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 9/14 | 0.12 it/sec | Loss 0.1591 | Reco 0.1591 | Nsdr 6.305[0m
[[36m09-23 15:03:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 12/14 | 0.13 it/sec | Loss 0.1578 | Reco 0.1578 | Nsdr 6.397[0m
[[36m09-23 15:03:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 3/14 | 11.2 sec/it | Loss 0.1666 | Reco 0.1666 | Nsdr 5.968[0m
[[36m09-23 15:04:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 6/14 | 0.12 it/sec | Loss 0.1585 | Reco 0.1585 | Nsdr 6.138[0m
[[36m09-23 15:04:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 9/14 | 0.12 it/sec | Loss 0.1586 | Reco 0.1586 | Nsdr 6.341[0m
[[36m09-23 15:04:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 12/14 | 0.13 it/sec | Loss 0.1573 | Reco 0.1573 | Nsdr 6.434[0m
[[36m09-23 15:05:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 3/14 | 11.1 sec/it | Loss 0.1691 | Reco 0.1691 | Nsdr 5.856[0m
[[36m09-23 15:05:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 6/14 | 0.12 it/sec | Loss 0.1603 | Reco 0.1603 | Nsdr 6.048[0m
[[36m09-23 15:06:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 9/14 | 0.13 it/sec | Loss 0.1603 | Reco 0.1603 | Nsdr 6.242[0m
[[36m09-23 15:06:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 12/14 | 0.14 it/sec | Loss 0.1589 | Reco 0.1589 | Nsdr 6.334[0m
[[36m09-23 15:07:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 3/14 | 11.2 sec/it | Loss 0.1694 | Reco 0.1694 | Nsdr 5.849[0m
[[36m09-23 15:07:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 6/14 | 0.12 it/sec | Loss 0.1603 | Reco 0.1603 | Nsdr 6.050[0m
[[36m09-23 15:08:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 9/14 | 0.12 it/sec | Loss 0.1603 | Reco 0.1603 | Nsdr 6.241[0m
[[36m09-23 15:08:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 12/14 | 0.13 it/sec | Loss 0.1589 | Reco 0.1589 | Nsdr 6.330[0m
[[36m09-23 15:08:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 5 | Loss=0.1586 | Reco=0.1586 | Nsdr=6.296 | Best=0.1586 | Bname=ema_batch_1 | Penalty=208.4846[0m
[[36m09-23 15:08:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1586[0m
[[36m09-23 15:08:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-23 15:08:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-23 15:56:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 6 | 1164/4656 | 0.41 it/sec | Loss 0.0911 | Reco 0.0891 | Grad 0.0831 | Penalty 203.2935[0m
[[36m09-23 16:42:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 6 | 2328/4656 | 0.41 it/sec | Loss 0.0915 | Reco 0.0895 | Grad 0.0825 | Penalty 202.8475[0m
[[36m09-23 17:29:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 6 | 3492/4656 | 0.41 it/sec | Loss 0.0919 | Reco 0.0899 | Grad 0.0843 | Penalty 203.3463[0m
[[36m09-23 18:16:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 6 | Loss=0.0915 | Reco=0.0895 | Grad=0.0841 | Penalty=203.2673[0m
[[36m09-23 18:16:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-23 18:16:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-23 18:16:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 3/14 | 11.5 sec/it | Loss 0.1736 | Reco 0.1736 | Nsdr 5.686[0m
[[36m09-23 18:17:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 6/14 | 0.12 it/sec | Loss 0.1644 | Reco 0.1644 | Nsdr 5.914[0m
[[36m09-23 18:17:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 9/14 | 0.12 it/sec | Loss 0.1635 | Reco 0.1635 | Nsdr 6.160[0m
[[36m09-23 18:17:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 12/14 | 0.13 it/sec | Loss 0.1620 | Reco 0.1620 | Nsdr 6.241[0m
[[36m09-23 18:18:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 3/14 | 11.1 sec/it | Loss 0.1670 | Reco 0.1670 | Nsdr 5.951[0m
[[36m09-23 18:18:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 6/14 | 0.12 it/sec | Loss 0.1596 | Reco 0.1596 | Nsdr 6.104[0m
[[36m09-23 18:19:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 9/14 | 0.13 it/sec | Loss 0.1596 | Reco 0.1596 | Nsdr 6.308[0m
[[36m09-23 18:19:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 12/14 | 0.14 it/sec | Loss 0.1583 | Reco 0.1583 | Nsdr 6.391[0m
[[36m09-23 18:20:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 3/14 | 11.0 sec/it | Loss 0.1670 | Reco 0.1670 | Nsdr 5.958[0m
[[36m09-23 18:20:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 6/14 | 0.12 it/sec | Loss 0.1589 | Reco 0.1589 | Nsdr 6.126[0m
[[36m09-23 18:20:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 9/14 | 0.13 it/sec | Loss 0.1590 | Reco 0.1590 | Nsdr 6.328[0m
[[36m09-23 18:21:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 12/14 | 0.14 it/sec | Loss 0.1575 | Reco 0.1575 | Nsdr 6.426[0m
[[36m09-23 18:22:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 3/14 | 10.9 sec/it | Loss 0.1697 | Reco 0.1697 | Nsdr 5.847[0m
[[36m09-23 18:22:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 6/14 | 0.12 it/sec | Loss 0.1605 | Reco 0.1605 | Nsdr 6.056[0m
[[36m09-23 18:22:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 9/14 | 0.13 it/sec | Loss 0.1603 | Reco 0.1603 | Nsdr 6.257[0m
[[36m09-23 18:23:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 12/14 | 0.14 it/sec | Loss 0.1589 | Reco 0.1589 | Nsdr 6.345[0m
[[36m09-23 18:23:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 3/14 | 10.9 sec/it | Loss 0.1695 | Reco 0.1695 | Nsdr 5.854[0m
[[36m09-23 18:24:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 6/14 | 0.12 it/sec | Loss 0.1605 | Reco 0.1605 | Nsdr 6.055[0m
[[36m09-23 18:24:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 9/14 | 0.13 it/sec | Loss 0.1602 | Reco 0.1602 | Nsdr 6.260[0m
[[36m09-23 18:24:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 12/14 | 0.14 it/sec | Loss 0.1589 | Reco 0.1589 | Nsdr 6.347[0m
[[36m09-23 18:24:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 6 | Loss=0.1589 | Reco=0.1589 | Nsdr=6.285 | Best=0.1586 | Bname=ema_batch_1 | Penalty=207.2583[0m
[[36m09-23 18:25:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-23 18:25:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-23 19:11:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 7 | 1164/4656 | 0.42 it/sec | Loss 0.0910 | Reco 0.0890 | Grad 0.0816 | Penalty 201.5768[0m
[[36m09-23 19:58:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 7 | 2328/4656 | 0.41 it/sec | Loss 0.0914 | Reco 0.0894 | Grad 0.0822 | Penalty 201.0446[0m
[[36m09-23 20:45:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 7 | 3492/4656 | 0.41 it/sec | Loss 0.0918 | Reco 0.0898 | Grad 0.0833 | Penalty 201.1065[0m
[[36m09-23 21:31:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 7 | Loss=0.0913 | Reco=0.0893 | Grad=0.0833 | Penalty=200.8836[0m
[[36m09-23 21:31:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-23 21:31:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-23 21:32:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 3/14 | 11.1 sec/it | Loss 0.1700 | Reco 0.1700 | Nsdr 5.762[0m
[[36m09-23 21:32:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 6/14 | 0.12 it/sec | Loss 0.1631 | Reco 0.1631 | Nsdr 5.913[0m
[[36m09-23 21:32:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 9/14 | 0.13 it/sec | Loss 0.1639 | Reco 0.1639 | Nsdr 6.086[0m
[[36m09-23 21:33:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 12/14 | 0.14 it/sec | Loss 0.1621 | Reco 0.1621 | Nsdr 6.198[0m
[[36m09-23 21:34:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 3/14 | 11.0 sec/it | Loss 0.1657 | Reco 0.1657 | Nsdr 5.994[0m
[[36m09-23 21:34:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 6/14 | 0.12 it/sec | Loss 0.1591 | Reco 0.1591 | Nsdr 6.126[0m
[[36m09-23 21:34:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 9/14 | 0.13 it/sec | Loss 0.1594 | Reco 0.1594 | Nsdr 6.318[0m
[[36m09-23 21:34:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 12/14 | 0.14 it/sec | Loss 0.1581 | Reco 0.1581 | Nsdr 6.402[0m
[[36m09-23 21:35:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 3/14 | 10.7 sec/it | Loss 0.1653 | Reco 0.1653 | Nsdr 6.025[0m
[[36m09-23 21:35:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 6/14 | 0.12 it/sec | Loss 0.1584 | Reco 0.1584 | Nsdr 6.161[0m
[[36m09-23 21:36:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 9/14 | 0.13 it/sec | Loss 0.1587 | Reco 0.1587 | Nsdr 6.345[0m
[[36m09-23 21:36:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 12/14 | 0.14 it/sec | Loss 0.1574 | Reco 0.1574 | Nsdr 6.435[0m
[[36m09-23 21:37:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 3/14 | 10.8 sec/it | Loss 0.1680 | Reco 0.1680 | Nsdr 5.908[0m
[[36m09-23 21:37:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 6/14 | 0.12 it/sec | Loss 0.1599 | Reco 0.1599 | Nsdr 6.083[0m
[[36m09-23 21:38:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 9/14 | 0.13 it/sec | Loss 0.1598 | Reco 0.1598 | Nsdr 6.281[0m
[[36m09-23 21:38:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 12/14 | 0.14 it/sec | Loss 0.1584 | Reco 0.1584 | Nsdr 6.372[0m
[[36m09-23 21:39:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 3/14 | 10.7 sec/it | Loss 0.1680 | Reco 0.1680 | Nsdr 5.914[0m
[[36m09-23 21:39:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 6/14 | 0.12 it/sec | Loss 0.1598 | Reco 0.1598 | Nsdr 6.092[0m
[[36m09-23 21:39:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 9/14 | 0.13 it/sec | Loss 0.1597 | Reco 0.1597 | Nsdr 6.290[0m
[[36m09-23 21:40:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 12/14 | 0.14 it/sec | Loss 0.1584 | Reco 0.1584 | Nsdr 6.376[0m
[[36m09-23 21:40:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 7 | Loss=0.1588 | Reco=0.1588 | Nsdr=6.293 | Best=0.1586 | Bname=ema_batch_1 | Penalty=205.5539[0m
[[36m09-23 21:40:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-23 21:40:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-23 22:26:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 8 | 1164/4656 | 0.42 it/sec | Loss 0.0924 | Reco 0.0904 | Grad 0.0881 | Penalty 200.4196[0m
[[36m09-23 23:11:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 8 | 2328/4656 | 0.42 it/sec | Loss 0.0921 | Reco 0.0901 | Grad 0.0856 | Penalty 200.1644[0m
[[36m09-23 23:58:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 8 | 3492/4656 | 0.42 it/sec | Loss 0.0914 | Reco 0.0894 | Grad 0.0846 | Penalty 199.9863[0m
[[36m09-24 00:44:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 8 | Loss=0.0915 | Reco=0.0895 | Grad=0.0842 | Penalty=200.2128[0m
[[36m09-24 00:44:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-24 00:44:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-24 00:45:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 11.4 sec/it | Loss 0.1752 | Reco 0.1752 | Nsdr 5.584[0m
[[36m09-24 00:45:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.12 it/sec | Loss 0.1652 | Reco 0.1652 | Nsdr 5.817[0m
[[36m09-24 00:45:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.12 it/sec | Loss 0.1657 | Reco 0.1657 | Nsdr 5.966[0m
[[36m09-24 00:46:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.13 it/sec | Loss 0.1641 | Reco 0.1641 | Nsdr 6.059[0m
[[36m09-24 00:47:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 11.1 sec/it | Loss 0.1663 | Reco 0.1663 | Nsdr 5.974[0m
[[36m09-24 00:47:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.12 it/sec | Loss 0.1588 | Reco 0.1588 | Nsdr 6.131[0m
[[36m09-24 00:47:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.13 it/sec | Loss 0.1592 | Reco 0.1592 | Nsdr 6.308[0m
[[36m09-24 00:47:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.14 it/sec | Loss 0.1577 | Reco 0.1577 | Nsdr 6.413[0m
[[36m09-24 00:48:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 11.0 sec/it | Loss 0.1659 | Reco 0.1659 | Nsdr 5.999[0m
[[36m09-24 00:49:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.12 it/sec | Loss 0.1584 | Reco 0.1584 | Nsdr 6.157[0m
[[36m09-24 00:49:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.13 it/sec | Loss 0.1588 | Reco 0.1588 | Nsdr 6.332[0m
[[36m09-24 00:49:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.14 it/sec | Loss 0.1574 | Reco 0.1574 | Nsdr 6.426[0m
[[36m09-24 00:50:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 10.7 sec/it | Loss 0.1677 | Reco 0.1677 | Nsdr 5.922[0m
[[36m09-24 00:50:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.12 it/sec | Loss 0.1596 | Reco 0.1596 | Nsdr 6.099[0m
[[36m09-24 00:51:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.13 it/sec | Loss 0.1596 | Reco 0.1596 | Nsdr 6.294[0m
[[36m09-24 00:51:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.14 it/sec | Loss 0.1582 | Reco 0.1582 | Nsdr 6.383[0m
[[36m09-24 00:52:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 11.0 sec/it | Loss 0.1677 | Reco 0.1677 | Nsdr 5.924[0m
[[36m09-24 00:52:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.12 it/sec | Loss 0.1595 | Reco 0.1595 | Nsdr 6.102[0m
[[36m09-24 00:52:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.13 it/sec | Loss 0.1595 | Reco 0.1595 | Nsdr 6.296[0m
[[36m09-24 00:53:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.14 it/sec | Loss 0.1582 | Reco 0.1582 | Nsdr 6.380[0m
[[36m09-24 00:53:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 8 | Loss=0.1589 | Reco=0.1589 | Nsdr=6.282 | Best=0.1586 | Bname=ema_batch_1 | Penalty=206.0840[0m
[[36m09-24 00:53:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-24 00:53:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-24 01:39:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 9 | 1164/4656 | 0.42 it/sec | Loss 0.0920 | Reco 0.0900 | Grad 0.0827 | Penalty 202.0684[0m
[[36m09-24 02:25:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 9 | 2328/4656 | 0.42 it/sec | Loss 0.0911 | Reco 0.0891 | Grad 0.0838 | Penalty 201.0399[0m
[[36m09-24 03:11:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 9 | 3492/4656 | 0.42 it/sec | Loss 0.0910 | Reco 0.0890 | Grad 0.0839 | Penalty 200.4949[0m
[[36m09-24 03:59:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 9 | Loss=0.0909 | Reco=0.0889 | Grad=0.0834 | Penalty=200.1950[0m
[[36m09-24 03:59:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-24 03:59:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-24 04:00:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 12.2 sec/it | Loss 0.1676 | Reco 0.1676 | Nsdr 5.910[0m
[[36m09-24 04:00:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.11 it/sec | Loss 0.1606 | Reco 0.1606 | Nsdr 6.025[0m
[[36m09-24 04:00:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.12 it/sec | Loss 0.1613 | Reco 0.1613 | Nsdr 6.198[0m
[[36m09-24 04:00:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.13 it/sec | Loss 0.1596 | Reco 0.1596 | Nsdr 6.313[0m
[[36m09-24 04:01:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 12.7 sec/it | Loss 0.1657 | Reco 0.1657 | Nsdr 6.021[0m
[[36m09-24 04:02:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.11 it/sec | Loss 0.1586 | Reco 0.1586 | Nsdr 6.153[0m
[[36m09-24 04:02:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.11 it/sec | Loss 0.1590 | Reco 0.1590 | Nsdr 6.327[0m
[[36m09-24 04:02:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.12 it/sec | Loss 0.1575 | Reco 0.1575 | Nsdr 6.425[0m
[[36m09-24 04:03:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 12.2 sec/it | Loss 0.1655 | Reco 0.1655 | Nsdr 6.023[0m
[[36m09-24 04:04:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.11 it/sec | Loss 0.1586 | Reco 0.1586 | Nsdr 6.153[0m
[[36m09-24 04:04:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.12 it/sec | Loss 0.1587 | Reco 0.1587 | Nsdr 6.348[0m
[[36m09-24 04:04:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.13 it/sec | Loss 0.1573 | Reco 0.1573 | Nsdr 6.445[0m
[[36m09-24 04:05:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 12.1 sec/it | Loss 0.1668 | Reco 0.1668 | Nsdr 5.964[0m
[[36m09-24 04:05:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.11 it/sec | Loss 0.1591 | Reco 0.1591 | Nsdr 6.119[0m
[[36m09-24 04:06:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.12 it/sec | Loss 0.1593 | Reco 0.1593 | Nsdr 6.307[0m
[[36m09-24 04:06:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.13 it/sec | Loss 0.1579 | Reco 0.1579 | Nsdr 6.403[0m
[[36m09-24 04:07:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 12.1 sec/it | Loss 0.1667 | Reco 0.1667 | Nsdr 5.966[0m
[[36m09-24 04:07:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.11 it/sec | Loss 0.1590 | Reco 0.1590 | Nsdr 6.127[0m
[[36m09-24 04:08:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.12 it/sec | Loss 0.1591 | Reco 0.1591 | Nsdr 6.318[0m
[[36m09-24 04:08:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.13 it/sec | Loss 0.1577 | Reco 0.1577 | Nsdr 6.413[0m
[[36m09-24 04:08:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 9 | Loss=0.1587 | Reco=0.1587 | Nsdr=6.298 | Best=0.1586 | Bname=ema_batch_1 | Penalty=205.5264[0m
[[36m09-24 04:08:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-24 04:08:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-24 04:55:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 10 | 1164/4656 | 0.42 it/sec | Loss 0.0903 | Reco 0.0883 | Grad 0.0859 | Penalty 199.2823[0m
[[36m09-24 05:41:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 10 | 2328/4656 | 0.42 it/sec | Loss 0.0915 | Reco 0.0895 | Grad 0.0866 | Penalty 199.1291[0m
[[36m09-24 06:27:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 10 | 3492/4656 | 0.42 it/sec | Loss 0.0913 | Reco 0.0893 | Grad 0.0851 | Penalty 198.7397[0m
[[36m09-24 07:13:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 10 | Loss=0.0911 | Reco=0.0892 | Grad=0.0842 | Penalty=198.5601[0m
[[36m09-24 07:13:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-24 07:13:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-24 07:14:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 10.8 sec/it | Loss 0.1713 | Reco 0.1713 | Nsdr 5.758[0m
[[36m09-24 07:14:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 0.12 it/sec | Loss 0.1630 | Reco 0.1630 | Nsdr 5.915[0m
[[36m09-24 07:15:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.13 it/sec | Loss 0.1633 | Reco 0.1633 | Nsdr 6.106[0m
[[36m09-24 07:15:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.14 it/sec | Loss 0.1611 | Reco 0.1611 | Nsdr 6.246[0m
[[36m09-24 07:16:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 11.0 sec/it | Loss 0.1664 | Reco 0.1664 | Nsdr 5.981[0m
[[36m09-24 07:16:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 0.12 it/sec | Loss 0.1586 | Reco 0.1586 | Nsdr 6.140[0m
[[36m09-24 07:17:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.13 it/sec | Loss 0.1591 | Reco 0.1591 | Nsdr 6.313[0m
[[36m09-24 07:17:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.14 it/sec | Loss 0.1575 | Reco 0.1575 | Nsdr 6.419[0m
[[36m09-24 07:18:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 11.3 sec/it | Loss 0.1656 | Reco 0.1656 | Nsdr 6.020[0m
[[36m09-24 07:18:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 0.12 it/sec | Loss 0.1582 | Reco 0.1582 | Nsdr 6.163[0m
[[36m09-24 07:18:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.13 it/sec | Loss 0.1584 | Reco 0.1584 | Nsdr 6.352[0m
[[36m09-24 07:19:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.14 it/sec | Loss 0.1569 | Reco 0.1569 | Nsdr 6.454[0m
[[36m09-24 07:19:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 10.7 sec/it | Loss 0.1670 | Reco 0.1670 | Nsdr 5.963[0m
[[36m09-24 07:20:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 0.12 it/sec | Loss 0.1590 | Reco 0.1590 | Nsdr 6.127[0m
[[36m09-24 07:20:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.13 it/sec | Loss 0.1592 | Reco 0.1592 | Nsdr 6.313[0m
[[36m09-24 07:20:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.14 it/sec | Loss 0.1576 | Reco 0.1576 | Nsdr 6.422[0m
[[36m09-24 07:21:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 10.8 sec/it | Loss 0.1668 | Reco 0.1668 | Nsdr 5.971[0m
[[36m09-24 07:21:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 0.12 it/sec | Loss 0.1589 | Reco 0.1589 | Nsdr 6.130[0m
[[36m09-24 07:22:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.13 it/sec | Loss 0.1591 | Reco 0.1591 | Nsdr 6.320[0m
[[36m09-24 07:22:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.14 it/sec | Loss 0.1576 | Reco 0.1576 | Nsdr 6.417[0m
[[36m09-24 07:22:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 10 | Loss=0.1583 | Reco=0.1583 | Nsdr=6.312 | Best=0.1583 | Bname=ema_batch_1 | Penalty=202.3547[0m
[[36m09-24 07:22:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1583[0m
[[36m09-24 07:22:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-24 07:22:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-24 08:09:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 11 | 1164/4656 | 0.42 it/sec | Loss 0.0902 | Reco 0.0882 | Grad 0.0854 | Penalty 197.5803[0m
[[36m09-24 08:54:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 11 | 2328/4656 | 0.42 it/sec | Loss 0.0912 | Reco 0.0892 | Grad 0.0836 | Penalty 197.5184[0m
[[36m09-24 09:40:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 11 | 3492/4656 | 0.42 it/sec | Loss 0.0908 | Reco 0.0888 | Grad 0.0851 | Penalty 198.3693[0m
[[36m09-24 10:25:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 11 | Loss=0.0905 | Reco=0.0886 | Grad=0.0842 | Penalty=198.0890[0m
[[36m09-24 10:25:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-24 10:25:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-24 10:26:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 10.6 sec/it | Loss 0.1677 | Reco 0.1677 | Nsdr 5.964[0m
[[36m09-24 10:26:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.12 it/sec | Loss 0.1601 | Reco 0.1601 | Nsdr 6.110[0m
[[36m09-24 10:26:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.13 it/sec | Loss 0.1612 | Reco 0.1612 | Nsdr 6.253[0m
[[36m09-24 10:27:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.14 it/sec | Loss 0.1601 | Reco 0.1601 | Nsdr 6.332[0m
[[36m09-24 10:28:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 10.6 sec/it | Loss 0.1653 | Reco 0.1653 | Nsdr 6.046[0m
[[36m09-24 10:28:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.12 it/sec | Loss 0.1577 | Reco 0.1577 | Nsdr 6.195[0m
[[36m09-24 10:28:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.13 it/sec | Loss 0.1582 | Reco 0.1582 | Nsdr 6.369[0m
[[36m09-24 10:28:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.14 it/sec | Loss 0.1569 | Reco 0.1569 | Nsdr 6.460[0m
[[36m09-24 10:29:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 10.4 sec/it | Loss 0.1651 | Reco 0.1651 | Nsdr 6.053[0m
[[36m09-24 10:30:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.12 it/sec | Loss 0.1576 | Reco 0.1576 | Nsdr 6.196[0m
[[36m09-24 10:30:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.13 it/sec | Loss 0.1579 | Reco 0.1579 | Nsdr 6.385[0m
[[36m09-24 10:30:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.14 it/sec | Loss 0.1566 | Reco 0.1566 | Nsdr 6.481[0m
[[36m09-24 10:31:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 10.6 sec/it | Loss 0.1661 | Reco 0.1661 | Nsdr 6.008[0m
[[36m09-24 10:31:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.12 it/sec | Loss 0.1583 | Reco 0.1583 | Nsdr 6.160[0m
[[36m09-24 10:32:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.13 it/sec | Loss 0.1587 | Reco 0.1587 | Nsdr 6.343[0m
[[36m09-24 10:32:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.14 it/sec | Loss 0.1573 | Reco 0.1573 | Nsdr 6.438[0m
[[36m09-24 10:33:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 10.9 sec/it | Loss 0.1662 | Reco 0.1662 | Nsdr 6.001[0m
[[36m09-24 10:33:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.12 it/sec | Loss 0.1585 | Reco 0.1585 | Nsdr 6.153[0m
[[36m09-24 10:33:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.13 it/sec | Loss 0.1588 | Reco 0.1588 | Nsdr 6.335[0m
[[36m09-24 10:34:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.14 it/sec | Loss 0.1574 | Reco 0.1574 | Nsdr 6.427[0m
[[36m09-24 10:34:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 11 | Loss=0.1580 | Reco=0.1580 | Nsdr=6.335 | Best=0.1580 | Bname=ema_batch_1 | Penalty=201.9065[0m
[[36m09-24 10:34:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1580[0m
[[36m09-24 10:34:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-24 10:34:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-24 11:20:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 12 | 1164/4656 | 0.42 it/sec | Loss 0.0913 | Reco 0.0893 | Grad 0.0826 | Penalty 196.9431[0m
[[36m09-24 12:06:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 12 | 2328/4656 | 0.42 it/sec | Loss 0.0910 | Reco 0.0890 | Grad 0.0825 | Penalty 196.8410[0m
[[36m09-24 12:52:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 12 | 3492/4656 | 0.42 it/sec | Loss 0.0909 | Reco 0.0889 | Grad 0.0832 | Penalty 196.7159[0m
[[36m09-24 13:38:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 12 | Loss=0.0907 | Reco=0.0887 | Grad=0.0837 | Penalty=196.6368[0m
[[36m09-24 13:38:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-24 13:38:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-24 13:39:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 11.2 sec/it | Loss 0.1720 | Reco 0.1720 | Nsdr 5.750[0m
[[36m09-24 13:39:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.12 it/sec | Loss 0.1634 | Reco 0.1634 | Nsdr 5.948[0m
[[36m09-24 13:40:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.13 it/sec | Loss 0.1633 | Reco 0.1633 | Nsdr 6.129[0m
[[36m09-24 13:40:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.14 it/sec | Loss 0.1613 | Reco 0.1613 | Nsdr 6.239[0m
[[36m09-24 13:41:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 11.1 sec/it | Loss 0.1658 | Reco 0.1658 | Nsdr 6.017[0m
[[36m09-24 13:41:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.12 it/sec | Loss 0.1586 | Reco 0.1586 | Nsdr 6.155[0m
[[36m09-24 13:41:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.13 it/sec | Loss 0.1591 | Reco 0.1591 | Nsdr 6.319[0m
[[36m09-24 13:42:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.14 it/sec | Loss 0.1575 | Reco 0.1575 | Nsdr 6.424[0m
[[36m09-24 13:42:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 10.9 sec/it | Loss 0.1642 | Reco 0.1642 | Nsdr 6.088[0m
[[36m09-24 13:43:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.12 it/sec | Loss 0.1575 | Reco 0.1575 | Nsdr 6.211[0m
[[36m09-24 13:43:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.13 it/sec | Loss 0.1578 | Reco 0.1578 | Nsdr 6.399[0m
[[36m09-24 13:43:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.14 it/sec | Loss 0.1564 | Reco 0.1564 | Nsdr 6.492[0m
[[36m09-24 13:44:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 10.6 sec/it | Loss 0.1665 | Reco 0.1665 | Nsdr 5.991[0m
[[36m09-24 13:44:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.12 it/sec | Loss 0.1588 | Reco 0.1588 | Nsdr 6.151[0m
[[36m09-24 13:45:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.13 it/sec | Loss 0.1588 | Reco 0.1588 | Nsdr 6.345[0m
[[36m09-24 13:45:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.14 it/sec | Loss 0.1573 | Reco 0.1573 | Nsdr 6.444[0m
[[36m09-24 13:46:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 11.1 sec/it | Loss 0.1667 | Reco 0.1667 | Nsdr 5.981[0m
[[36m09-24 13:46:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.12 it/sec | Loss 0.1589 | Reco 0.1589 | Nsdr 6.139[0m
[[36m09-24 13:47:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.13 it/sec | Loss 0.1589 | Reco 0.1589 | Nsdr 6.337[0m
[[36m09-24 13:47:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.14 it/sec | Loss 0.1575 | Reco 0.1575 | Nsdr 6.433[0m
[[36m09-24 13:47:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 12 | Loss=0.1578 | Reco=0.1578 | Nsdr=6.348 | Best=0.1578 | Bname=ema_batch_1 | Penalty=201.1647[0m
[[36m09-24 13:47:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1578[0m
[[36m09-24 13:47:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-24 13:47:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-24 14:34:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 13 | 1164/4656 | 0.42 it/sec | Loss 0.0903 | Reco 0.0884 | Grad 0.0844 | Penalty 196.0334[0m
[[36m09-24 15:21:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 13 | 2328/4656 | 0.41 it/sec | Loss 0.0902 | Reco 0.0882 | Grad 0.0846 | Penalty 195.9873[0m
[[36m09-24 16:09:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 13 | 3492/4656 | 0.41 it/sec | Loss 0.0905 | Reco 0.0886 | Grad 0.0842 | Penalty 195.8182[0m
[[36m09-24 16:55:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 13 | Loss=0.0902 | Reco=0.0883 | Grad=0.0833 | Penalty=195.4904[0m
[[36m09-24 16:55:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-24 16:55:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-24 16:55:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 11.1 sec/it | Loss 0.1713 | Reco 0.1713 | Nsdr 5.771[0m
[[36m09-24 16:56:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 6/14 | 0.12 it/sec | Loss 0.1616 | Reco 0.1616 | Nsdr 5.993[0m
[[36m09-24 16:56:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 9/14 | 0.13 it/sec | Loss 0.1633 | Reco 0.1633 | Nsdr 6.106[0m
[[36m09-24 16:56:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 12/14 | 0.14 it/sec | Loss 0.1619 | Reco 0.1619 | Nsdr 6.206[0m
[[36m09-24 16:57:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 10.8 sec/it | Loss 0.1660 | Reco 0.1660 | Nsdr 5.993[0m
[[36m09-24 16:57:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 6/14 | 0.12 it/sec | Loss 0.1583 | Reco 0.1583 | Nsdr 6.150[0m
[[36m09-24 16:58:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 9/14 | 0.13 it/sec | Loss 0.1591 | Reco 0.1591 | Nsdr 6.305[0m
[[36m09-24 16:58:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 12/14 | 0.14 it/sec | Loss 0.1575 | Reco 0.1575 | Nsdr 6.414[0m
[[36m09-24 16:59:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 10.9 sec/it | Loss 0.1647 | Reco 0.1647 | Nsdr 6.068[0m
[[36m09-24 16:59:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 6/14 | 0.12 it/sec | Loss 0.1575 | Reco 0.1575 | Nsdr 6.202[0m
[[36m09-24 16:59:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 9/14 | 0.13 it/sec | Loss 0.1581 | Reco 0.1581 | Nsdr 6.370[0m
[[36m09-24 17:00:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 12/14 | 0.14 it/sec | Loss 0.1567 | Reco 0.1567 | Nsdr 6.469[0m
[[36m09-24 17:01:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 10.7 sec/it | Loss 0.1660 | Reco 0.1660 | Nsdr 6.010[0m
[[36m09-24 17:01:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 6/14 | 0.12 it/sec | Loss 0.1585 | Reco 0.1585 | Nsdr 6.161[0m
[[36m09-24 17:01:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 9/14 | 0.13 it/sec | Loss 0.1588 | Reco 0.1588 | Nsdr 6.342[0m
[[36m09-24 17:01:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 12/14 | 0.14 it/sec | Loss 0.1573 | Reco 0.1573 | Nsdr 6.445[0m
[[36m09-24 17:02:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 11.0 sec/it | Loss 0.1661 | Reco 0.1661 | Nsdr 6.007[0m
[[36m09-24 17:03:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 6/14 | 0.12 it/sec | Loss 0.1583 | Reco 0.1583 | Nsdr 6.166[0m
[[36m09-24 17:03:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 9/14 | 0.13 it/sec | Loss 0.1586 | Reco 0.1586 | Nsdr 6.353[0m
[[36m09-24 17:03:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 12/14 | 0.14 it/sec | Loss 0.1572 | Reco 0.1572 | Nsdr 6.446[0m
[[36m09-24 17:03:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 13 | Loss=0.1581 | Reco=0.1581 | Nsdr=6.324 | Best=0.1578 | Bname=ema_batch_1 | Penalty=199.8938[0m
[[36m09-24 17:03:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-24 17:03:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-24 17:49:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 14 | 1164/4656 | 0.42 it/sec | Loss 0.0896 | Reco 0.0877 | Grad 0.0824 | Penalty 194.2660[0m
[[36m09-24 18:35:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 14 | 2328/4656 | 0.42 it/sec | Loss 0.0905 | Reco 0.0885 | Grad 0.0859 | Penalty 194.5995[0m
[[36m09-24 19:21:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 14 | 3492/4656 | 0.42 it/sec | Loss 0.0907 | Reco 0.0887 | Grad 0.0855 | Penalty 194.7568[0m
[[36m09-24 20:07:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 14 | Loss=0.0905 | Reco=0.0886 | Grad=0.0851 | Penalty=194.6580[0m
[[36m09-24 20:07:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-24 20:07:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-24 20:08:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 3/14 | 11.4 sec/it | Loss 0.1701 | Reco 0.1701 | Nsdr 5.832[0m
[[36m09-24 20:08:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 6/14 | 0.12 it/sec | Loss 0.1614 | Reco 0.1614 | Nsdr 6.024[0m
[[36m09-24 20:09:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 9/14 | 0.12 it/sec | Loss 0.1616 | Reco 0.1616 | Nsdr 6.199[0m
[[36m09-24 20:09:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 12/14 | 0.13 it/sec | Loss 0.1602 | Reco 0.1602 | Nsdr 6.288[0m
[[36m09-24 20:10:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 3/14 | 11.0 sec/it | Loss 0.1668 | Reco 0.1668 | Nsdr 5.974[0m
[[36m09-24 20:10:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 6/14 | 0.12 it/sec | Loss 0.1579 | Reco 0.1579 | Nsdr 6.176[0m
[[36m09-24 20:10:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 9/14 | 0.13 it/sec | Loss 0.1586 | Reco 0.1586 | Nsdr 6.334[0m
[[36m09-24 20:11:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 12/14 | 0.14 it/sec | Loss 0.1572 | Reco 0.1572 | Nsdr 6.428[0m
[[36m09-24 20:11:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 3/14 | 10.8 sec/it | Loss 0.1650 | Reco 0.1650 | Nsdr 6.050[0m
[[36m09-24 20:12:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 6/14 | 0.12 it/sec | Loss 0.1574 | Reco 0.1574 | Nsdr 6.202[0m
[[36m09-24 20:12:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 9/14 | 0.13 it/sec | Loss 0.1580 | Reco 0.1580 | Nsdr 6.367[0m
[[36m09-24 20:12:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 12/14 | 0.14 it/sec | Loss 0.1566 | Reco 0.1566 | Nsdr 6.464[0m
[[36m09-24 20:13:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 3/14 | 11.1 sec/it | Loss 0.1657 | Reco 0.1657 | Nsdr 6.026[0m
[[36m09-24 20:13:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 6/14 | 0.12 it/sec | Loss 0.1583 | Reco 0.1583 | Nsdr 6.171[0m
[[36m09-24 20:14:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 9/14 | 0.13 it/sec | Loss 0.1585 | Reco 0.1585 | Nsdr 6.359[0m
[[36m09-24 20:14:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 12/14 | 0.14 it/sec | Loss 0.1572 | Reco 0.1572 | Nsdr 6.451[0m
[[36m09-24 20:15:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 3/14 | 11.4 sec/it | Loss 0.1655 | Reco 0.1655 | Nsdr 6.034[0m
[[36m09-24 20:15:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 6/14 | 0.12 it/sec | Loss 0.1582 | Reco 0.1582 | Nsdr 6.176[0m
[[36m09-24 20:16:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 9/14 | 0.12 it/sec | Loss 0.1585 | Reco 0.1585 | Nsdr 6.358[0m
[[36m09-24 20:16:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 12/14 | 0.13 it/sec | Loss 0.1572 | Reco 0.1572 | Nsdr 6.449[0m
[[36m09-24 20:16:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 14 | Loss=0.1580 | Reco=0.1580 | Nsdr=6.323 | Best=0.1578 | Bname=ema_batch_1 | Penalty=198.6648[0m
[[36m09-24 20:16:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-24 20:16:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-24 21:02:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 15 | 1164/4656 | 0.42 it/sec | Loss 0.0895 | Reco 0.0876 | Grad 0.0846 | Penalty 193.9206[0m
[[36m09-24 21:48:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 15 | 2328/4656 | 0.42 it/sec | Loss 0.0897 | Reco 0.0878 | Grad 0.0847 | Penalty 194.0734[0m
[[36m09-24 22:35:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 15 | 3492/4656 | 0.42 it/sec | Loss 0.0904 | Reco 0.0885 | Grad 0.0856 | Penalty 194.6471[0m
[[36m09-24 23:22:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 15 | Loss=0.0904 | Reco=0.0884 | Grad=0.0848 | Penalty=194.6633[0m
[[36m09-24 23:22:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-24 23:22:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-24 23:22:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 3/14 | 10.7 sec/it | Loss 0.1757 | Reco 0.1757 | Nsdr 5.641[0m
[[36m09-24 23:23:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 6/14 | 0.12 it/sec | Loss 0.1650 | Reco 0.1650 | Nsdr 5.881[0m
[[36m09-24 23:23:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 9/14 | 0.13 it/sec | Loss 0.1646 | Reco 0.1646 | Nsdr 6.088[0m
[[36m09-24 23:23:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 12/14 | 0.14 it/sec | Loss 0.1618 | Reco 0.1618 | Nsdr 6.244[0m
[[36m09-24 23:24:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 3/14 | 10.7 sec/it | Loss 0.1676 | Reco 0.1676 | Nsdr 5.933[0m
[[36m09-24 23:24:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 6/14 | 0.12 it/sec | Loss 0.1590 | Reco 0.1590 | Nsdr 6.122[0m
[[36m09-24 23:25:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 9/14 | 0.13 it/sec | Loss 0.1592 | Reco 0.1592 | Nsdr 6.308[0m
[[36m09-24 23:25:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 12/14 | 0.14 it/sec | Loss 0.1576 | Reco 0.1576 | Nsdr 6.417[0m
[[36m09-24 23:26:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 3/14 | 10.4 sec/it | Loss 0.1650 | Reco 0.1650 | Nsdr 6.055[0m
[[36m09-24 23:26:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 6/14 | 0.12 it/sec | Loss 0.1573 | Reco 0.1573 | Nsdr 6.211[0m
[[36m09-24 23:26:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 9/14 | 0.13 it/sec | Loss 0.1578 | Reco 0.1578 | Nsdr 6.387[0m
[[36m09-24 23:27:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 12/14 | 0.14 it/sec | Loss 0.1564 | Reco 0.1564 | Nsdr 6.482[0m
[[36m09-24 23:27:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 3/14 | 10.4 sec/it | Loss 0.1660 | Reco 0.1660 | Nsdr 6.024[0m
[[36m09-24 23:28:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 6/14 | 0.12 it/sec | Loss 0.1586 | Reco 0.1586 | Nsdr 6.168[0m
[[36m09-24 23:28:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 9/14 | 0.13 it/sec | Loss 0.1587 | Reco 0.1587 | Nsdr 6.356[0m
[[36m09-24 23:28:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 12/14 | 0.14 it/sec | Loss 0.1572 | Reco 0.1572 | Nsdr 6.460[0m
[[36m09-24 23:29:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 3/14 | 10.5 sec/it | Loss 0.1663 | Reco 0.1663 | Nsdr 6.007[0m
[[36m09-24 23:29:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 6/14 | 0.12 it/sec | Loss 0.1586 | Reco 0.1586 | Nsdr 6.158[0m
[[36m09-24 23:30:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 9/14 | 0.13 it/sec | Loss 0.1587 | Reco 0.1587 | Nsdr 6.350[0m
[[36m09-24 23:30:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 12/14 | 0.14 it/sec | Loss 0.1573 | Reco 0.1573 | Nsdr 6.444[0m
[[36m09-24 23:30:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 15 | Loss=0.1579 | Reco=0.1579 | Nsdr=6.336 | Best=0.1578 | Bname=ema_batch_1 | Penalty=199.7693[0m
[[36m09-24 23:30:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-24 23:30:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-25 00:17:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 16 | 1164/4656 | 0.42 it/sec | Loss 0.0881 | Reco 0.0862 | Grad 0.0833 | Penalty 194.2901[0m
[[36m09-25 01:03:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 16 | 2328/4656 | 0.42 it/sec | Loss 0.0890 | Reco 0.0870 | Grad 0.0849 | Penalty 194.2853[0m
[[36m09-25 01:49:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 16 | 3492/4656 | 0.42 it/sec | Loss 0.0899 | Reco 0.0879 | Grad 0.0852 | Penalty 194.3112[0m
[[36m09-25 02:34:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 16 | Loss=0.0900 | Reco=0.0880 | Grad=0.0850 | Penalty=194.1794[0m
[[36m09-25 02:34:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-25 02:34:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-25 02:35:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 3/14 | 11.5 sec/it | Loss 0.1655 | Reco 0.1655 | Nsdr 5.997[0m
[[36m09-25 02:36:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 6/14 | 0.11 it/sec | Loss 0.1594 | Reco 0.1594 | Nsdr 6.096[0m
[[36m09-25 02:36:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 9/14 | 0.12 it/sec | Loss 0.1608 | Reco 0.1608 | Nsdr 6.225[0m
[[36m09-25 02:36:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 12/14 | 0.13 it/sec | Loss 0.1598 | Reco 0.1598 | Nsdr 6.299[0m
[[36m09-25 02:37:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 3/14 | 11.5 sec/it | Loss 0.1653 | Reco 0.1653 | Nsdr 6.025[0m
[[36m09-25 02:37:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 6/14 | 0.12 it/sec | Loss 0.1576 | Reco 0.1576 | Nsdr 6.190[0m
[[36m09-25 02:38:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 9/14 | 0.12 it/sec | Loss 0.1580 | Reco 0.1580 | Nsdr 6.378[0m
[[36m09-25 02:38:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 12/14 | 0.13 it/sec | Loss 0.1566 | Reco 0.1566 | Nsdr 6.480[0m
[[36m09-25 02:39:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 3/14 | 11.5 sec/it | Loss 0.1660 | Reco 0.1660 | Nsdr 6.011[0m
[[36m09-25 02:39:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 6/14 | 0.11 it/sec | Loss 0.1575 | Reco 0.1575 | Nsdr 6.196[0m
[[36m09-25 02:39:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 9/14 | 0.12 it/sec | Loss 0.1580 | Reco 0.1580 | Nsdr 6.371[0m
[[36m09-25 02:40:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 12/14 | 0.13 it/sec | Loss 0.1564 | Reco 0.1564 | Nsdr 6.476[0m
[[36m09-25 02:41:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 3/14 | 11.1 sec/it | Loss 0.1657 | Reco 0.1657 | Nsdr 6.040[0m
[[36m09-25 02:41:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 6/14 | 0.12 it/sec | Loss 0.1582 | Reco 0.1582 | Nsdr 6.183[0m
[[36m09-25 02:41:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 9/14 | 0.13 it/sec | Loss 0.1584 | Reco 0.1584 | Nsdr 6.376[0m
[[36m09-25 02:41:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 12/14 | 0.14 it/sec | Loss 0.1569 | Reco 0.1569 | Nsdr 6.471[0m
[[36m09-25 02:42:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 3/14 | 11.1 sec/it | Loss 0.1656 | Reco 0.1656 | Nsdr 6.036[0m
[[36m09-25 02:43:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 6/14 | 0.12 it/sec | Loss 0.1581 | Reco 0.1581 | Nsdr 6.186[0m
[[36m09-25 02:43:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 9/14 | 0.13 it/sec | Loss 0.1583 | Reco 0.1583 | Nsdr 6.377[0m
[[36m09-25 02:43:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 12/14 | 0.14 it/sec | Loss 0.1569 | Reco 0.1569 | Nsdr 6.471[0m
[[36m09-25 02:43:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 16 | Loss=0.1580 | Reco=0.1580 | Nsdr=6.327 | Best=0.1578 | Bname=ema_batch_1 | Penalty=198.8032[0m
[[36m09-25 02:43:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-25 02:43:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-25 03:30:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 17 | 1164/4656 | 0.41 it/sec | Loss 0.0911 | Reco 0.0891 | Grad 0.0864 | Penalty 200.7183[0m
[[36m09-25 04:16:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 17 | 2328/4656 | 0.42 it/sec | Loss 0.0901 | Reco 0.0882 | Grad 0.0849 | Penalty 197.7831[0m
[[36m09-25 05:02:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 17 | 3492/4656 | 0.42 it/sec | Loss 0.0901 | Reco 0.0881 | Grad 0.0849 | Penalty 196.7733[0m
[[36m09-25 05:48:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 17 | Loss=0.0900 | Reco=0.0880 | Grad=0.0842 | Penalty=196.0848[0m
[[36m09-25 05:48:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-25 05:48:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-25 05:49:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 3/14 | 10.8 sec/it | Loss 0.1651 | Reco 0.1651 | Nsdr 6.013[0m
[[36m09-25 05:49:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 6/14 | 0.12 it/sec | Loss 0.1589 | Reco 0.1589 | Nsdr 6.114[0m
[[36m09-25 05:50:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 9/14 | 0.13 it/sec | Loss 0.1599 | Reco 0.1599 | Nsdr 6.311[0m
[[36m09-25 05:50:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 12/14 | 0.14 it/sec | Loss 0.1592 | Reco 0.1592 | Nsdr 6.357[0m
[[36m09-25 05:51:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 3/14 | 10.9 sec/it | Loss 0.1636 | Reco 0.1636 | Nsdr 6.113[0m
[[36m09-25 05:51:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 6/14 | 0.12 it/sec | Loss 0.1562 | Reco 0.1562 | Nsdr 6.251[0m
[[36m09-25 05:51:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 9/14 | 0.13 it/sec | Loss 0.1570 | Reco 0.1570 | Nsdr 6.427[0m
[[36m09-25 05:52:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 12/14 | 0.14 it/sec | Loss 0.1559 | Reco 0.1559 | Nsdr 6.511[0m
[[36m09-25 05:52:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 3/14 | 10.7 sec/it | Loss 0.1648 | Reco 0.1648 | Nsdr 6.064[0m
[[36m09-25 05:53:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 6/14 | 0.12 it/sec | Loss 0.1568 | Reco 0.1568 | Nsdr 6.229[0m
[[36m09-25 05:53:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 9/14 | 0.13 it/sec | Loss 0.1572 | Reco 0.1572 | Nsdr 6.417[0m
[[36m09-25 05:53:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 12/14 | 0.14 it/sec | Loss 0.1559 | Reco 0.1559 | Nsdr 6.513[0m
[[36m09-25 05:54:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 3/14 | 10.7 sec/it | Loss 0.1648 | Reco 0.1648 | Nsdr 6.075[0m
[[36m09-25 05:54:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 6/14 | 0.12 it/sec | Loss 0.1575 | Reco 0.1575 | Nsdr 6.210[0m
[[36m09-25 05:55:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 9/14 | 0.13 it/sec | Loss 0.1578 | Reco 0.1578 | Nsdr 6.400[0m
[[36m09-25 05:55:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 12/14 | 0.14 it/sec | Loss 0.1566 | Reco 0.1566 | Nsdr 6.484[0m
[[36m09-25 05:56:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 3/14 | 10.5 sec/it | Loss 0.1652 | Reco 0.1652 | Nsdr 6.058[0m
[[36m09-25 05:56:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 6/14 | 0.12 it/sec | Loss 0.1579 | Reco 0.1579 | Nsdr 6.191[0m
[[36m09-25 05:56:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 9/14 | 0.13 it/sec | Loss 0.1581 | Reco 0.1581 | Nsdr 6.385[0m
[[36m09-25 05:57:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 12/14 | 0.14 it/sec | Loss 0.1569 | Reco 0.1569 | Nsdr 6.470[0m
[[36m09-25 05:57:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 17 | Loss=0.1573 | Reco=0.1573 | Nsdr=6.368 | Best=0.1573 | Bname=ema_batch_0 | Penalty=199.1154[0m
[[36m09-25 05:57:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1573[0m
[[36m09-25 05:57:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-25 05:57:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-25 06:43:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 18 | 1164/4656 | 0.43 it/sec | Loss 0.0909 | Reco 0.0890 | Grad 0.0850 | Penalty 194.4395[0m
[[36m09-25 07:29:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 18 | 2328/4656 | 0.42 it/sec | Loss 0.0902 | Reco 0.0883 | Grad 0.0830 | Penalty 194.1528[0m
[[36m09-25 08:15:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 18 | 3492/4656 | 0.42 it/sec | Loss 0.0901 | Reco 0.0881 | Grad 0.0834 | Penalty 193.9287[0m
[[36m09-25 09:01:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 18 | Loss=0.0901 | Reco=0.0882 | Grad=0.0841 | Penalty=194.0368[0m
[[36m09-25 09:01:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-25 09:01:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-25 09:02:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 3/14 | 10.7 sec/it | Loss 0.1689 | Reco 0.1689 | Nsdr 5.851[0m
[[36m09-25 09:02:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 6/14 | 0.12 it/sec | Loss 0.1613 | Reco 0.1613 | Nsdr 6.007[0m
[[36m09-25 09:02:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 9/14 | 0.13 it/sec | Loss 0.1604 | Reco 0.1604 | Nsdr 6.268[0m
[[36m09-25 09:03:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 12/14 | 0.14 it/sec | Loss 0.1595 | Reco 0.1595 | Nsdr 6.327[0m
[[36m09-25 09:04:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 3/14 | 10.7 sec/it | Loss 0.1654 | Reco 0.1654 | Nsdr 6.020[0m
[[36m09-25 09:04:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 6/14 | 0.12 it/sec | Loss 0.1577 | Reco 0.1577 | Nsdr 6.172[0m
[[36m09-25 09:04:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 9/14 | 0.13 it/sec | Loss 0.1580 | Reco 0.1580 | Nsdr 6.371[0m
[[36m09-25 09:04:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 12/14 | 0.14 it/sec | Loss 0.1570 | Reco 0.1570 | Nsdr 6.442[0m
[[36m09-25 09:05:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 3/14 | 10.5 sec/it | Loss 0.1648 | Reco 0.1648 | Nsdr 6.066[0m
[[36m09-25 09:06:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 6/14 | 0.12 it/sec | Loss 0.1567 | Reco 0.1567 | Nsdr 6.231[0m
[[36m09-25 09:06:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 9/14 | 0.13 it/sec | Loss 0.1571 | Reco 0.1571 | Nsdr 6.421[0m
[[36m09-25 09:06:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 12/14 | 0.14 it/sec | Loss 0.1560 | Reco 0.1560 | Nsdr 6.502[0m
[[36m09-25 09:07:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 3/14 | 10.4 sec/it | Loss 0.1653 | Reco 0.1653 | Nsdr 6.050[0m
[[36m09-25 09:07:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 6/14 | 0.12 it/sec | Loss 0.1578 | Reco 0.1578 | Nsdr 6.192[0m
[[36m09-25 09:08:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 9/14 | 0.13 it/sec | Loss 0.1579 | Reco 0.1579 | Nsdr 6.397[0m
[[36m09-25 09:08:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 12/14 | 0.14 it/sec | Loss 0.1566 | Reco 0.1566 | Nsdr 6.486[0m
[[36m09-25 09:09:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 3/14 | 10.8 sec/it | Loss 0.1662 | Reco 0.1662 | Nsdr 6.018[0m
[[36m09-25 09:09:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 6/14 | 0.12 it/sec | Loss 0.1584 | Reco 0.1584 | Nsdr 6.175[0m
[[36m09-25 09:09:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 9/14 | 0.13 it/sec | Loss 0.1583 | Reco 0.1583 | Nsdr 6.383[0m
[[36m09-25 09:10:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 12/14 | 0.14 it/sec | Loss 0.1569 | Reco 0.1569 | Nsdr 6.473[0m
[[36m09-25 09:10:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 18 | Loss=0.1574 | Reco=0.1574 | Nsdr=6.357 | Best=0.1573 | Bname=ema_batch_1 | Penalty=198.7619[0m
[[36m09-25 09:10:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-25 09:10:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-25 09:55:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 19 | 1164/4656 | 0.43 it/sec | Loss 0.0905 | Reco 0.0885 | Grad 0.0834 | Penalty 193.8313[0m
[[36m09-25 10:41:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 19 | 2328/4656 | 0.43 it/sec | Loss 0.0907 | Reco 0.0888 | Grad 0.0840 | Penalty 193.5199[0m
[[36m09-25 11:27:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 19 | 3492/4656 | 0.43 it/sec | Loss 0.0901 | Reco 0.0882 | Grad 0.0838 | Penalty 193.5783[0m
[[36m09-25 12:12:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 19 | Loss=0.0902 | Reco=0.0883 | Grad=0.0841 | Penalty=193.5822[0m
[[36m09-25 12:12:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-25 12:12:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-25 12:13:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 3/14 | 11.1 sec/it | Loss 0.1704 | Reco 0.1704 | Nsdr 5.825[0m
[[36m09-25 12:13:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 6/14 | 0.12 it/sec | Loss 0.1633 | Reco 0.1633 | Nsdr 5.941[0m
[[36m09-25 12:13:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 9/14 | 0.13 it/sec | Loss 0.1626 | Reco 0.1626 | Nsdr 6.181[0m
[[36m09-25 12:14:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 12/14 | 0.14 it/sec | Loss 0.1608 | Reco 0.1608 | Nsdr 6.299[0m
[[36m09-25 12:15:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 3/14 | 10.8 sec/it | Loss 0.1649 | Reco 0.1649 | Nsdr 6.054[0m
[[36m09-25 12:15:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 6/14 | 0.12 it/sec | Loss 0.1576 | Reco 0.1576 | Nsdr 6.183[0m
[[36m09-25 12:15:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 9/14 | 0.13 it/sec | Loss 0.1579 | Reco 0.1579 | Nsdr 6.389[0m
[[36m09-25 12:15:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 12/14 | 0.14 it/sec | Loss 0.1567 | Reco 0.1567 | Nsdr 6.473[0m
[[36m09-25 12:16:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 3/14 | 10.4 sec/it | Loss 0.1651 | Reco 0.1651 | Nsdr 6.050[0m
[[36m09-25 12:17:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 6/14 | 0.12 it/sec | Loss 0.1569 | Reco 0.1569 | Nsdr 6.211[0m
[[36m09-25 12:17:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 9/14 | 0.13 it/sec | Loss 0.1573 | Reco 0.1573 | Nsdr 6.402[0m
[[36m09-25 12:17:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 12/14 | 0.14 it/sec | Loss 0.1560 | Reco 0.1560 | Nsdr 6.497[0m
[[36m09-25 12:18:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 3/14 | 10.4 sec/it | Loss 0.1656 | Reco 0.1656 | Nsdr 6.047[0m
[[36m09-25 12:18:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 6/14 | 0.13 it/sec | Loss 0.1579 | Reco 0.1579 | Nsdr 6.197[0m
[[36m09-25 12:19:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 9/14 | 0.13 it/sec | Loss 0.1580 | Reco 0.1580 | Nsdr 6.397[0m
[[36m09-25 12:19:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 12/14 | 0.14 it/sec | Loss 0.1566 | Reco 0.1566 | Nsdr 6.487[0m
[[36m09-25 12:20:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 3/14 | 10.5 sec/it | Loss 0.1656 | Reco 0.1656 | Nsdr 6.046[0m
[[36m09-25 12:20:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 6/14 | 0.12 it/sec | Loss 0.1580 | Reco 0.1580 | Nsdr 6.191[0m
[[36m09-25 12:20:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 9/14 | 0.13 it/sec | Loss 0.1581 | Reco 0.1581 | Nsdr 6.391[0m
[[36m09-25 12:21:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 12/14 | 0.14 it/sec | Loss 0.1567 | Reco 0.1567 | Nsdr 6.484[0m
[[36m09-25 12:21:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 19 | Loss=0.1574 | Reco=0.1574 | Nsdr=6.354 | Best=0.1573 | Bname=ema_batch_1 | Penalty=198.7581[0m
[[36m09-25 12:21:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-25 12:21:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-25 13:07:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 20 | 1164/4656 | 0.42 it/sec | Loss 0.0912 | Reco 0.0893 | Grad 0.0845 | Penalty 193.0517[0m
[[36m09-25 13:52:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 20 | 2328/4656 | 0.42 it/sec | Loss 0.0906 | Reco 0.0887 | Grad 0.0846 | Penalty 193.1907[0m
[[36m09-25 14:38:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 20 | 3492/4656 | 0.42 it/sec | Loss 0.0902 | Reco 0.0883 | Grad 0.0841 | Penalty 193.1825[0m
[[36m09-25 15:24:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 20 | Loss=0.0900 | Reco=0.0880 | Grad=0.0841 | Penalty=193.2521[0m
[[36m09-25 15:24:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-25 15:24:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-25 15:24:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 3/14 | 10.5 sec/it | Loss 0.1691 | Reco 0.1691 | Nsdr 5.877[0m
[[36m09-25 15:24:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 6/14 | 0.12 it/sec | Loss 0.1613 | Reco 0.1613 | Nsdr 6.013[0m
[[36m09-25 15:25:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 9/14 | 0.13 it/sec | Loss 0.1622 | Reco 0.1622 | Nsdr 6.157[0m
[[36m09-25 15:25:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 12/14 | 0.14 it/sec | Loss 0.1603 | Reco 0.1603 | Nsdr 6.281[0m
[[36m09-25 15:26:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 3/14 | 10.7 sec/it | Loss 0.1665 | Reco 0.1665 | Nsdr 5.974[0m
[[36m09-25 15:26:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 6/14 | 0.12 it/sec | Loss 0.1583 | Reco 0.1583 | Nsdr 6.156[0m
[[36m09-25 15:27:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 9/14 | 0.13 it/sec | Loss 0.1587 | Reco 0.1587 | Nsdr 6.340[0m
[[36m09-25 15:27:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 12/14 | 0.14 it/sec | Loss 0.1569 | Reco 0.1569 | Nsdr 6.454[0m
[[36m09-25 15:28:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 3/14 | 10.7 sec/it | Loss 0.1652 | Reco 0.1652 | Nsdr 6.046[0m
[[36m09-25 15:28:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 6/14 | 0.12 it/sec | Loss 0.1572 | Reco 0.1572 | Nsdr 6.209[0m
[[36m09-25 15:28:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 9/14 | 0.13 it/sec | Loss 0.1574 | Reco 0.1574 | Nsdr 6.406[0m
[[36m09-25 15:29:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 12/14 | 0.14 it/sec | Loss 0.1560 | Reco 0.1560 | Nsdr 6.508[0m
[[36m09-25 15:29:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 3/14 | 10.5 sec/it | Loss 0.1651 | Reco 0.1651 | Nsdr 6.069[0m
[[36m09-25 15:30:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 6/14 | 0.12 it/sec | Loss 0.1576 | Reco 0.1576 | Nsdr 6.215[0m
[[36m09-25 15:30:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 9/14 | 0.13 it/sec | Loss 0.1578 | Reco 0.1578 | Nsdr 6.405[0m
[[36m09-25 15:30:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 12/14 | 0.14 it/sec | Loss 0.1564 | Reco 0.1564 | Nsdr 6.495[0m
[[36m09-25 15:31:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 3/14 | 10.5 sec/it | Loss 0.1653 | Reco 0.1653 | Nsdr 6.056[0m
[[36m09-25 15:31:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 6/14 | 0.12 it/sec | Loss 0.1578 | Reco 0.1578 | Nsdr 6.196[0m
[[36m09-25 15:32:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 9/14 | 0.13 it/sec | Loss 0.1580 | Reco 0.1580 | Nsdr 6.390[0m
[[36m09-25 15:32:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 12/14 | 0.14 it/sec | Loss 0.1566 | Reco 0.1566 | Nsdr 6.483[0m
[[36m09-25 15:32:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 20 | Loss=0.1573 | Reco=0.1573 | Nsdr=6.365 | Best=0.1573 | Bname=ema_batch_1 | Penalty=197.8172[0m
[[36m09-25 15:32:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-25 15:32:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Evaluating on the test set...[0m
[[36m09-25 15:33:15[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval | 2/10 | 12.8 sec/it[0m
[[36m09-25 15:33:43[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval | 4/10 | 13.1 sec/it[0m
[[36m09-25 15:34:14[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval | 6/10 | 13.8 sec/it[0m
[[36m09-25 15:34:45[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval | 8/10 | 14.2 sec/it[0m
[[36m09-25 15:46:31[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval (BSS) | 2/10 | 231.4 sec/it[0m
[[36m09-25 15:52:36[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval (BSS) | 4/10 | 211.8 sec/it[0m
[[36m09-25 16:00:04[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval (BSS) | 6/10 | 215.3 sec/it[0m
[[36m09-25 16:08:09[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval (BSS) | 8/10 | 221.4 sec/it[0m
[[36m09-25 16:10:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTest Summary | Epoch 20 | Sdr=4.915 | Nsdr=5.386 | Sdr_drums=6.956 | Nsdr_drums=6.996 | Sdr_bass=4.164 | Nsdr_bass=4.644 | Sdr_other=2.472 | Nsdr_other=3.090 | Sdr_vocals=6.068 | Nsdr_vocals=6.813[0m
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mParser[0m Injecting argv ['hdemucs.norm_starts=999', 'hdemucs.cac=False', 'test.split=True', 'valid_apply=True', 'model=hdemucs', 'hdemucs.dconv_lstm=4', 'ema.epoch=[0.9, 0.95]', 'ema.batch=[0.9995, 0.9999]', 'seed=42', 'hdemucs.hybrid_old=True', 'svd=base', 'svd.penalty=1e-05', 'svd.dim=100', 'svd.convtr=True', 'optim.lr=0.0005', 'batch_size=4', 'dset.segment=8', 'hdemucs.channels=24', 'test.workers=', 'continue_from=a68eaf9b', 'epochs=20'] from sig 538354e6
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mExecutor:[0m Starting 1 worker processes for DDP.
[1mExecutor:[0m All workers completed successfully
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:228: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  return hydra.main(
[[36m09-25 16:37:27[0m][[34mdemucs.train[0m][[32mINFO[0m] - For logs, checkpoints and samples check /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/10d3d91d[0m
[[36m09-25 16:37:27[0m][[34mdora.distrib[0m][[32mINFO[0m] - world_size is 1, skipping init.[0m
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
GlobalSelfAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
GlobalCrossAttn: AttentionLayer(
  (inner_attention): PerformerAttention(
    (kernel_fn): ReLU()
  )
  (query_projection): Linear(in_features=100, out_features=240, bias=True)
  (key_projection): Linear(in_features=100, out_features=240, bias=True)
  (value_projection): Linear(in_features=100, out_features=240, bias=True)
  (out_projection): Linear(in_features=240, out_features=100, bias=True)
  (dropout_qkv): Dropout(p=0.0, inplace=False)
)
LocalSelfAttn: None
LocalCrossAttn: None
Using Embedding: temporal
Time Emb Dim: 6
Space Embedding: True
Time Embedding: True
Val Embedding: True
Given Embedding: True
Null Value: None
Pad Value: None
Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0
D_Model = 100
/home/paperspace/.local/lib/python3.8/site-packages/musdb/configs/mus.yaml
[[36m09-25 16:37:36[0m][[34mdemucs.train[0m][[32mINFO[0m] - train/valid set size: 18626 14[0m
Hi
[[36m09-25 16:37:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Loading from /home/paperspace/Source_Sep_Rea/Facebook_Transformers/demucs-main/demucs-main/outputs/xps/5e8ce54e/checkpoint.th[0m
[[36m09-25 16:37:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-25 16:37:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
/home/paperspace/.local/lib/python3.8/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
/home/paperspace/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
[[36m09-25 17:23:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 1 | 1164/4656 | 0.42 it/sec | Loss 0.0890 | Reco 0.0871 | Grad 0.0796 | Penalty 190.5043[0m
[[36m09-25 18:09:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 1 | 2328/4656 | 0.42 it/sec | Loss 0.0889 | Reco 0.0870 | Grad 0.0792 | Penalty 190.9272[0m
[[36m09-25 18:54:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 1 | 3492/4656 | 0.42 it/sec | Loss 0.0892 | Reco 0.0873 | Grad 0.0795 | Penalty 191.1780[0m
[[36m09-25 19:40:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 1 | Loss=0.0892 | Reco=0.0873 | Grad=0.0798 | Penalty=191.4521[0m
[[36m09-25 19:40:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-25 19:40:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-25 19:41:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 3/14 | 10.8 sec/it | Loss 0.1679 | Reco 0.1679 | Nsdr 5.922[0m
[[36m09-25 19:41:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 6/14 | 0.12 it/sec | Loss 0.1595 | Reco 0.1595 | Nsdr 6.074[0m
[[36m09-25 19:41:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 9/14 | 0.13 it/sec | Loss 0.1598 | Reco 0.1598 | Nsdr 6.280[0m
[[36m09-25 19:42:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 12/14 | 0.14 it/sec | Loss 0.1589 | Reco 0.1589 | Nsdr 6.335[0m
[[36m09-25 19:42:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 3/14 | 10.6 sec/it | Loss 0.1651 | Reco 0.1651 | Nsdr 6.046[0m
[[36m09-25 19:43:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 6/14 | 0.12 it/sec | Loss 0.1575 | Reco 0.1575 | Nsdr 6.200[0m
[[36m09-25 19:43:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 9/14 | 0.13 it/sec | Loss 0.1577 | Reco 0.1577 | Nsdr 6.402[0m
[[36m09-25 19:43:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 12/14 | 0.14 it/sec | Loss 0.1564 | Reco 0.1564 | Nsdr 6.495[0m
[[36m09-25 19:44:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 3/14 | 11.0 sec/it | Loss 0.1644 | Reco 0.1644 | Nsdr 6.072[0m
[[36m09-25 19:44:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 6/14 | 0.12 it/sec | Loss 0.1570 | Reco 0.1570 | Nsdr 6.215[0m
[[36m09-25 19:45:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 9/14 | 0.13 it/sec | Loss 0.1573 | Reco 0.1573 | Nsdr 6.418[0m
[[36m09-25 19:45:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 12/14 | 0.14 it/sec | Loss 0.1561 | Reco 0.1561 | Nsdr 6.506[0m
[[36m09-25 19:46:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 3/14 | 10.7 sec/it | Loss 0.1677 | Reco 0.1677 | Nsdr 5.927[0m
[[36m09-25 19:46:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 6/14 | 0.12 it/sec | Loss 0.1594 | Reco 0.1594 | Nsdr 6.075[0m
[[36m09-25 19:47:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 9/14 | 0.13 it/sec | Loss 0.1597 | Reco 0.1597 | Nsdr 6.284[0m
[[36m09-25 19:47:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 12/14 | 0.14 it/sec | Loss 0.1588 | Reco 0.1588 | Nsdr 6.338[0m
[[36m09-25 19:48:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 3/14 | 11.0 sec/it | Loss 0.1678 | Reco 0.1678 | Nsdr 5.926[0m
[[36m09-25 19:48:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 6/14 | 0.12 it/sec | Loss 0.1594 | Reco 0.1594 | Nsdr 6.083[0m
[[36m09-25 19:48:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 9/14 | 0.13 it/sec | Loss 0.1597 | Reco 0.1597 | Nsdr 6.287[0m
[[36m09-25 19:49:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 1 | 12/14 | 0.14 it/sec | Loss 0.1588 | Reco 0.1588 | Nsdr 6.342[0m
[[36m09-25 19:49:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 1 | Loss=0.1576 | Reco=0.1576 | Nsdr=6.356 | Best=0.1576 | Bname=ema_batch_1 | Penalty=196.8898[0m
[[36m09-25 19:49:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1576[0m
[[36m09-25 19:49:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-25 19:49:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-25 20:35:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 2 | 1164/4656 | 0.42 it/sec | Loss 0.0896 | Reco 0.0876 | Grad 0.0780 | Penalty 191.7069[0m
[[36m09-25 21:20:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 2 | 2328/4656 | 0.42 it/sec | Loss 0.0892 | Reco 0.0873 | Grad 0.0791 | Penalty 191.9330[0m
[[36m09-25 22:06:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 2 | 3492/4656 | 0.42 it/sec | Loss 0.0895 | Reco 0.0876 | Grad 0.0804 | Penalty 192.3051[0m
[[36m09-25 22:51:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 2 | Loss=0.0896 | Reco=0.0877 | Grad=0.0803 | Penalty=192.2909[0m
[[36m09-25 22:51:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-25 22:51:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-25 22:52:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 3/14 | 11.2 sec/it | Loss 0.1691 | Reco 0.1691 | Nsdr 5.902[0m
[[36m09-25 22:52:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 6/14 | 0.12 it/sec | Loss 0.1590 | Reco 0.1590 | Nsdr 6.121[0m
[[36m09-25 22:53:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 9/14 | 0.13 it/sec | Loss 0.1598 | Reco 0.1598 | Nsdr 6.272[0m
[[36m09-25 22:53:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 12/14 | 0.14 it/sec | Loss 0.1591 | Reco 0.1591 | Nsdr 6.316[0m
[[36m09-25 22:54:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 3/14 | 10.7 sec/it | Loss 0.1635 | Reco 0.1635 | Nsdr 6.128[0m
[[36m09-25 22:54:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 6/14 | 0.12 it/sec | Loss 0.1561 | Reco 0.1561 | Nsdr 6.270[0m
[[36m09-25 22:54:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 9/14 | 0.13 it/sec | Loss 0.1566 | Reco 0.1566 | Nsdr 6.463[0m
[[36m09-25 22:55:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 12/14 | 0.14 it/sec | Loss 0.1554 | Reco 0.1554 | Nsdr 6.550[0m
[[36m09-25 22:56:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 3/14 | 11.3 sec/it | Loss 0.1634 | Reco 0.1634 | Nsdr 6.130[0m
[[36m09-25 22:56:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 6/14 | 0.12 it/sec | Loss 0.1563 | Reco 0.1563 | Nsdr 6.256[0m
[[36m09-25 22:56:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 9/14 | 0.12 it/sec | Loss 0.1568 | Reco 0.1568 | Nsdr 6.453[0m
[[36m09-25 22:56:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 12/14 | 0.14 it/sec | Loss 0.1556 | Reco 0.1556 | Nsdr 6.538[0m
[[36m09-25 22:57:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 3/14 | 11.0 sec/it | Loss 0.1663 | Reco 0.1663 | Nsdr 6.016[0m
[[36m09-25 22:58:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 6/14 | 0.12 it/sec | Loss 0.1574 | Reco 0.1574 | Nsdr 6.202[0m
[[36m09-25 22:58:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 9/14 | 0.13 it/sec | Loss 0.1576 | Reco 0.1576 | Nsdr 6.399[0m
[[36m09-25 22:58:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 12/14 | 0.14 it/sec | Loss 0.1568 | Reco 0.1568 | Nsdr 6.448[0m
[[36m09-25 22:59:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 3/14 | 10.8 sec/it | Loss 0.1664 | Reco 0.1664 | Nsdr 6.016[0m
[[36m09-25 22:59:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 6/14 | 0.12 it/sec | Loss 0.1574 | Reco 0.1574 | Nsdr 6.195[0m
[[36m09-25 23:00:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 9/14 | 0.13 it/sec | Loss 0.1577 | Reco 0.1577 | Nsdr 6.388[0m
[[36m09-25 23:00:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 2 | 12/14 | 0.14 it/sec | Loss 0.1569 | Reco 0.1569 | Nsdr 6.440[0m
[[36m09-25 23:00:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 2 | Loss=0.1570 | Reco=0.1570 | Nsdr=6.392 | Best=0.1570 | Bname=ema_batch_0 | Penalty=196.3713[0m
[[36m09-25 23:00:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1570[0m
[[36m09-25 23:00:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-25 23:00:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-25 23:46:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 3 | 1164/4656 | 0.42 it/sec | Loss 0.0884 | Reco 0.0865 | Grad 0.0789 | Penalty 192.5410[0m
[[36m09-26 00:32:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 3 | 2328/4656 | 0.42 it/sec | Loss 0.0890 | Reco 0.0871 | Grad 0.0798 | Penalty 191.7355[0m
[[36m09-26 01:17:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 3 | 3492/4656 | 0.42 it/sec | Loss 0.0892 | Reco 0.0873 | Grad 0.0796 | Penalty 191.3153[0m
[[36m09-26 02:03:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 3 | Loss=0.0889 | Reco=0.0870 | Grad=0.0795 | Penalty=191.1415[0m
[[36m09-26 02:03:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-26 02:03:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-26 02:04:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 3/14 | 11.0 sec/it | Loss 0.1695 | Reco 0.1695 | Nsdr 5.850[0m
[[36m09-26 02:04:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 6/14 | 0.12 it/sec | Loss 0.1626 | Reco 0.1626 | Nsdr 5.998[0m
[[36m09-26 02:04:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 9/14 | 0.13 it/sec | Loss 0.1628 | Reco 0.1628 | Nsdr 6.182[0m
[[36m09-26 02:05:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 12/14 | 0.14 it/sec | Loss 0.1614 | Reco 0.1614 | Nsdr 6.270[0m
[[36m09-26 02:05:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 3/14 | 11.1 sec/it | Loss 0.1643 | Reco 0.1643 | Nsdr 6.086[0m
[[36m09-26 02:06:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 6/14 | 0.12 it/sec | Loss 0.1568 | Reco 0.1568 | Nsdr 6.235[0m
[[36m09-26 02:06:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 9/14 | 0.13 it/sec | Loss 0.1576 | Reco 0.1576 | Nsdr 6.406[0m
[[36m09-26 02:06:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 12/14 | 0.14 it/sec | Loss 0.1563 | Reco 0.1563 | Nsdr 6.496[0m
[[36m09-26 02:07:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 3/14 | 10.8 sec/it | Loss 0.1641 | Reco 0.1641 | Nsdr 6.110[0m
[[36m09-26 02:07:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 6/14 | 0.12 it/sec | Loss 0.1566 | Reco 0.1566 | Nsdr 6.256[0m
[[36m09-26 02:08:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 9/14 | 0.13 it/sec | Loss 0.1569 | Reco 0.1569 | Nsdr 6.450[0m
[[36m09-26 02:08:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 12/14 | 0.14 it/sec | Loss 0.1556 | Reco 0.1556 | Nsdr 6.542[0m
[[36m09-26 02:09:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 3/14 | 11.0 sec/it | Loss 0.1659 | Reco 0.1659 | Nsdr 6.027[0m
[[36m09-26 02:09:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 6/14 | 0.12 it/sec | Loss 0.1575 | Reco 0.1575 | Nsdr 6.207[0m
[[36m09-26 02:09:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 9/14 | 0.13 it/sec | Loss 0.1579 | Reco 0.1579 | Nsdr 6.386[0m
[[36m09-26 02:10:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 12/14 | 0.14 it/sec | Loss 0.1570 | Reco 0.1570 | Nsdr 6.452[0m
[[36m09-26 02:11:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 3/14 | 10.7 sec/it | Loss 0.1656 | Reco 0.1656 | Nsdr 6.049[0m
[[36m09-26 02:11:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 6/14 | 0.12 it/sec | Loss 0.1578 | Reco 0.1578 | Nsdr 6.203[0m
[[36m09-26 02:11:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 9/14 | 0.13 it/sec | Loss 0.1580 | Reco 0.1580 | Nsdr 6.390[0m
[[36m09-26 02:11:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 3 | 12/14 | 0.14 it/sec | Loss 0.1570 | Reco 0.1570 | Nsdr 6.458[0m
[[36m09-26 02:12:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 3 | Loss=0.1572 | Reco=0.1572 | Nsdr=6.387 | Best=0.1570 | Bname=ema_batch_1 | Penalty=195.0111[0m
[[36m09-26 02:12:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-26 02:12:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-26 02:58:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 4 | 1164/4656 | 0.42 it/sec | Loss 0.0895 | Reco 0.0876 | Grad 0.0817 | Penalty 190.6695[0m
[[36m09-26 03:43:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 4 | 2328/4656 | 0.42 it/sec | Loss 0.0896 | Reco 0.0877 | Grad 0.0814 | Penalty 190.5558[0m
[[36m09-26 04:29:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 4 | 3492/4656 | 0.42 it/sec | Loss 0.0899 | Reco 0.0880 | Grad 0.0818 | Penalty 190.9388[0m
[[36m09-26 05:15:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 4 | Loss=0.0895 | Reco=0.0876 | Grad=0.0815 | Penalty=190.9106[0m
[[36m09-26 05:15:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-26 05:15:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-26 05:15:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 3/14 | 11.0 sec/it | Loss 0.1697 | Reco 0.1697 | Nsdr 5.840[0m
[[36m09-26 05:16:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 6/14 | 0.12 it/sec | Loss 0.1612 | Reco 0.1612 | Nsdr 6.043[0m
[[36m09-26 05:16:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 9/14 | 0.13 it/sec | Loss 0.1621 | Reco 0.1621 | Nsdr 6.223[0m
[[36m09-26 05:16:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 12/14 | 0.14 it/sec | Loss 0.1603 | Reco 0.1603 | Nsdr 6.332[0m
[[36m09-26 05:17:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 3/14 | 11.2 sec/it | Loss 0.1650 | Reco 0.1650 | Nsdr 6.047[0m
[[36m09-26 05:17:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 6/14 | 0.12 it/sec | Loss 0.1568 | Reco 0.1568 | Nsdr 6.225[0m
[[36m09-26 05:18:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 9/14 | 0.12 it/sec | Loss 0.1573 | Reco 0.1573 | Nsdr 6.408[0m
[[36m09-26 05:18:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 12/14 | 0.13 it/sec | Loss 0.1558 | Reco 0.1558 | Nsdr 6.512[0m
[[36m09-26 05:19:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 3/14 | 10.9 sec/it | Loss 0.1635 | Reco 0.1635 | Nsdr 6.125[0m
[[36m09-26 05:19:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 6/14 | 0.12 it/sec | Loss 0.1562 | Reco 0.1562 | Nsdr 6.267[0m
[[36m09-26 05:19:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 9/14 | 0.13 it/sec | Loss 0.1567 | Reco 0.1567 | Nsdr 6.451[0m
[[36m09-26 05:20:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 12/14 | 0.14 it/sec | Loss 0.1554 | Reco 0.1554 | Nsdr 6.548[0m
[[36m09-26 05:21:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 3/14 | 11.0 sec/it | Loss 0.1655 | Reco 0.1655 | Nsdr 6.047[0m
[[36m09-26 05:21:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 6/14 | 0.12 it/sec | Loss 0.1575 | Reco 0.1575 | Nsdr 6.212[0m
[[36m09-26 05:21:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 9/14 | 0.13 it/sec | Loss 0.1579 | Reco 0.1579 | Nsdr 6.400[0m
[[36m09-26 05:21:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 12/14 | 0.14 it/sec | Loss 0.1567 | Reco 0.1567 | Nsdr 6.478[0m
[[36m09-26 05:22:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 3/14 | 10.7 sec/it | Loss 0.1655 | Reco 0.1655 | Nsdr 6.049[0m
[[36m09-26 05:23:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 6/14 | 0.12 it/sec | Loss 0.1575 | Reco 0.1575 | Nsdr 6.216[0m
[[36m09-26 05:23:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 9/14 | 0.13 it/sec | Loss 0.1579 | Reco 0.1579 | Nsdr 6.402[0m
[[36m09-26 05:23:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 4 | 12/14 | 0.14 it/sec | Loss 0.1567 | Reco 0.1567 | Nsdr 6.481[0m
[[36m09-26 05:23:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 4 | Loss=0.1570 | Reco=0.1570 | Nsdr=6.391 | Best=0.1570 | Bname=ema_batch_1 | Penalty=195.2295[0m
[[36m09-26 05:23:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-26 05:23:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-26 06:09:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 5 | 1164/4656 | 0.42 it/sec | Loss 0.0899 | Reco 0.0880 | Grad 0.0837 | Penalty 190.8156[0m
[[36m09-26 06:55:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 5 | 2328/4656 | 0.42 it/sec | Loss 0.0899 | Reco 0.0880 | Grad 0.0830 | Penalty 190.6919[0m
[[36m09-26 07:41:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 5 | 3492/4656 | 0.42 it/sec | Loss 0.0892 | Reco 0.0873 | Grad 0.0815 | Penalty 190.5119[0m
[[36m09-26 08:27:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 5 | Loss=0.0893 | Reco=0.0874 | Grad=0.0815 | Penalty=190.5056[0m
[[36m09-26 08:27:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-26 08:27:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-26 08:27:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 3/14 | 10.6 sec/it | Loss 0.1691 | Reco 0.1691 | Nsdr 5.812[0m
[[36m09-26 08:27:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 6/14 | 0.12 it/sec | Loss 0.1595 | Reco 0.1595 | Nsdr 6.074[0m
[[36m09-26 08:28:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 9/14 | 0.13 it/sec | Loss 0.1600 | Reco 0.1600 | Nsdr 6.256[0m
[[36m09-26 08:28:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 12/14 | 0.14 it/sec | Loss 0.1585 | Reco 0.1585 | Nsdr 6.356[0m
[[36m09-26 08:29:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 3/14 | 10.6 sec/it | Loss 0.1660 | Reco 0.1660 | Nsdr 5.998[0m
[[36m09-26 08:29:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 6/14 | 0.12 it/sec | Loss 0.1578 | Reco 0.1578 | Nsdr 6.180[0m
[[36m09-26 08:30:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 9/14 | 0.13 it/sec | Loss 0.1584 | Reco 0.1584 | Nsdr 6.351[0m
[[36m09-26 08:30:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 12/14 | 0.14 it/sec | Loss 0.1569 | Reco 0.1569 | Nsdr 6.453[0m
[[36m09-26 08:31:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 3/14 | 11.1 sec/it | Loss 0.1634 | Reco 0.1634 | Nsdr 6.127[0m
[[36m09-26 08:31:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 6/14 | 0.12 it/sec | Loss 0.1561 | Reco 0.1561 | Nsdr 6.270[0m
[[36m09-26 08:31:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 9/14 | 0.13 it/sec | Loss 0.1567 | Reco 0.1567 | Nsdr 6.447[0m
[[36m09-26 08:32:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 12/14 | 0.14 it/sec | Loss 0.1554 | Reco 0.1554 | Nsdr 6.538[0m
[[36m09-26 08:32:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 3/14 | 10.7 sec/it | Loss 0.1646 | Reco 0.1646 | Nsdr 6.078[0m
[[36m09-26 08:33:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 6/14 | 0.12 it/sec | Loss 0.1568 | Reco 0.1568 | Nsdr 6.246[0m
[[36m09-26 08:33:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 9/14 | 0.13 it/sec | Loss 0.1573 | Reco 0.1573 | Nsdr 6.427[0m
[[36m09-26 08:33:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 12/14 | 0.14 it/sec | Loss 0.1560 | Reco 0.1560 | Nsdr 6.510[0m
[[36m09-26 08:34:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 3/14 | 10.6 sec/it | Loss 0.1644 | Reco 0.1644 | Nsdr 6.085[0m
[[36m09-26 08:34:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 6/14 | 0.12 it/sec | Loss 0.1566 | Reco 0.1566 | Nsdr 6.252[0m
[[36m09-26 08:35:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 9/14 | 0.13 it/sec | Loss 0.1572 | Reco 0.1572 | Nsdr 6.430[0m
[[36m09-26 08:35:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 5 | 12/14 | 0.14 it/sec | Loss 0.1560 | Reco 0.1560 | Nsdr 6.507[0m
[[36m09-26 08:35:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 5 | Loss=0.1569 | Reco=0.1569 | Nsdr=6.388 | Best=0.1569 | Bname=ema_batch_1 | Penalty=195.8961[0m
[[36m09-26 08:35:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1569[0m
[[36m09-26 08:35:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-26 08:35:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-26 09:21:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 6 | 1164/4656 | 0.42 it/sec | Loss 0.0901 | Reco 0.0881 | Grad 0.0798 | Penalty 190.4858[0m
[[36m09-26 10:07:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 6 | 2328/4656 | 0.42 it/sec | Loss 0.0894 | Reco 0.0875 | Grad 0.0809 | Penalty 190.3048[0m
[[36m09-26 10:53:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 6 | 3492/4656 | 0.42 it/sec | Loss 0.0892 | Reco 0.0873 | Grad 0.0817 | Penalty 190.2374[0m
[[36m09-26 11:38:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 6 | Loss=0.0890 | Reco=0.0871 | Grad=0.0817 | Penalty=190.2618[0m
[[36m09-26 11:38:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-26 11:38:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-26 11:39:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 3/14 | 10.8 sec/it | Loss 0.1675 | Reco 0.1675 | Nsdr 5.900[0m
[[36m09-26 11:39:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 6/14 | 0.12 it/sec | Loss 0.1587 | Reco 0.1587 | Nsdr 6.081[0m
[[36m09-26 11:40:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 9/14 | 0.13 it/sec | Loss 0.1591 | Reco 0.1591 | Nsdr 6.282[0m
[[36m09-26 11:40:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 12/14 | 0.14 it/sec | Loss 0.1583 | Reco 0.1583 | Nsdr 6.348[0m
[[36m09-26 11:41:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 3/14 | 11.2 sec/it | Loss 0.1637 | Reco 0.1637 | Nsdr 6.097[0m
[[36m09-26 11:41:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 6/14 | 0.12 it/sec | Loss 0.1563 | Reco 0.1563 | Nsdr 6.244[0m
[[36m09-26 11:41:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 9/14 | 0.13 it/sec | Loss 0.1569 | Reco 0.1569 | Nsdr 6.418[0m
[[36m09-26 11:42:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 12/14 | 0.14 it/sec | Loss 0.1560 | Reco 0.1560 | Nsdr 6.488[0m
[[36m09-26 11:42:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 3/14 | 11.1 sec/it | Loss 0.1635 | Reco 0.1635 | Nsdr 6.114[0m
[[36m09-26 11:43:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 6/14 | 0.12 it/sec | Loss 0.1561 | Reco 0.1561 | Nsdr 6.265[0m
[[36m09-26 11:43:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 9/14 | 0.13 it/sec | Loss 0.1568 | Reco 0.1568 | Nsdr 6.430[0m
[[36m09-26 11:43:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 12/14 | 0.14 it/sec | Loss 0.1556 | Reco 0.1556 | Nsdr 6.521[0m
[[36m09-26 11:44:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 3/14 | 10.8 sec/it | Loss 0.1637 | Reco 0.1637 | Nsdr 6.110[0m
[[36m09-26 11:44:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 6/14 | 0.12 it/sec | Loss 0.1561 | Reco 0.1561 | Nsdr 6.264[0m
[[36m09-26 11:45:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 9/14 | 0.13 it/sec | Loss 0.1566 | Reco 0.1566 | Nsdr 6.449[0m
[[36m09-26 11:45:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 12/14 | 0.14 it/sec | Loss 0.1555 | Reco 0.1555 | Nsdr 6.527[0m
[[36m09-26 11:46:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 3/14 | 11.3 sec/it | Loss 0.1638 | Reco 0.1638 | Nsdr 6.109[0m
[[36m09-26 11:46:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 6/14 | 0.12 it/sec | Loss 0.1562 | Reco 0.1562 | Nsdr 6.266[0m
[[36m09-26 11:47:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 9/14 | 0.12 it/sec | Loss 0.1566 | Reco 0.1566 | Nsdr 6.448[0m
[[36m09-26 11:47:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 6 | 12/14 | 0.13 it/sec | Loss 0.1555 | Reco 0.1555 | Nsdr 6.527[0m
[[36m09-26 11:47:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 6 | Loss=0.1570 | Reco=0.1570 | Nsdr=6.375 | Best=0.1569 | Bname=ema_batch_1 | Penalty=195.1019[0m
[[36m09-26 11:47:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-26 11:47:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-26 12:33:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 7 | 1164/4656 | 0.42 it/sec | Loss 0.0881 | Reco 0.0862 | Grad 0.0863 | Penalty 190.6179[0m
[[36m09-26 13:19:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 7 | 2328/4656 | 0.42 it/sec | Loss 0.0892 | Reco 0.0872 | Grad 0.0851 | Penalty 190.7289[0m
[[36m09-26 14:05:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 7 | 3492/4656 | 0.42 it/sec | Loss 0.0893 | Reco 0.0874 | Grad 0.0841 | Penalty 190.5955[0m
[[36m09-26 14:50:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 7 | Loss=0.0892 | Reco=0.0873 | Grad=0.0836 | Penalty=190.5063[0m
[[36m09-26 14:50:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-26 14:50:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-26 14:51:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 3/14 | 11.1 sec/it | Loss 0.1670 | Reco 0.1670 | Nsdr 5.929[0m
[[36m09-26 14:51:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 6/14 | 0.12 it/sec | Loss 0.1597 | Reco 0.1597 | Nsdr 6.065[0m
[[36m09-26 14:52:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 9/14 | 0.13 it/sec | Loss 0.1603 | Reco 0.1603 | Nsdr 6.253[0m
[[36m09-26 14:52:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 12/14 | 0.14 it/sec | Loss 0.1594 | Reco 0.1594 | Nsdr 6.319[0m
[[36m09-26 14:53:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 3/14 | 10.7 sec/it | Loss 0.1630 | Reco 0.1630 | Nsdr 6.145[0m
[[36m09-26 14:53:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 6/14 | 0.12 it/sec | Loss 0.1563 | Reco 0.1563 | Nsdr 6.263[0m
[[36m09-26 14:53:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 9/14 | 0.13 it/sec | Loss 0.1571 | Reco 0.1571 | Nsdr 6.428[0m
[[36m09-26 14:54:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 12/14 | 0.14 it/sec | Loss 0.1561 | Reco 0.1561 | Nsdr 6.501[0m
[[36m09-26 14:55:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 3/14 | 11.0 sec/it | Loss 0.1628 | Reco 0.1628 | Nsdr 6.155[0m
[[36m09-26 14:55:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 6/14 | 0.12 it/sec | Loss 0.1557 | Reco 0.1557 | Nsdr 6.288[0m
[[36m09-26 14:55:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 9/14 | 0.12 it/sec | Loss 0.1564 | Reco 0.1564 | Nsdr 6.458[0m
[[36m09-26 14:55:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 12/14 | 0.13 it/sec | Loss 0.1553 | Reco 0.1553 | Nsdr 6.539[0m
[[36m09-26 14:56:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 3/14 | 10.9 sec/it | Loss 0.1635 | Reco 0.1635 | Nsdr 6.123[0m
[[36m09-26 14:57:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 6/14 | 0.12 it/sec | Loss 0.1559 | Reco 0.1559 | Nsdr 6.269[0m
[[36m09-26 14:57:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 9/14 | 0.13 it/sec | Loss 0.1565 | Reco 0.1565 | Nsdr 6.449[0m
[[36m09-26 14:57:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 12/14 | 0.14 it/sec | Loss 0.1554 | Reco 0.1554 | Nsdr 6.530[0m
[[36m09-26 14:58:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 3/14 | 10.7 sec/it | Loss 0.1639 | Reco 0.1639 | Nsdr 6.114[0m
[[36m09-26 14:58:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 6/14 | 0.12 it/sec | Loss 0.1561 | Reco 0.1561 | Nsdr 6.270[0m
[[36m09-26 14:59:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 9/14 | 0.13 it/sec | Loss 0.1565 | Reco 0.1565 | Nsdr 6.462[0m
[[36m09-26 14:59:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 7 | 12/14 | 0.14 it/sec | Loss 0.1555 | Reco 0.1555 | Nsdr 6.535[0m
[[36m09-26 14:59:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 7 | Loss=0.1568 | Reco=0.1568 | Nsdr=6.391 | Best=0.1568 | Bname=ema_batch_1 | Penalty=196.3977[0m
[[36m09-26 14:59:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1568[0m
[[36m09-26 14:59:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-26 14:59:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-26 15:45:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 8 | 1164/4656 | 0.42 it/sec | Loss 0.0883 | Reco 0.0864 | Grad 0.0824 | Penalty 190.0022[0m
[[36m09-26 16:31:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 8 | 2328/4656 | 0.42 it/sec | Loss 0.0894 | Reco 0.0875 | Grad 0.0816 | Penalty 190.1714[0m
[[36m09-26 17:17:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 8 | 3492/4656 | 0.42 it/sec | Loss 0.0890 | Reco 0.0871 | Grad 0.0828 | Penalty 190.3003[0m
[[36m09-26 18:03:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 8 | Loss=0.0889 | Reco=0.0870 | Grad=0.0832 | Penalty=190.4107[0m
[[36m09-26 18:03:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-26 18:03:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-26 18:04:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 11.3 sec/it | Loss 0.1655 | Reco 0.1655 | Nsdr 6.025[0m
[[36m09-26 18:04:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.12 it/sec | Loss 0.1581 | Reco 0.1581 | Nsdr 6.189[0m
[[36m09-26 18:04:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.12 it/sec | Loss 0.1596 | Reco 0.1596 | Nsdr 6.309[0m
[[36m09-26 18:04:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.13 it/sec | Loss 0.1585 | Reco 0.1585 | Nsdr 6.388[0m
[[36m09-26 18:05:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 11.2 sec/it | Loss 0.1620 | Reco 0.1620 | Nsdr 6.198[0m
[[36m09-26 18:06:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.12 it/sec | Loss 0.1554 | Reco 0.1554 | Nsdr 6.305[0m
[[36m09-26 18:06:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.13 it/sec | Loss 0.1564 | Reco 0.1564 | Nsdr 6.463[0m
[[36m09-26 18:06:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.14 it/sec | Loss 0.1554 | Reco 0.1554 | Nsdr 6.537[0m
[[36m09-26 18:07:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 11.0 sec/it | Loss 0.1617 | Reco 0.1617 | Nsdr 6.205[0m
[[36m09-26 18:07:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.12 it/sec | Loss 0.1554 | Reco 0.1554 | Nsdr 6.307[0m
[[36m09-26 18:08:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.13 it/sec | Loss 0.1561 | Reco 0.1561 | Nsdr 6.485[0m
[[36m09-26 18:08:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.14 it/sec | Loss 0.1551 | Reco 0.1551 | Nsdr 6.561[0m
[[36m09-26 18:09:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 10.9 sec/it | Loss 0.1629 | Reco 0.1629 | Nsdr 6.147[0m
[[36m09-26 18:09:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.12 it/sec | Loss 0.1557 | Reco 0.1557 | Nsdr 6.296[0m
[[36m09-26 18:09:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.13 it/sec | Loss 0.1562 | Reco 0.1562 | Nsdr 6.473[0m
[[36m09-26 18:10:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.14 it/sec | Loss 0.1553 | Reco 0.1553 | Nsdr 6.544[0m
[[36m09-26 18:11:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 3/14 | 10.9 sec/it | Loss 0.1631 | Reco 0.1631 | Nsdr 6.143[0m
[[36m09-26 18:11:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 6/14 | 0.12 it/sec | Loss 0.1557 | Reco 0.1557 | Nsdr 6.293[0m
[[36m09-26 18:11:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 9/14 | 0.13 it/sec | Loss 0.1562 | Reco 0.1562 | Nsdr 6.474[0m
[[36m09-26 18:11:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 8 | 12/14 | 0.14 it/sec | Loss 0.1551 | Reco 0.1551 | Nsdr 6.555[0m
[[36m09-26 18:12:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 8 | Loss=0.1565 | Reco=0.1565 | Nsdr=6.418 | Best=0.1565 | Bname=ema_batch_1 | Penalty=197.9984[0m
[[36m09-26 18:12:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1565[0m
[[36m09-26 18:12:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-26 18:12:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-26 18:58:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 9 | 1164/4656 | 0.42 it/sec | Loss 0.0891 | Reco 0.0872 | Grad 0.0819 | Penalty 190.4394[0m
[[36m09-26 19:44:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 9 | 2328/4656 | 0.42 it/sec | Loss 0.0890 | Reco 0.0871 | Grad 0.0818 | Penalty 190.1120[0m
[[36m09-26 20:31:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 9 | 3492/4656 | 0.42 it/sec | Loss 0.0888 | Reco 0.0869 | Grad 0.0824 | Penalty 190.1024[0m
[[36m09-26 21:17:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 9 | Loss=0.0885 | Reco=0.0866 | Grad=0.0822 | Penalty=190.2437[0m
[[36m09-26 21:17:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-26 21:17:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-26 21:18:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 11.2 sec/it | Loss 0.1696 | Reco 0.1696 | Nsdr 5.834[0m
[[36m09-26 21:18:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.12 it/sec | Loss 0.1613 | Reco 0.1613 | Nsdr 6.018[0m
[[36m09-26 21:18:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.13 it/sec | Loss 0.1618 | Reco 0.1618 | Nsdr 6.200[0m
[[36m09-26 21:18:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.14 it/sec | Loss 0.1600 | Reco 0.1600 | Nsdr 6.316[0m
[[36m09-26 21:19:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 12.3 sec/it | Loss 0.1641 | Reco 0.1641 | Nsdr 6.101[0m
[[36m09-26 21:20:09[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.11 it/sec | Loss 0.1565 | Reco 0.1565 | Nsdr 6.252[0m
[[36m09-26 21:20:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.12 it/sec | Loss 0.1573 | Reco 0.1573 | Nsdr 6.426[0m
[[36m09-26 21:20:45[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.13 it/sec | Loss 0.1558 | Reco 0.1558 | Nsdr 6.529[0m
[[36m09-26 21:21:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 11.3 sec/it | Loss 0.1618 | Reco 0.1618 | Nsdr 6.205[0m
[[36m09-26 21:21:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.12 it/sec | Loss 0.1551 | Reco 0.1551 | Nsdr 6.323[0m
[[36m09-26 21:22:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.12 it/sec | Loss 0.1561 | Reco 0.1561 | Nsdr 6.481[0m
[[36m09-26 21:22:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.13 it/sec | Loss 0.1549 | Reco 0.1549 | Nsdr 6.566[0m
[[36m09-26 21:23:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 12.0 sec/it | Loss 0.1634 | Reco 0.1634 | Nsdr 6.134[0m
[[36m09-26 21:23:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.11 it/sec | Loss 0.1559 | Reco 0.1559 | Nsdr 6.287[0m
[[36m09-26 21:24:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.12 it/sec | Loss 0.1564 | Reco 0.1564 | Nsdr 6.468[0m
[[36m09-26 21:24:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.13 it/sec | Loss 0.1553 | Reco 0.1553 | Nsdr 6.547[0m
[[36m09-26 21:25:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 3/14 | 11.0 sec/it | Loss 0.1637 | Reco 0.1637 | Nsdr 6.114[0m
[[36m09-26 21:25:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 6/14 | 0.12 it/sec | Loss 0.1560 | Reco 0.1560 | Nsdr 6.277[0m
[[36m09-26 21:25:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 9/14 | 0.13 it/sec | Loss 0.1564 | Reco 0.1564 | Nsdr 6.465[0m
[[36m09-26 21:26:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 9 | 12/14 | 0.14 it/sec | Loss 0.1552 | Reco 0.1552 | Nsdr 6.546[0m
[[36m09-26 21:26:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 9 | Loss=0.1563 | Reco=0.1563 | Nsdr=6.426 | Best=0.1563 | Bname=ema_batch_1 | Penalty=196.1523[0m
[[36m09-26 21:26:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1563[0m
[[36m09-26 21:26:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-26 21:26:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-26 22:12:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 10 | 1164/4656 | 0.42 it/sec | Loss 0.0894 | Reco 0.0875 | Grad 0.0844 | Penalty 191.1749[0m
[[36m09-26 22:59:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 10 | 2328/4656 | 0.42 it/sec | Loss 0.0888 | Reco 0.0869 | Grad 0.0828 | Penalty 190.9103[0m
[[36m09-26 23:45:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 10 | 3492/4656 | 0.42 it/sec | Loss 0.0890 | Reco 0.0870 | Grad 0.0826 | Penalty 190.7851[0m
[[36m09-27 00:32:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 10 | Loss=0.0885 | Reco=0.0866 | Grad=0.0820 | Penalty=190.5696[0m
[[36m09-27 00:32:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-27 00:32:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-27 00:32:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 11.4 sec/it | Loss 0.1673 | Reco 0.1673 | Nsdr 5.914[0m
[[36m09-27 00:33:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 0.12 it/sec | Loss 0.1596 | Reco 0.1596 | Nsdr 6.058[0m
[[36m09-27 00:33:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.12 it/sec | Loss 0.1605 | Reco 0.1605 | Nsdr 6.238[0m
[[36m09-27 00:33:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.13 it/sec | Loss 0.1592 | Reco 0.1592 | Nsdr 6.342[0m
[[36m09-27 00:34:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 11.0 sec/it | Loss 0.1636 | Reco 0.1636 | Nsdr 6.127[0m
[[36m09-27 00:34:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 0.12 it/sec | Loss 0.1564 | Reco 0.1564 | Nsdr 6.261[0m
[[36m09-27 00:35:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.13 it/sec | Loss 0.1572 | Reco 0.1572 | Nsdr 6.434[0m
[[36m09-27 00:35:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.14 it/sec | Loss 0.1559 | Reco 0.1559 | Nsdr 6.522[0m
[[36m09-27 00:36:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 10.9 sec/it | Loss 0.1624 | Reco 0.1624 | Nsdr 6.179[0m
[[36m09-27 00:36:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 0.12 it/sec | Loss 0.1553 | Reco 0.1553 | Nsdr 6.308[0m
[[36m09-27 00:36:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.13 it/sec | Loss 0.1562 | Reco 0.1562 | Nsdr 6.473[0m
[[36m09-27 00:37:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.14 it/sec | Loss 0.1551 | Reco 0.1551 | Nsdr 6.559[0m
[[36m09-27 00:38:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 11.3 sec/it | Loss 0.1633 | Reco 0.1633 | Nsdr 6.134[0m
[[36m09-27 00:38:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 0.12 it/sec | Loss 0.1557 | Reco 0.1557 | Nsdr 6.288[0m
[[36m09-27 00:38:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.13 it/sec | Loss 0.1562 | Reco 0.1562 | Nsdr 6.471[0m
[[36m09-27 00:38:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.14 it/sec | Loss 0.1550 | Reco 0.1550 | Nsdr 6.561[0m
[[36m09-27 00:39:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 3/14 | 11.0 sec/it | Loss 0.1633 | Reco 0.1633 | Nsdr 6.135[0m
[[36m09-27 00:40:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 6/14 | 0.12 it/sec | Loss 0.1556 | Reco 0.1556 | Nsdr 6.293[0m
[[36m09-27 00:40:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 9/14 | 0.13 it/sec | Loss 0.1561 | Reco 0.1561 | Nsdr 6.475[0m
[[36m09-27 00:40:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 10 | 12/14 | 0.14 it/sec | Loss 0.1550 | Reco 0.1550 | Nsdr 6.558[0m
[[36m09-27 00:40:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 10 | Loss=0.1565 | Reco=0.1565 | Nsdr=6.409 | Best=0.1563 | Bname=ema_epoch_1 | Penalty=195.2262[0m
[[36m09-27 00:40:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-27 00:40:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-27 01:27:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 11 | 1164/4656 | 0.42 it/sec | Loss 0.0884 | Reco 0.0865 | Grad 0.0816 | Penalty 189.6231[0m
[[36m09-27 02:13:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 11 | 2328/4656 | 0.42 it/sec | Loss 0.0887 | Reco 0.0868 | Grad 0.0826 | Penalty 189.5307[0m
[[36m09-27 02:59:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 11 | 3492/4656 | 0.42 it/sec | Loss 0.0890 | Reco 0.0871 | Grad 0.0824 | Penalty 189.4508[0m
[[36m09-27 03:46:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 11 | Loss=0.0888 | Reco=0.0869 | Grad=0.0827 | Penalty=189.3716[0m
[[36m09-27 03:46:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-27 03:46:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-27 03:46:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 10.9 sec/it | Loss 0.1631 | Reco 0.1631 | Nsdr 6.096[0m
[[36m09-27 03:47:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.12 it/sec | Loss 0.1594 | Reco 0.1594 | Nsdr 6.122[0m
[[36m09-27 03:47:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.13 it/sec | Loss 0.1600 | Reco 0.1600 | Nsdr 6.310[0m
[[36m09-27 03:47:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.14 it/sec | Loss 0.1590 | Reco 0.1590 | Nsdr 6.377[0m
[[36m09-27 03:48:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 10.9 sec/it | Loss 0.1635 | Reco 0.1635 | Nsdr 6.146[0m
[[36m09-27 03:48:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.12 it/sec | Loss 0.1564 | Reco 0.1564 | Nsdr 6.274[0m
[[36m09-27 03:49:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.13 it/sec | Loss 0.1567 | Reco 0.1567 | Nsdr 6.474[0m
[[36m09-27 03:49:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.14 it/sec | Loss 0.1553 | Reco 0.1553 | Nsdr 6.565[0m
[[36m09-27 03:50:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 10.9 sec/it | Loss 0.1625 | Reco 0.1625 | Nsdr 6.185[0m
[[36m09-27 03:50:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.12 it/sec | Loss 0.1554 | Reco 0.1554 | Nsdr 6.315[0m
[[36m09-27 03:51:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.13 it/sec | Loss 0.1560 | Reco 0.1560 | Nsdr 6.492[0m
[[36m09-27 03:51:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.14 it/sec | Loss 0.1548 | Reco 0.1548 | Nsdr 6.581[0m
[[36m09-27 03:52:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 11.3 sec/it | Loss 0.1627 | Reco 0.1627 | Nsdr 6.162[0m
[[36m09-27 03:52:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.12 it/sec | Loss 0.1557 | Reco 0.1557 | Nsdr 6.297[0m
[[36m09-27 03:52:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.12 it/sec | Loss 0.1561 | Reco 0.1561 | Nsdr 6.488[0m
[[36m09-27 03:53:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.13 it/sec | Loss 0.1550 | Reco 0.1550 | Nsdr 6.566[0m
[[36m09-27 03:53:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 3/14 | 11.5 sec/it | Loss 0.1629 | Reco 0.1629 | Nsdr 6.154[0m
[[36m09-27 03:54:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 6/14 | 0.12 it/sec | Loss 0.1557 | Reco 0.1557 | Nsdr 6.294[0m
[[36m09-27 03:54:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 9/14 | 0.12 it/sec | Loss 0.1561 | Reco 0.1561 | Nsdr 6.486[0m
[[36m09-27 03:54:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 11 | 12/14 | 0.13 it/sec | Loss 0.1550 | Reco 0.1550 | Nsdr 6.564[0m
[[36m09-27 03:54:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 11 | Loss=0.1563 | Reco=0.1563 | Nsdr=6.435 | Best=0.1563 | Bname=ema_batch_1 | Penalty=194.6503[0m
[[36m09-27 03:54:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1563[0m
[[36m09-27 03:55:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-27 03:55:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-27 04:41:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 12 | 1164/4656 | 0.42 it/sec | Loss 0.0882 | Reco 0.0863 | Grad 0.0832 | Penalty 189.6755[0m
[[36m09-27 05:27:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 12 | 2328/4656 | 0.42 it/sec | Loss 0.0888 | Reco 0.0869 | Grad 0.0820 | Penalty 189.5821[0m
[[36m09-27 06:14:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 12 | 3492/4656 | 0.42 it/sec | Loss 0.0893 | Reco 0.0874 | Grad 0.0833 | Penalty 189.7254[0m
[[36m09-27 07:00:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 12 | Loss=0.0892 | Reco=0.0873 | Grad=0.0832 | Penalty=189.8254[0m
[[36m09-27 07:00:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-27 07:00:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-27 07:01:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 11.0 sec/it | Loss 0.1706 | Reco 0.1706 | Nsdr 5.853[0m
[[36m09-27 07:01:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.12 it/sec | Loss 0.1610 | Reco 0.1610 | Nsdr 6.045[0m
[[36m09-27 07:02:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.13 it/sec | Loss 0.1614 | Reco 0.1614 | Nsdr 6.225[0m
[[36m09-27 07:02:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.14 it/sec | Loss 0.1598 | Reco 0.1598 | Nsdr 6.316[0m
[[36m09-27 07:03:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 11.2 sec/it | Loss 0.1649 | Reco 0.1649 | Nsdr 6.087[0m
[[36m09-27 07:03:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.12 it/sec | Loss 0.1570 | Reco 0.1570 | Nsdr 6.229[0m
[[36m09-27 07:04:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.13 it/sec | Loss 0.1571 | Reco 0.1571 | Nsdr 6.439[0m
[[36m09-27 07:04:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.14 it/sec | Loss 0.1555 | Reco 0.1555 | Nsdr 6.546[0m
[[36m09-27 07:05:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 11.6 sec/it | Loss 0.1623 | Reco 0.1623 | Nsdr 6.190[0m
[[36m09-27 07:05:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.11 it/sec | Loss 0.1553 | Reco 0.1553 | Nsdr 6.312[0m
[[36m09-27 07:05:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.12 it/sec | Loss 0.1560 | Reco 0.1560 | Nsdr 6.490[0m
[[36m09-27 07:06:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.13 it/sec | Loss 0.1547 | Reco 0.1547 | Nsdr 6.587[0m
[[36m09-27 07:07:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 11.1 sec/it | Loss 0.1630 | Reco 0.1630 | Nsdr 6.154[0m
[[36m09-27 07:07:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.12 it/sec | Loss 0.1555 | Reco 0.1555 | Nsdr 6.301[0m
[[36m09-27 07:07:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.13 it/sec | Loss 0.1560 | Reco 0.1560 | Nsdr 6.485[0m
[[36m09-27 07:07:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.14 it/sec | Loss 0.1549 | Reco 0.1549 | Nsdr 6.563[0m
[[36m09-27 07:08:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 3/14 | 11.0 sec/it | Loss 0.1630 | Reco 0.1630 | Nsdr 6.156[0m
[[36m09-27 07:09:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 6/14 | 0.12 it/sec | Loss 0.1555 | Reco 0.1555 | Nsdr 6.307[0m
[[36m09-27 07:09:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 9/14 | 0.13 it/sec | Loss 0.1560 | Reco 0.1560 | Nsdr 6.488[0m
[[36m09-27 07:09:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 12 | 12/14 | 0.14 it/sec | Loss 0.1548 | Reco 0.1548 | Nsdr 6.572[0m
[[36m09-27 07:09:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 12 | Loss=0.1561 | Reco=0.1561 | Nsdr=6.442 | Best=0.1561 | Bname=ema_batch_1 | Penalty=195.5384[0m
[[36m09-27 07:09:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1561[0m
[[36m09-27 07:09:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-27 07:09:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-27 07:56:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 13 | 1164/4656 | 0.42 it/sec | Loss 0.0879 | Reco 0.0860 | Grad 0.0852 | Penalty 190.1534[0m
[[36m09-27 08:43:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 13 | 2328/4656 | 0.42 it/sec | Loss 0.0878 | Reco 0.0859 | Grad 0.0842 | Penalty 190.4706[0m
[[36m09-27 09:29:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 13 | 3492/4656 | 0.42 it/sec | Loss 0.0884 | Reco 0.0865 | Grad 0.0841 | Penalty 190.5553[0m
[[36m09-27 10:15:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 13 | Loss=0.0884 | Reco=0.0865 | Grad=0.0843 | Penalty=190.8673[0m
[[36m09-27 10:15:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-27 10:15:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-27 10:16:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 11.1 sec/it | Loss 0.1664 | Reco 0.1664 | Nsdr 5.973[0m
[[36m09-27 10:16:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 6/14 | 0.12 it/sec | Loss 0.1581 | Reco 0.1581 | Nsdr 6.142[0m
[[36m09-27 10:16:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 9/14 | 0.13 it/sec | Loss 0.1591 | Reco 0.1591 | Nsdr 6.303[0m
[[36m09-27 10:17:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 12/14 | 0.14 it/sec | Loss 0.1580 | Reco 0.1580 | Nsdr 6.381[0m
[[36m09-27 10:18:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 11.3 sec/it | Loss 0.1655 | Reco 0.1655 | Nsdr 6.058[0m
[[36m09-27 10:18:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 6/14 | 0.12 it/sec | Loss 0.1572 | Reco 0.1572 | Nsdr 6.230[0m
[[36m09-27 10:18:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 9/14 | 0.13 it/sec | Loss 0.1574 | Reco 0.1574 | Nsdr 6.433[0m
[[36m09-27 10:18:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 12/14 | 0.14 it/sec | Loss 0.1558 | Reco 0.1558 | Nsdr 6.542[0m
[[36m09-27 10:19:52[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 10.9 sec/it | Loss 0.1636 | Reco 0.1636 | Nsdr 6.138[0m
[[36m09-27 10:20:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 6/14 | 0.12 it/sec | Loss 0.1559 | Reco 0.1559 | Nsdr 6.288[0m
[[36m09-27 10:20:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 9/14 | 0.13 it/sec | Loss 0.1563 | Reco 0.1563 | Nsdr 6.479[0m
[[36m09-27 10:20:43[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 12/14 | 0.14 it/sec | Loss 0.1549 | Reco 0.1549 | Nsdr 6.576[0m
[[36m09-27 10:21:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 10.8 sec/it | Loss 0.1629 | Reco 0.1629 | Nsdr 6.153[0m
[[36m09-27 10:21:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 6/14 | 0.12 it/sec | Loss 0.1554 | Reco 0.1554 | Nsdr 6.299[0m
[[36m09-27 10:22:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 9/14 | 0.13 it/sec | Loss 0.1561 | Reco 0.1561 | Nsdr 6.472[0m
[[36m09-27 10:22:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 12/14 | 0.14 it/sec | Loss 0.1548 | Reco 0.1548 | Nsdr 6.559[0m
[[36m09-27 10:23:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 3/14 | 11.0 sec/it | Loss 0.1629 | Reco 0.1629 | Nsdr 6.162[0m
[[36m09-27 10:23:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 6/14 | 0.12 it/sec | Loss 0.1552 | Reco 0.1552 | Nsdr 6.313[0m
[[36m09-27 10:23:55[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 9/14 | 0.13 it/sec | Loss 0.1558 | Reco 0.1558 | Nsdr 6.492[0m
[[36m09-27 10:24:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 13 | 12/14 | 0.14 it/sec | Loss 0.1546 | Reco 0.1546 | Nsdr 6.578[0m
[[36m09-27 10:24:22[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 13 | Loss=0.1561 | Reco=0.1561 | Nsdr=6.428 | Best=0.1561 | Bname=ema_epoch_1 | Penalty=196.3878[0m
[[36m09-27 10:24:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-27 10:24:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-27 11:10:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 14 | 1164/4656 | 0.42 it/sec | Loss 0.0897 | Reco 0.0877 | Grad 0.0879 | Penalty 192.7415[0m
[[36m09-27 11:57:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 14 | 2328/4656 | 0.42 it/sec | Loss 0.0892 | Reco 0.0873 | Grad 0.0857 | Penalty 192.4575[0m
[[36m09-27 12:43:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 14 | 3492/4656 | 0.42 it/sec | Loss 0.0890 | Reco 0.0871 | Grad 0.0848 | Penalty 192.1865[0m
[[36m09-27 13:29:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 14 | Loss=0.0889 | Reco=0.0870 | Grad=0.0844 | Penalty=191.8807[0m
[[36m09-27 13:29:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-27 13:29:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-27 13:30:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 3/14 | 11.5 sec/it | Loss 0.1668 | Reco 0.1668 | Nsdr 5.980[0m
[[36m09-27 13:30:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 6/14 | 0.12 it/sec | Loss 0.1597 | Reco 0.1597 | Nsdr 6.105[0m
[[36m09-27 13:31:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 9/14 | 0.12 it/sec | Loss 0.1602 | Reco 0.1602 | Nsdr 6.306[0m
[[36m09-27 13:31:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 12/14 | 0.13 it/sec | Loss 0.1585 | Reco 0.1585 | Nsdr 6.408[0m
[[36m09-27 13:32:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 3/14 | 10.9 sec/it | Loss 0.1627 | Reco 0.1627 | Nsdr 6.166[0m
[[36m09-27 13:32:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 6/14 | 0.12 it/sec | Loss 0.1561 | Reco 0.1561 | Nsdr 6.283[0m
[[36m09-27 13:32:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 9/14 | 0.13 it/sec | Loss 0.1564 | Reco 0.1564 | Nsdr 6.493[0m
[[36m09-27 13:33:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 12/14 | 0.14 it/sec | Loss 0.1549 | Reco 0.1549 | Nsdr 6.594[0m
[[36m09-27 13:33:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 3/14 | 11.3 sec/it | Loss 0.1623 | Reco 0.1623 | Nsdr 6.187[0m
[[36m09-27 13:34:12[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 6/14 | 0.12 it/sec | Loss 0.1553 | Reco 0.1553 | Nsdr 6.315[0m
[[36m09-27 13:34:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 9/14 | 0.12 it/sec | Loss 0.1558 | Reco 0.1558 | Nsdr 6.512[0m
[[36m09-27 13:34:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 12/14 | 0.13 it/sec | Loss 0.1545 | Reco 0.1545 | Nsdr 6.609[0m
[[36m09-27 13:35:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 3/14 | 10.9 sec/it | Loss 0.1629 | Reco 0.1629 | Nsdr 6.162[0m
[[36m09-27 13:35:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 6/14 | 0.12 it/sec | Loss 0.1555 | Reco 0.1555 | Nsdr 6.301[0m
[[36m09-27 13:36:16[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 9/14 | 0.13 it/sec | Loss 0.1559 | Reco 0.1559 | Nsdr 6.493[0m
[[36m09-27 13:36:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 12/14 | 0.14 it/sec | Loss 0.1546 | Reco 0.1546 | Nsdr 6.587[0m
[[36m09-27 13:37:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 3/14 | 11.0 sec/it | Loss 0.1626 | Reco 0.1626 | Nsdr 6.168[0m
[[36m09-27 13:37:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 6/14 | 0.12 it/sec | Loss 0.1554 | Reco 0.1554 | Nsdr 6.307[0m
[[36m09-27 13:38:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 9/14 | 0.13 it/sec | Loss 0.1559 | Reco 0.1559 | Nsdr 6.495[0m
[[36m09-27 13:38:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 14 | 12/14 | 0.14 it/sec | Loss 0.1547 | Reco 0.1547 | Nsdr 6.578[0m
[[36m09-27 13:38:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 14 | Loss=0.1560 | Reco=0.1560 | Nsdr=6.458 | Best=0.1560 | Bname=ema_batch_1 | Penalty=196.0062[0m
[[36m09-27 13:38:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1560[0m
[[36m09-27 13:38:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-27 13:38:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-27 14:24:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 15 | 1164/4656 | 0.42 it/sec | Loss 0.0900 | Reco 0.0881 | Grad 0.0809 | Penalty 191.6933[0m
[[36m09-27 15:10:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 15 | 2328/4656 | 0.42 it/sec | Loss 0.0892 | Reco 0.0873 | Grad 0.0829 | Penalty 191.3358[0m
[[36m09-27 15:56:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 15 | 3492/4656 | 0.42 it/sec | Loss 0.0890 | Reco 0.0871 | Grad 0.0838 | Penalty 191.2587[0m
[[36m09-27 16:42:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 15 | Loss=0.0891 | Reco=0.0871 | Grad=0.0847 | Penalty=195.6318[0m
[[36m09-27 16:42:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-27 16:42:25[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-27 16:43:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 3/14 | 11.3 sec/it | Loss 0.1692 | Reco 0.1692 | Nsdr 5.837[0m
[[36m09-27 16:43:26[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 6/14 | 0.12 it/sec | Loss 0.1588 | Reco 0.1588 | Nsdr 6.042[0m
[[36m09-27 16:43:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 9/14 | 0.12 it/sec | Loss 0.1596 | Reco 0.1596 | Nsdr 6.219[0m
[[36m09-27 16:44:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 12/14 | 0.13 it/sec | Loss 0.1583 | Reco 0.1583 | Nsdr 6.316[0m
[[36m09-27 16:44:56[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 3/14 | 11.0 sec/it | Loss 0.1650 | Reco 0.1650 | Nsdr 6.069[0m
[[36m09-27 16:45:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 6/14 | 0.12 it/sec | Loss 0.1567 | Reco 0.1567 | Nsdr 6.245[0m
[[36m09-27 16:45:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 9/14 | 0.13 it/sec | Loss 0.1569 | Reco 0.1569 | Nsdr 6.445[0m
[[36m09-27 16:45:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 12/14 | 0.14 it/sec | Loss 0.1555 | Reco 0.1555 | Nsdr 6.543[0m
[[36m09-27 16:46:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 3/14 | 10.6 sec/it | Loss 0.1629 | Reco 0.1629 | Nsdr 6.167[0m
[[36m09-27 16:46:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 6/14 | 0.12 it/sec | Loss 0.1556 | Reco 0.1556 | Nsdr 6.304[0m
[[36m09-27 16:47:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 9/14 | 0.13 it/sec | Loss 0.1559 | Reco 0.1559 | Nsdr 6.506[0m
[[36m09-27 16:47:30[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 12/14 | 0.14 it/sec | Loss 0.1544 | Reco 0.1544 | Nsdr 6.610[0m
[[36m09-27 16:48:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 3/14 | 11.0 sec/it | Loss 0.1625 | Reco 0.1625 | Nsdr 6.175[0m
[[36m09-27 16:48:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 6/14 | 0.12 it/sec | Loss 0.1551 | Reco 0.1551 | Nsdr 6.316[0m
[[36m09-27 16:48:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 9/14 | 0.13 it/sec | Loss 0.1555 | Reco 0.1555 | Nsdr 6.516[0m
[[36m09-27 16:49:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 12/14 | 0.14 it/sec | Loss 0.1543 | Reco 0.1543 | Nsdr 6.603[0m
[[36m09-27 16:50:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 3/14 | 10.7 sec/it | Loss 0.1623 | Reco 0.1623 | Nsdr 6.185[0m
[[36m09-27 16:50:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 6/14 | 0.12 it/sec | Loss 0.1551 | Reco 0.1551 | Nsdr 6.322[0m
[[36m09-27 16:50:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 9/14 | 0.13 it/sec | Loss 0.1555 | Reco 0.1555 | Nsdr 6.513[0m
[[36m09-27 16:50:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 15 | 12/14 | 0.14 it/sec | Loss 0.1544 | Reco 0.1544 | Nsdr 6.595[0m
[[36m09-27 16:51:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 15 | Loss=0.1559 | Reco=0.1559 | Nsdr=6.447 | Best=0.1559 | Bname=ema_epoch_0 | Penalty=199.5349[0m
[[36m09-27 16:51:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1559[0m
[[36m09-27 16:51:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-27 16:51:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-27 17:37:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 16 | 1164/4656 | 0.42 it/sec | Loss 0.0892 | Reco 0.0873 | Grad 0.0846 | Penalty 193.2583[0m
[[36m09-27 18:23:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 16 | 2328/4656 | 0.42 it/sec | Loss 0.0890 | Reco 0.0871 | Grad 0.0844 | Penalty 192.8696[0m
[[36m09-27 19:08:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 16 | 3492/4656 | 0.42 it/sec | Loss 0.0884 | Reco 0.0864 | Grad 0.0840 | Penalty 192.7384[0m
[[36m09-27 19:54:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 16 | Loss=0.0888 | Reco=0.0868 | Grad=0.0868 | Penalty=193.2364[0m
[[36m09-27 19:54:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-27 19:54:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-27 19:55:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 3/14 | 11.4 sec/it | Loss 0.1700 | Reco 0.1700 | Nsdr 5.861[0m
[[36m09-27 19:55:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 6/14 | 0.12 it/sec | Loss 0.1617 | Reco 0.1617 | Nsdr 6.010[0m
[[36m09-27 19:56:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 9/14 | 0.12 it/sec | Loss 0.1618 | Reco 0.1618 | Nsdr 6.202[0m
[[36m09-27 19:56:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 12/14 | 0.13 it/sec | Loss 0.1602 | Reco 0.1602 | Nsdr 6.311[0m
[[36m09-27 19:57:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 3/14 | 11.3 sec/it | Loss 0.1628 | Reco 0.1628 | Nsdr 6.164[0m
[[36m09-27 19:57:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 6/14 | 0.12 it/sec | Loss 0.1562 | Reco 0.1562 | Nsdr 6.265[0m
[[36m09-27 19:57:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 9/14 | 0.12 it/sec | Loss 0.1567 | Reco 0.1567 | Nsdr 6.451[0m
[[36m09-27 19:58:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 12/14 | 0.13 it/sec | Loss 0.1551 | Reco 0.1551 | Nsdr 6.566[0m
[[36m09-27 19:59:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 3/14 | 10.9 sec/it | Loss 0.1632 | Reco 0.1632 | Nsdr 6.158[0m
[[36m09-27 19:59:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 6/14 | 0.12 it/sec | Loss 0.1557 | Reco 0.1557 | Nsdr 6.297[0m
[[36m09-27 19:59:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 9/14 | 0.13 it/sec | Loss 0.1560 | Reco 0.1560 | Nsdr 6.496[0m
[[36m09-27 19:59:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 12/14 | 0.14 it/sec | Loss 0.1545 | Reco 0.1545 | Nsdr 6.608[0m
[[36m09-27 20:00:48[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 3/14 | 11.1 sec/it | Loss 0.1625 | Reco 0.1625 | Nsdr 6.182[0m
[[36m09-27 20:01:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 6/14 | 0.12 it/sec | Loss 0.1552 | Reco 0.1552 | Nsdr 6.314[0m
[[36m09-27 20:01:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 9/14 | 0.13 it/sec | Loss 0.1555 | Reco 0.1555 | Nsdr 6.516[0m
[[36m09-27 20:01:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 12/14 | 0.14 it/sec | Loss 0.1543 | Reco 0.1543 | Nsdr 6.607[0m
[[36m09-27 20:02:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 3/14 | 10.9 sec/it | Loss 0.1625 | Reco 0.1625 | Nsdr 6.178[0m
[[36m09-27 20:02:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 6/14 | 0.12 it/sec | Loss 0.1550 | Reco 0.1550 | Nsdr 6.319[0m
[[36m09-27 20:03:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 9/14 | 0.13 it/sec | Loss 0.1554 | Reco 0.1554 | Nsdr 6.512[0m
[[36m09-27 20:03:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 16 | 12/14 | 0.14 it/sec | Loss 0.1543 | Reco 0.1543 | Nsdr 6.600[0m
[[36m09-27 20:03:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 16 | Loss=0.1558 | Reco=0.1558 | Nsdr=6.448 | Best=0.1558 | Bname=ema_epoch_1 | Penalty=199.2232[0m
[[36m09-27 20:03:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1558[0m
[[36m09-27 20:03:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-27 20:03:39[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-27 20:49:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 17 | 1164/4656 | 0.42 it/sec | Loss 0.0892 | Reco 0.0873 | Grad 0.0820 | Penalty 192.7409[0m
[[36m09-27 21:35:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 17 | 2328/4656 | 0.42 it/sec | Loss 0.0889 | Reco 0.0869 | Grad 0.0818 | Penalty 192.5010[0m
[[36m09-27 22:21:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 17 | 3492/4656 | 0.42 it/sec | Loss 0.0886 | Reco 0.0866 | Grad 0.0821 | Penalty 192.4372[0m
[[36m09-27 23:07:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 17 | Loss=0.0885 | Reco=0.0866 | Grad=0.0823 | Penalty=192.2725[0m
[[36m09-27 23:07:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-27 23:07:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-27 23:08:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 3/14 | 10.7 sec/it | Loss 0.1665 | Reco 0.1665 | Nsdr 5.993[0m
[[36m09-27 23:08:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 6/14 | 0.12 it/sec | Loss 0.1600 | Reco 0.1600 | Nsdr 6.114[0m
[[36m09-27 23:08:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 9/14 | 0.13 it/sec | Loss 0.1600 | Reco 0.1600 | Nsdr 6.312[0m
[[36m09-27 23:08:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 12/14 | 0.14 it/sec | Loss 0.1580 | Reco 0.1580 | Nsdr 6.450[0m
[[36m09-27 23:09:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 3/14 | 10.9 sec/it | Loss 0.1637 | Reco 0.1637 | Nsdr 6.128[0m
[[36m09-27 23:10:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 6/14 | 0.12 it/sec | Loss 0.1564 | Reco 0.1564 | Nsdr 6.255[0m
[[36m09-27 23:10:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 9/14 | 0.13 it/sec | Loss 0.1567 | Reco 0.1567 | Nsdr 6.457[0m
[[36m09-27 23:10:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 12/14 | 0.14 it/sec | Loss 0.1552 | Reco 0.1552 | Nsdr 6.569[0m
[[36m09-27 23:11:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 3/14 | 11.1 sec/it | Loss 0.1628 | Reco 0.1628 | Nsdr 6.171[0m
[[36m09-27 23:11:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 6/14 | 0.12 it/sec | Loss 0.1555 | Reco 0.1555 | Nsdr 6.303[0m
[[36m09-27 23:12:07[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 9/14 | 0.12 it/sec | Loss 0.1558 | Reco 0.1558 | Nsdr 6.503[0m
[[36m09-27 23:12:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 12/14 | 0.14 it/sec | Loss 0.1543 | Reco 0.1543 | Nsdr 6.612[0m
[[36m09-27 23:13:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 3/14 | 11.0 sec/it | Loss 0.1621 | Reco 0.1621 | Nsdr 6.193[0m
[[36m09-27 23:13:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 6/14 | 0.12 it/sec | Loss 0.1552 | Reco 0.1552 | Nsdr 6.316[0m
[[36m09-27 23:13:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 9/14 | 0.13 it/sec | Loss 0.1555 | Reco 0.1555 | Nsdr 6.516[0m
[[36m09-27 23:14:08[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 12/14 | 0.14 it/sec | Loss 0.1542 | Reco 0.1542 | Nsdr 6.611[0m
[[36m09-27 23:14:59[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 3/14 | 10.5 sec/it | Loss 0.1626 | Reco 0.1626 | Nsdr 6.180[0m
[[36m09-27 23:15:14[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 6/14 | 0.12 it/sec | Loss 0.1552 | Reco 0.1552 | Nsdr 6.320[0m
[[36m09-27 23:15:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 9/14 | 0.13 it/sec | Loss 0.1554 | Reco 0.1554 | Nsdr 6.524[0m
[[36m09-27 23:15:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 17 | 12/14 | 0.14 it/sec | Loss 0.1542 | Reco 0.1542 | Nsdr 6.617[0m
[[36m09-27 23:16:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 17 | Loss=0.1558 | Reco=0.1558 | Nsdr=6.464 | Best=0.1558 | Bname=ema_epoch_1 | Penalty=196.9650[0m
[[36m09-27 23:16:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1558[0m
[[36m09-27 23:16:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-27 23:16:05[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-28 00:02:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 18 | 1164/4656 | 0.42 it/sec | Loss 0.0877 | Reco 0.0858 | Grad 0.0823 | Penalty 190.9901[0m
[[36m09-28 00:47:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 18 | 2328/4656 | 0.42 it/sec | Loss 0.0884 | Reco 0.0865 | Grad 0.0831 | Penalty 191.0851[0m
[[36m09-28 01:33:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 18 | 3492/4656 | 0.42 it/sec | Loss 0.0885 | Reco 0.0866 | Grad 0.0837 | Penalty 191.0592[0m
[[36m09-28 02:19:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 18 | Loss=0.0885 | Reco=0.0866 | Grad=0.0835 | Penalty=191.0022[0m
[[36m09-28 02:19:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-28 02:19:31[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-28 02:20:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 3/14 | 10.7 sec/it | Loss 0.1720 | Reco 0.1720 | Nsdr 5.776[0m
[[36m09-28 02:20:29[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 6/14 | 0.12 it/sec | Loss 0.1615 | Reco 0.1615 | Nsdr 6.026[0m
[[36m09-28 02:20:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 9/14 | 0.13 it/sec | Loss 0.1610 | Reco 0.1610 | Nsdr 6.254[0m
[[36m09-28 02:21:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 12/14 | 0.14 it/sec | Loss 0.1593 | Reco 0.1593 | Nsdr 6.365[0m
[[36m09-28 02:21:58[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 3/14 | 10.8 sec/it | Loss 0.1648 | Reco 0.1648 | Nsdr 6.090[0m
[[36m09-28 02:22:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 6/14 | 0.12 it/sec | Loss 0.1572 | Reco 0.1572 | Nsdr 6.239[0m
[[36m09-28 02:22:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 9/14 | 0.13 it/sec | Loss 0.1573 | Reco 0.1573 | Nsdr 6.444[0m
[[36m09-28 02:22:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 12/14 | 0.14 it/sec | Loss 0.1557 | Reco 0.1557 | Nsdr 6.549[0m
[[36m09-28 02:23:42[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 3/14 | 10.9 sec/it | Loss 0.1633 | Reco 0.1633 | Nsdr 6.159[0m
[[36m09-28 02:23:57[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 6/14 | 0.12 it/sec | Loss 0.1560 | Reco 0.1560 | Nsdr 6.287[0m
[[36m09-28 02:24:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 9/14 | 0.13 it/sec | Loss 0.1562 | Reco 0.1562 | Nsdr 6.489[0m
[[36m09-28 02:24:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 12/14 | 0.14 it/sec | Loss 0.1547 | Reco 0.1547 | Nsdr 6.599[0m
[[36m09-28 02:25:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 3/14 | 10.8 sec/it | Loss 0.1628 | Reco 0.1628 | Nsdr 6.170[0m
[[36m09-28 02:25:41[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 6/14 | 0.12 it/sec | Loss 0.1555 | Reco 0.1555 | Nsdr 6.307[0m
[[36m09-28 02:26:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 9/14 | 0.13 it/sec | Loss 0.1557 | Reco 0.1557 | Nsdr 6.512[0m
[[36m09-28 02:26:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 12/14 | 0.14 it/sec | Loss 0.1544 | Reco 0.1544 | Nsdr 6.605[0m
[[36m09-28 02:27:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 3/14 | 10.7 sec/it | Loss 0.1630 | Reco 0.1630 | Nsdr 6.160[0m
[[36m09-28 02:27:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 6/14 | 0.12 it/sec | Loss 0.1553 | Reco 0.1553 | Nsdr 6.311[0m
[[36m09-28 02:27:44[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 9/14 | 0.13 it/sec | Loss 0.1556 | Reco 0.1556 | Nsdr 6.510[0m
[[36m09-28 02:28:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 18 | 12/14 | 0.14 it/sec | Loss 0.1543 | Reco 0.1543 | Nsdr 6.605[0m
[[36m09-28 02:28:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 18 | Loss=0.1559 | Reco=0.1559 | Nsdr=6.455 | Best=0.1558 | Bname=ema_epoch_1 | Penalty=195.7368[0m
[[36m09-28 02:28:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-28 02:28:15[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-28 03:14:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 19 | 1164/4656 | 0.42 it/sec | Loss 0.0890 | Reco 0.0870 | Grad 0.0857 | Penalty 191.4311[0m
[[36m09-28 04:00:13[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 19 | 2328/4656 | 0.42 it/sec | Loss 0.0889 | Reco 0.0870 | Grad 0.0856 | Penalty 191.6964[0m
[[36m09-28 04:46:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 19 | 3492/4656 | 0.42 it/sec | Loss 0.0885 | Reco 0.0865 | Grad 0.0856 | Penalty 192.0648[0m
[[36m09-28 05:31:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 19 | Loss=0.0887 | Reco=0.0867 | Grad=0.0856 | Penalty=192.0344[0m
[[36m09-28 05:31:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-28 05:31:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-28 05:32:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 3/14 | 10.7 sec/it | Loss 0.1659 | Reco 0.1659 | Nsdr 6.030[0m
[[36m09-28 05:32:51[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 6/14 | 0.12 it/sec | Loss 0.1596 | Reco 0.1596 | Nsdr 6.109[0m
[[36m09-28 05:33:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 9/14 | 0.13 it/sec | Loss 0.1598 | Reco 0.1598 | Nsdr 6.313[0m
[[36m09-28 05:33:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 12/14 | 0.14 it/sec | Loss 0.1587 | Reco 0.1587 | Nsdr 6.396[0m
[[36m09-28 05:34:19[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 3/14 | 10.7 sec/it | Loss 0.1639 | Reco 0.1639 | Nsdr 6.143[0m
[[36m09-28 05:34:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 6/14 | 0.12 it/sec | Loss 0.1568 | Reco 0.1568 | Nsdr 6.259[0m
[[36m09-28 05:34:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 9/14 | 0.13 it/sec | Loss 0.1571 | Reco 0.1571 | Nsdr 6.451[0m
[[36m09-28 05:35:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 12/14 | 0.14 it/sec | Loss 0.1556 | Reco 0.1556 | Nsdr 6.550[0m
[[36m09-28 05:36:03[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 3/14 | 11.0 sec/it | Loss 0.1628 | Reco 0.1628 | Nsdr 6.186[0m
[[36m09-28 05:36:18[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 6/14 | 0.12 it/sec | Loss 0.1556 | Reco 0.1556 | Nsdr 6.308[0m
[[36m09-28 05:36:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 9/14 | 0.13 it/sec | Loss 0.1560 | Reco 0.1560 | Nsdr 6.502[0m
[[36m09-28 05:36:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 12/14 | 0.14 it/sec | Loss 0.1546 | Reco 0.1546 | Nsdr 6.602[0m
[[36m09-28 05:37:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 3/14 | 10.7 sec/it | Loss 0.1622 | Reco 0.1622 | Nsdr 6.198[0m
[[36m09-28 05:38:01[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 6/14 | 0.12 it/sec | Loss 0.1555 | Reco 0.1555 | Nsdr 6.310[0m
[[36m09-28 05:38:21[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 9/14 | 0.13 it/sec | Loss 0.1556 | Reco 0.1556 | Nsdr 6.519[0m
[[36m09-28 05:38:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 12/14 | 0.14 it/sec | Loss 0.1543 | Reco 0.1543 | Nsdr 6.614[0m
[[36m09-28 05:39:32[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 3/14 | 11.0 sec/it | Loss 0.1624 | Reco 0.1624 | Nsdr 6.190[0m
[[36m09-28 05:39:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 6/14 | 0.12 it/sec | Loss 0.1554 | Reco 0.1554 | Nsdr 6.314[0m
[[36m09-28 05:40:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 9/14 | 0.13 it/sec | Loss 0.1555 | Reco 0.1555 | Nsdr 6.522[0m
[[36m09-28 05:40:23[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 19 | 12/14 | 0.14 it/sec | Loss 0.1542 | Reco 0.1542 | Nsdr 6.615[0m
[[36m09-28 05:40:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 19 | Loss=0.1558 | Reco=0.1558 | Nsdr=6.465 | Best=0.1558 | Bname=ema_epoch_1 | Penalty=198.3008[0m
[[36m09-28 05:40:33[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1558[0m
[[36m09-28 05:40:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-28 05:40:38[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Training...[0m
[[36m09-28 06:26:35[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 20 | 1164/4656 | 0.42 it/sec | Loss 0.0888 | Reco 0.0869 | Grad 0.0867 | Penalty 192.6538[0m
[[36m09-28 07:12:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 20 | 2328/4656 | 0.42 it/sec | Loss 0.0887 | Reco 0.0868 | Grad 0.0849 | Penalty 192.2912[0m
[[36m09-28 07:58:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Train | Epoch 20 | 3492/4656 | 0.42 it/sec | Loss 0.0887 | Reco 0.0868 | Grad 0.0863 | Penalty 192.6837[0m
[[36m09-28 08:44:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTrain Summary | Epoch 20 | Loss=0.0886 | Reco=0.0867 | Grad=0.0856 | Penalty=192.5857[0m
[[36m09-28 08:44:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-28 08:44:06[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Cross validation...[0m
[[36m09-28 08:44:49[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 3/14 | 10.8 sec/it | Loss 0.1648 | Reco 0.1648 | Nsdr 6.049[0m
[[36m09-28 08:45:04[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 6/14 | 0.12 it/sec | Loss 0.1566 | Reco 0.1566 | Nsdr 6.226[0m
[[36m09-28 08:45:24[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 9/14 | 0.13 it/sec | Loss 0.1584 | Reco 0.1584 | Nsdr 6.368[0m
[[36m09-28 08:45:40[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 12/14 | 0.14 it/sec | Loss 0.1575 | Reco 0.1575 | Nsdr 6.446[0m
[[36m09-28 08:46:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 3/14 | 11.2 sec/it | Loss 0.1647 | Reco 0.1647 | Nsdr 6.111[0m
[[36m09-28 08:46:50[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 6/14 | 0.12 it/sec | Loss 0.1567 | Reco 0.1567 | Nsdr 6.252[0m
[[36m09-28 08:47:11[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 9/14 | 0.12 it/sec | Loss 0.1572 | Reco 0.1572 | Nsdr 6.437[0m
[[36m09-28 08:47:27[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 12/14 | 0.13 it/sec | Loss 0.1557 | Reco 0.1557 | Nsdr 6.541[0m
[[36m09-28 08:48:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 3/14 | 10.8 sec/it | Loss 0.1635 | Reco 0.1635 | Nsdr 6.160[0m
[[36m09-28 08:48:34[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 6/14 | 0.12 it/sec | Loss 0.1561 | Reco 0.1561 | Nsdr 6.287[0m
[[36m09-28 08:48:54[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 9/14 | 0.13 it/sec | Loss 0.1564 | Reco 0.1564 | Nsdr 6.487[0m
[[36m09-28 08:49:10[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 12/14 | 0.14 it/sec | Loss 0.1547 | Reco 0.1547 | Nsdr 6.601[0m
[[36m09-28 08:50:02[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 3/14 | 10.6 sec/it | Loss 0.1616 | Reco 0.1616 | Nsdr 6.219[0m
[[36m09-28 08:50:17[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 6/14 | 0.12 it/sec | Loss 0.1551 | Reco 0.1551 | Nsdr 6.330[0m
[[36m09-28 08:50:37[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 9/14 | 0.13 it/sec | Loss 0.1553 | Reco 0.1553 | Nsdr 6.541[0m
[[36m09-28 08:50:53[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 12/14 | 0.14 it/sec | Loss 0.1541 | Reco 0.1541 | Nsdr 6.633[0m
[[36m09-28 08:51:46[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 3/14 | 10.8 sec/it | Loss 0.1620 | Reco 0.1620 | Nsdr 6.210[0m
[[36m09-28 08:52:00[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 6/14 | 0.12 it/sec | Loss 0.1550 | Reco 0.1550 | Nsdr 6.333[0m
[[36m09-28 08:52:20[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 9/14 | 0.13 it/sec | Loss 0.1552 | Reco 0.1552 | Nsdr 6.542[0m
[[36m09-28 08:52:36[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Valid | Epoch 20 | 12/14 | 0.14 it/sec | Loss 0.1541 | Reco 0.1541 | Nsdr 6.627[0m
[[36m09-28 08:52:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mValid Summary | Epoch 20 | Loss=0.1556 | Reco=0.1556 | Nsdr=6.482 | Best=0.1556 | Bname=ema_epoch_0 | Penalty=198.2275[0m
[[36m09-28 08:52:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mNew best valid loss 0.1556[0m
[[36m09-28 08:52:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - ----------------------------------------------------------------------[0m
[[36m09-28 08:52:47[0m][[34mdemucs.solver[0m][[32mINFO[0m] - Evaluating on the test set...[0m
[[36m09-28 08:53:29[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval | 2/10 | 13.5 sec/it[0m
[[36m09-28 08:53:57[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval | 4/10 | 13.7 sec/it[0m
[[36m09-28 08:54:29[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval | 6/10 | 14.4 sec/it[0m
[[36m09-28 08:55:02[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval | 8/10 | 14.9 sec/it[0m
[[36m09-28 09:06:48[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval (BSS) | 2/10 | 230.9 sec/it[0m
[[36m09-28 09:12:55[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval (BSS) | 4/10 | 211.9 sec/it[0m
[[36m09-28 09:20:24[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval (BSS) | 6/10 | 215.6 sec/it[0m
[[36m09-28 09:28:29[0m][[34mdemucs.evaluate[0m][[32mINFO[0m] - Eval (BSS) | 8/10 | 221.5 sec/it[0m
[[36m09-28 09:30:28[0m][[34mdemucs.solver[0m][[32mINFO[0m] - [1mTest Summary | Epoch 20 | Sdr=4.886 | Nsdr=5.350 | Sdr_drums=6.807 | Nsdr_drums=6.785 | Sdr_bass=4.029 | Nsdr_bass=4.506 | Sdr_other=2.551 | Nsdr_other=3.153 | Sdr_vocals=6.157 | Nsdr_vocals=6.958[0m
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.10) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:237: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mParser[0m Injecting argv ['hdemucs.norm_starts=999', 'hdemucs.cac=False', 'test.split=True', 'valid_apply=True', 'model=hdemucs', 'hdemucs.dconv_lstm=4', 'ema.epoch=[0.9, 0.95]', 'ema.batch=[0.9995, 0.9999]', 'seed=42', 'hdemucs.hybrid_old=True', 'svd=base', 'svd.penalty=1e-05', 'svd.dim=100', 'svd.convtr=True', 'batch_size=4', 'dset.segment=8', 'hdemucs.channels=24', 'test.workers=', 'continue_from=538354e6', 'epochs=20', 'optim.lr=0.00025'] from sig 5e8ce54e
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:277: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
/home/paperspace/.local/lib/python3.8/site-packages/dora/hydra.py:254: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  with initialize_config_dir(str(self.full_config_path), job_name=self._job_name):
[1mExecutor:[0m Starting 1 worker processes for DDP.
[1mExecutor:[0m All workers completed successfully
